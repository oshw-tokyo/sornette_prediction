#!/usr/bin/env python3
"""
éŠ˜æŸ„åˆ¥å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
å„éŠ˜æŸ„ã®æœ€æ–°ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã¨äºˆæ¸¬å±¥æ­´ã‚’è¡¨ç¤º
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import matplotlib.cm
from datetime import datetime, timedelta
import numpy as np
from typing import Dict, List, Optional, Tuple
import sys
import os
try:
    from scipy.optimize import curve_fit
except ImportError:
    curve_fit = None

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
from dotenv import load_dotenv
load_dotenv()

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from src.database.results_database import ResultsDatabase
from src.data_sources.unified_data_client import UnifiedDataClient

class SymbolVisualizationDashboard:
    """éŠ˜æŸ„åˆ¥å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        self.db_path = "results/analysis_results.db"
        self.db = ResultsDatabase(self.db_path)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        self.data_client = UnifiedDataClient()
        
        # ãƒšãƒ¼ã‚¸è¨­å®š
        st.set_page_config(
            page_title="Symbol Analysis Dashboard",
            page_icon="ğŸ“Š",
            layout="wide",
            initial_sidebar_state="expanded"
        )
    
    def tc_to_datetime_with_hours(self, tc: float, data_end_date: datetime, window_days: int) -> datetime:
        """
        tcå€¤ã‚’æ—¥æ™‚ã«å¤‰æ›ï¼ˆæ™‚é–“ç²¾åº¦ã¾ã§å«ã‚€ï¼‰
        
        Args:
            tc: æ­£è¦åŒ–ã•ã‚ŒãŸtcå€¤
            data_end_date: ãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚æ—¥ï¼ˆdatetime or pandas.Timestampï¼‰
            window_days: ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®æ—¥æ•°
            
        Returns:
            datetime: äºˆæ¸¬æ—¥æ™‚ï¼ˆæ™‚é–“ç²¾åº¦ï¼‰
        """
        # pandas.Timestampã®å ´åˆã¯python datetimeã«å¤‰æ›
        if hasattr(data_end_date, 'to_pydatetime'):
            data_end_date = data_end_date.to_pydatetime()
        if tc > 1.0:
            # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã‚’è¶…ãˆãŸäºˆæ¸¬
            days_beyond = (tc - 1.0) * window_days
            days_int = int(days_beyond)
            hours = (days_beyond - days_int) * 24
            return data_end_date + timedelta(days=days_int, hours=hours)
        else:
            # ãƒ‡ãƒ¼ã‚¿æœŸé–“å†…ã®äºˆæ¸¬
            days_from_start = tc * window_days
            days_int = int(days_from_start)
            hours = (days_from_start - days_int) * 24
            data_start_date = data_end_date - timedelta(days=window_days)
            return data_start_date + timedelta(days=days_int, hours=hours)
    
    def get_symbol_latest_price_data(self, symbol: str, days: int = 365) -> Optional[pd.DataFrame]:
        """
        éŠ˜æŸ„ã®æœ€æ–°ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            symbol: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            days: å–å¾—æ—¥æ•°
            
        Returns:
            pd.DataFrame: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        """
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆéŠ˜æŸ„åˆ¥ã«é©åˆ‡ãªã‚½ãƒ¼ã‚¹ã‚’æŒ‡å®šï¼‰
            if symbol == 'NASDAQCOM':
                preferred_source = 'fred'
            elif symbol in ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'NVDA', 'META', 'NFLX']:
                preferred_source = 'alpha_vantage'
            else:
                preferred_source = None
            data, source = self.data_client.get_data_with_fallback(
                symbol, 
                start_date.strftime('%Y-%m-%d'),
                end_date.strftime('%Y-%m-%d'),
                preferred_source=preferred_source
            )
            
            if data is not None and not data.empty:
                return data
            return None
            
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def get_prediction_history(self, symbol: str, limit: int = 10) -> pd.DataFrame:
        """
        éŠ˜æŸ„ã®äºˆæ¸¬å±¥æ­´ã‚’å–å¾—
        
        Args:
            symbol: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            limit: å–å¾—ä»¶æ•°
            
        Returns:
            pd.DataFrame: äºˆæ¸¬å±¥æ­´
        """
        try:
            # æœ€æ–°ã®åˆ†æçµæœã‚’å–å¾—
            analyses = self.db.get_recent_analyses(symbol=symbol, limit=limit)
            
            if analyses.empty:
                return pd.DataFrame()
            
            # å¿…è¦ãªåˆ—ã‚’æŠ½å‡ºï¼ˆå­˜åœ¨ç¢ºèªä»˜ãï¼‰
            required_columns = [
                'id', 'analysis_date', 'tc', 'beta', 'omega', 'phi', 'A', 'B', 'C',
                'r_squared', 'rmse', 'quality', 'confidence',
                'predicted_crash_date', 'days_to_crash'
            ]
            
            # ãƒ‡ãƒ¼ã‚¿æœŸé–“é–¢é€£ã®åˆ—ï¼ˆè¤‡æ•°å€™è£œï¼‰
            date_columns = ['data_period_end', 'data_end', 'end_date', 'analysis_date']
            window_columns = ['window_days', 'data_points', 'period_days']
            
            # ç¾åœ¨åˆ©ç”¨å¯èƒ½ãªåˆ—ã‚’ãƒ­ã‚°å‡ºåŠ›
            available_cols = list(analyses.columns)
            print(f"åˆ©ç”¨å¯èƒ½ãªåˆ—: {available_cols}")
            
            # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿é¸æŠ
            existing_columns = [col for col in required_columns if col in analyses.columns]
            result = analyses[existing_columns].copy()
            
            # ãƒ‡ãƒ¼ã‚¿æœŸé–“çµ‚äº†æ—¥ã®åˆ—ã‚’ç‰¹å®š
            data_end_col = None
            for col in date_columns:
                if col in analyses.columns:
                    data_end_col = col
                    break
            
            # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®åˆ—ã‚’ç‰¹å®š
            window_col = None
            for col in window_columns:
                if col in analyses.columns:
                    window_col = col
                    break
            
            # tcå€¤ã‹ã‚‰æ™‚é–“ç²¾åº¦ã®äºˆæ¸¬æ—¥æ™‚ã‚’è¨ˆç®—ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
            if data_end_col and window_col:
                # ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ã§é«˜é€ŸåŒ–
                def vectorized_tc_to_datetime(tc_series, end_date_series, window_series):
                    result_dates = []
                    for tc, end_date, window in zip(tc_series, end_date_series, window_series):
                        if pd.notna(tc):
                            try:
                                result_dates.append(self.tc_to_datetime_with_hours(tc, pd.to_datetime(end_date), window))
                            except:
                                result_dates.append(None)
                        else:
                            result_dates.append(None)
                    return result_dates
                
                result['predicted_datetime_calculated'] = vectorized_tc_to_datetime(
                    result['tc'], 
                    analyses[data_end_col], 
                    analyses[window_col]
                )
            else:
                # ãƒ‡ãƒ¼ã‚¿æœŸé–“æƒ…å ±ãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
                print(f"âš ï¸  ãƒ‡ãƒ¼ã‚¿æœŸé–“åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œ")
                print(f"   æœŸå¾…ã™ã‚‹åˆ—: {date_columns}")
                print(f"   åˆ©ç”¨å¯èƒ½ãªåˆ—: {available_cols}")
                
                default_window = 365
                if 'analysis_date' in analyses.columns:
                    def vectorized_tc_to_datetime_fallback(tc_series, analysis_date_series):
                        result_dates = []
                        for tc, analysis_date in zip(tc_series, analysis_date_series):
                            if pd.notna(tc):
                                try:
                                    result_dates.append(self.tc_to_datetime_with_hours(tc, pd.to_datetime(analysis_date), default_window))
                                except:
                                    result_dates.append(None)
                            else:
                                result_dates.append(None)
                        return result_dates
                    
                    result['predicted_datetime_calculated'] = vectorized_tc_to_datetime_fallback(
                        result['tc'], 
                        analyses['analysis_date']
                    )
                else:
                    result['predicted_datetime_calculated'] = None
            
            return result
            
        except Exception as e:
            st.error(f"äºˆæ¸¬å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return pd.DataFrame()
    
    def calculate_optimal_display_range(self, 
                                      price_data: pd.DataFrame,
                                      predictions: pd.DataFrame) -> Tuple[datetime, datetime]:
        """
        tcä½ç½®ã‚’å«ã‚€æœ€é©ãªè¡¨ç¤ºç¯„å›²ã‚’è¨ˆç®—
        
        Args:
            price_data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            predictions: äºˆæ¸¬å±¥æ­´
            
        Returns:
            Tuple[datetime, datetime]: è¡¨ç¤ºé–‹å§‹æ—¥, è¡¨ç¤ºçµ‚äº†æ—¥
        """
        if price_data.empty:
            return datetime.now() - timedelta(days=365), datetime.now()
        
        start_date = price_data.index.min()
        end_date = price_data.index.max()
        
        # äºˆæ¸¬æ—¥æ™‚ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ãã‚Œã‚’å«ã‚€ã‚ˆã†ã«ç¯„å›²ã‚’æ‹¡å¼µ
        if not predictions.empty and 'predicted_datetime_calculated' in predictions.columns:
            valid_predictions = predictions.dropna(subset=['predicted_datetime_calculated'])
            if not valid_predictions.empty:
                pred_dates = valid_predictions['predicted_datetime_calculated']
                earliest_pred = pred_dates.min()
                latest_pred = pred_dates.max()
                
                # ç¯„å›²ã‚’æ‹¡å¼µï¼ˆäºˆæ¸¬æ—¥æ™‚ã‚’å«ã‚€ã‚ˆã†ã«ï¼‰
                # Timestampäº’æ›æ€§å¯¾å¿œ
                if hasattr(earliest_pred, 'to_pydatetime'):
                    earliest_pred = earliest_pred.to_pydatetime()
                if hasattr(latest_pred, 'to_pydatetime'):
                    latest_pred = latest_pred.to_pydatetime()
                
                if earliest_pred < start_date:
                    start_date = earliest_pred - timedelta(days=30)  # å°‘ã—ä½™è£•ã‚’æŒãŸã›ã‚‹
                if latest_pred > end_date:
                    end_date = latest_pred + timedelta(days=30)  # å°‘ã—ä½™è£•ã‚’æŒãŸã›ã‚‹
        
        return start_date, end_date

    def create_price_chart_with_predictions(self, 
                                          price_data: pd.DataFrame,
                                          predictions: pd.DataFrame,
                                          symbol: str) -> go.Figure:
        """
        ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆã«äºˆæ¸¬å±¥æ­´ã‚’é‡ã­ã¦è¡¨ç¤º
        
        Args:
            price_data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            predictions: äºˆæ¸¬å±¥æ­´
            symbol: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            
        Returns:
            go.Figure: Plotlyãƒãƒ£ãƒ¼ãƒˆ
        """
        fig = go.Figure()
        
        # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        fig.add_trace(go.Scatter(
            x=price_data.index,
            y=price_data['Close'],
            mode='lines',
            name='Price',
            line=dict(color='blue', width=2)
        ))
        
        # äºˆæ¸¬å±¥æ­´ã‚’æ™‚ç³»åˆ—ã§ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è‰²ä»˜ã‘ã—ã¦è¡¨ç¤º
        if not predictions.empty:
            n_predictions = len(predictions)
            colors = plt.cm.Reds(np.linspace(0.3, 1.0, n_predictions))
            
            for idx, (_, pred) in enumerate(predictions.iterrows()):
                if pd.notna(pred.get('predicted_datetime_calculated')):
                    # äºˆæ¸¬æ—¥æ™‚ã«ç¸¦ç·šã‚’è¿½åŠ ï¼ˆTimestampäº’æ›æ€§å¯¾å¿œï¼‰
                    pred_datetime = pred['predicted_datetime_calculated']
                    # pandas.Timestampã®å ´åˆã¯python datetimeã«å¤‰æ›
                    if hasattr(pred_datetime, 'to_pydatetime'):
                        pred_datetime = pred_datetime.to_pydatetime()
                    
                    # å‚ç›´ç·šã‚’æç”»ï¼ˆæ³¨é‡ˆãªã—ï¼‰
                    fig.add_shape(
                        type="line",
                        x0=pred_datetime,
                        x1=pred_datetime,
                        y0=0,  # yè»¸ã®æœ€å°å€¤ã‹ã‚‰
                        y1=1,  # yè»¸ã®æœ€å¤§å€¤ã¾ã§ï¼ˆç›¸å¯¾åº§æ¨™ï¼‰
                        yref="paper",  # yè»¸ã‚’ç›¸å¯¾åº§æ¨™ã§æŒ‡å®š
                        line=dict(
                            color=f'rgba({int(colors[idx][0]*255)}, {int(colors[idx][1]*255)}, {int(colors[idx][2]*255)}, 0.7)',
                            width=2,
                            dash="dash"
                        )
                    )
                    
                    # å‡¡ä¾‹ç”¨ã®é€æ˜ãªç·šã‚’è¿½åŠ ï¼ˆæ—¥ä»˜ã‚’è¡¨ç¤ºï¼‰
                    fig.add_trace(go.Scatter(
                        x=[pred_datetime],
                        y=[None],  # éè¡¨ç¤º
                        mode='lines',
                        line=dict(
                            color=f'rgba({int(colors[idx][0]*255)}, {int(colors[idx][1]*255)}, {int(colors[idx][2]*255)}, 0.7)',
                            width=2,
                            dash='dash'
                        ),
                        name=f"Crash Prediction: {pred_datetime.strftime('%Y-%m-%d')}",
                        showlegend=True,
                        visible='legendonly'  # å‡¡ä¾‹ã®ã¿è¡¨ç¤º
                    ))
        
        # è¡¨ç¤ºç¯„å›²ã‚’äºˆæ¸¬æ—¥æ™‚ã‚’å«ã‚€ã‚ˆã†ã«æœ€é©åŒ–
        display_start, display_end = self.calculate_optimal_display_range(price_data, predictions)
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
        fig.update_layout(
            title=f"{symbol} - Price History with Crash Predictions",
            xaxis_title="Date",
            yaxis_title="Price",
            height=600,
            showlegend=True,
            hovermode='x unified',
            xaxis=dict(
                range=[display_start, display_end]
            ) if display_start and display_end else {}
        )
        
        return fig
    
    def create_prediction_scatter(self, predictions: pd.DataFrame, symbol: str) -> go.Figure:
        """
        äºˆæ¸¬å‚¾å‘ã®æ•£å¸ƒå›³ã‚’ä½œæˆ
        
        Args:
            predictions: äºˆæ¸¬å±¥æ­´
            symbol: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            
        Returns:
            go.Figure: Plotlyæ•£å¸ƒå›³
        """
        fig = go.Figure()
        
        if not predictions.empty:
            # æ™‚ç³»åˆ—ã§ã®è‰²ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            n_predictions = len(predictions)
            colors = plt.cm.Blues(np.linspace(0.3, 1.0, n_predictions))
            
            # æ•£å¸ƒå›³ãƒ—ãƒ­ãƒƒãƒˆ
            for idx, (_, pred) in enumerate(predictions.iterrows()):
                if pd.notna(pred.get('predicted_datetime_calculated')):
                    # Timestampäº’æ›æ€§å¯¾å¿œ
                    pred_datetime = pred['predicted_datetime_calculated']
                    if hasattr(pred_datetime, 'to_pydatetime'):
                        pred_datetime = pred_datetime.to_pydatetime()
                    
                    # data_period_endã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    if 'data_period_end' in pred.index and pd.notna(pred.get('data_period_end')):
                        period_end = pred['data_period_end']
                    else:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šanalysis_dateã‚’ä½¿ç”¨
                        period_end = pred.get('analysis_date', datetime.now())
                    
                    if hasattr(period_end, 'to_pydatetime'):
                        period_end = period_end.to_pydatetime()
                    
                    fig.add_trace(go.Scatter(
                        x=[period_end],     # ãƒ‡ãƒ¼ã‚¿æœŸé–“æœ€çµ‚æ—¥ï¼ˆæ¨ªè»¸ï¼‰
                        y=[pred_datetime],  # äºˆæ¸¬æ—¥æ™‚ï¼ˆç¸¦è»¸ï¼‰
                        mode='markers',
                        marker=dict(
                            size=10,
                            color=f'rgba({int(colors[idx][0]*255)}, {int(colors[idx][1]*255)}, {int(colors[idx][2]*255)}, 0.8)',
                        ),
                        text=f"tc={pred['tc']:.3f}, RÂ²={pred['r_squared']:.3f}",
                        hovertemplate='Data Period End: %{x}<br>Prediction: %{y}<br>%{text}<extra></extra>',
                        showlegend=False,
                        name='Predictions'
                    ))
        
        # ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°æ©Ÿèƒ½ã¯ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼ˆå®‰å®šæ€§ã®ãŸã‚ï¼‰
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
        fig.update_layout(
            title=f"{symbol} - Prediction Trend Analysis",
            xaxis_title="Analysis Date (Data Period End Date)",    # è§£ææ—¥ï¼ˆãƒ‡ãƒ¼ã‚¿æœŸé–“æœ€çµ‚æ—¥ï¼‰
            yaxis_title="Predicted Crash Date",                   # äºˆæ¸¬ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ—¥ä»˜
            height=600,
            showlegend=True,
            legend=dict(
                yanchor="top",
                y=0.99,
                xanchor="left",
                x=0.01,
                bgcolor="rgba(255,255,255,0.8)",
                bordercolor="Black",
                borderwidth=1
            )
        )
        
        return fig
    
    def render_dashboard(self):
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ãƒ¡ã‚¤ãƒ³è¡¨ç¤º"""
        st.title("ğŸ“Š Symbol-Specific Crash Prediction Dashboard")
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
        with st.sidebar:
            st.header("ğŸ›ï¸ Controls")
            
            # éŠ˜æŸ„é¸æŠ
            recent_analyses = self.db.get_recent_analyses(limit=1000)
            if not recent_analyses.empty:
                symbols = sorted(recent_analyses['symbol'].unique().tolist())
                selected_symbol = st.selectbox("Select Symbol", symbols)
                
                # è¡¨ç¤ºè¨­å®š
                st.subheader("ğŸ“Š Display Settings")
                
                # è¡¨ç¤ºä»¶æ•°
                n_predictions = st.slider(
                    "Number of Predictions to Show",
                    min_value=5,
                    max_value=50,
                    value=10,
                    step=5
                )
                
                # è¡¨ç¤ºç”¨ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿æœŸé–“ï¼ˆãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã¨ã¯ç‹¬ç«‹ï¼‰
                price_days = st.selectbox(
                    "Chart Display Period",
                    options=[90, 180, 365, 730],
                    index=2,
                    format_func=lambda x: f"{x} days",
                    help="ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆã«è¡¨ç¤ºã™ã‚‹æœŸé–“ï¼ˆãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°æœŸé–“ã¨ã¯ç‹¬ç«‹ï¼‰"
                )
                
                # äºˆæ¸¬è¡¨ç¤ºé–“éš”
                # TODO: ãƒ‡ãƒ¼ã‚¿æ¬ æã«å¯¾ã™ã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§ã‚’è€ƒæ…®ã—ãŸå®Ÿè£…ãŒå¿…è¦
                # Issue I011: å¯è¦–åŒ–è¡¨ç¤ºåˆ¶å¾¡ã®ãƒ­ãƒã‚¹ãƒˆæ€§
                display_interval = st.selectbox(
                    "Display Interval",
                    options=["All Available", "Weekly", "Bi-weekly", "Monthly"],
                    index=1,  # Weekly ã‚’åˆæœŸçŠ¶æ…‹ã«
                    help="äºˆæ¸¬å±¥æ­´ã®è¡¨ç¤ºé–“éš”ï¼ˆWeekly = æœ€æ–°ã®é€±æ¬¡äºˆæ¸¬ã®ã¿è¡¨ç¤ºï¼‰"
                )
            else:
                st.warning("No analysis data available")
                return
        
        # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        if selected_symbol:
            # æœ€æ–°ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            with st.spinner(f"Loading price data for {selected_symbol}..."):
                price_data = self.get_symbol_latest_price_data(selected_symbol, price_days)
            
            # äºˆæ¸¬å±¥æ­´ã‚’å–å¾—
            with st.spinner(f"Loading prediction history for {selected_symbol}..."):
                predictions = self.get_prediction_history(selected_symbol, n_predictions)
            
            # ã‚¿ãƒ–ä½œæˆ
            tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ Price & Predictions", "ğŸ“Š Prediction Trend", "ğŸ“‹ Parameters"])
            
            with tab1:
                st.subheader(f"{selected_symbol} - Price History with Predictions")
                
                if price_data is not None and not price_data.empty:
                    # ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
                    price_chart = self.create_price_chart_with_predictions(
                        price_data, predictions, selected_symbol
                    )
                    st.plotly_chart(price_chart, use_container_width=True)
                    
                    # æœ€æ–°äºˆæ¸¬æƒ…å ±
                    if not predictions.empty:
                        latest_pred = predictions.iloc[0]
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            if pd.notna(latest_pred.get('predicted_datetime_calculated')):
                                crash_date = latest_pred['predicted_datetime_calculated']
                                if hasattr(crash_date, 'to_pydatetime'):
                                    crash_date = crash_date.to_pydatetime()
                                st.metric(
                                    "Predicted Crash Date",
                                    crash_date.strftime('%Y-%m-%d')
                                )
                        
                        with col2:
                            if pd.notna(latest_pred.get('r_squared')):
                                st.metric("Model Fit (RÂ²)", f"{latest_pred['r_squared']:.3f}")
                        
                        with col3:
                            if pd.notna(latest_pred.get('tc')):
                                st.metric("tc Ratio", f"{latest_pred['tc']:.3f}")
                else:
                    st.error(f"No price data available for {selected_symbol}")
            
            with tab2:
                st.subheader(f"{selected_symbol} - Prediction Trend Analysis")
                
                if not predictions.empty:
                    # æ•£å¸ƒå›³ä½œæˆ
                    scatter_chart = self.create_prediction_scatter(predictions, selected_symbol)
                    st.plotly_chart(scatter_chart, use_container_width=True)
                    
                    # ãƒãƒ£ãƒ¼ãƒˆèª¬æ˜
                    with st.expander("ğŸ“Š Chart Explanation"):
                        st.write("""
                        **ç›®çš„**: ã‚¯ãƒ©ãƒƒã‚·ãƒ¥äºˆæ¸¬ã®æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¦–è¦šçš„ã«åˆ†æ
                        
                        **è»¸ã®èª¬æ˜**:
                        - **æ¨ªè»¸**: Analysis Date (Data Period End Date) - ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã«ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚æ—¥
                        - **ç¸¦è»¸**: Predicted Crash Date - LPPLãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã™ã‚‹ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ—¥ä»˜
                        
                        **è§£é‡ˆ**:
                        - **ç‚¹ã®åˆ†å¸ƒ**: äºˆæ¸¬ã®ä¸€è²«æ€§ã‚„å¤‰å‹•ã‚’ç¤ºã™
                        - **æ™‚ç³»åˆ—ã§ã®å¤‰åŒ–**: è§£ææ—¥ãŒé€²ã‚€ã«ã¤ã‚Œã¦äºˆæ¸¬ãŒã©ã†å¤‰åŒ–ã™ã‚‹ã‹ã‚’è¡¨ç¤º
                        - **è‰²ã®å¤‰åŒ–**: æ™‚ç³»åˆ—é †åºã‚’è¦–è¦šçš„ã«è¡¨ç¾
                        """)
                        
                        st.info("ğŸ’¡ äºˆæ¸¬æ—¥ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã€å¸‚å ´ã®ä¸å®‰å®šæ€§ã‚„ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ãƒªã‚¹ã‚¯ã®å¤‰åŒ–ã‚’èª­ã¿å–ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")
                        
                        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                        if not predictions.empty:
                            has_data_period_end = 'data_period_end' in predictions.columns
                            data_period_count = predictions['data_period_end'].notna().sum() if has_data_period_end else 0
                            analysis_date_count = predictions['analysis_date'].notna().sum() if 'analysis_date' in predictions.columns else 0
                            
                            st.write(f"**Data Source Info**: ")
                            st.write(f"- data_period_end available: {data_period_count}/{len(predictions)} records")
                            st.write(f"- analysis_date fallback: {analysis_date_count}/{len(predictions)} records")
                            
                            if has_data_period_end and data_period_count > 0:
                                sample_date = predictions['data_period_end'].dropna().iloc[0]
                                st.write(f"- Sample data_period_end: {sample_date}")
                            
                            sample_pred = predictions['predicted_datetime_calculated'].dropna().iloc[0]
                            st.write(f"- Sample predicted crash date: {sample_pred}")
                    
                    # çµ±è¨ˆæƒ…å ±ï¼ˆçµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
                    st.subheader("ğŸ“Š Prediction Statistics")
                    
                    # äºˆæ¸¬æ—¥ä»˜ã®çµ±è¨ˆï¼ˆtcå€¤ã‚’æ—¥ä»˜ã«å¤‰æ›ï¼‰
                    crash_dates = predictions['predicted_datetime_calculated'].dropna()
                    if not crash_dates.empty:
                        # datetimeå¤‰æ›
                        crash_dates_dt = []
                        for date in crash_dates:
                            if hasattr(date, 'to_pydatetime'):
                                crash_dates_dt.append(date.to_pydatetime())
                            else:
                                crash_dates_dt.append(date)
                        
                        # çµ±è¨ˆæƒ…å ±è¨ˆç®—ç”¨ã®é–¢æ•°
                        def calculate_stats(dates_list, r_squared_values=None):
                            if not dates_list:
                                return None, None, None, None, None
                            
                            # å¹³å‡æ—¥ä»˜
                            avg_timestamp = sum(dt.timestamp() for dt in dates_list) / len(dates_list)
                            avg_date = datetime.fromtimestamp(avg_timestamp)
                            
                            # æ—¥ä»˜ç¯„å›²
                            earliest = min(dates_list)
                            latest = max(dates_list)
                            date_range_days = (latest - earliest).days
                            
                            # RÂ²å¹³å‡å€¤
                            avg_r2 = r_squared_values.mean() if r_squared_values is not None and not r_squared_values.empty else None
                            
                            return avg_date, date_range_days, earliest, latest, avg_r2
                        
                        # æœ€æ–°Nä»¶ã®ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
                        st.write(f"**Latest {len(crash_dates_dt)} predictions:**")
                        avg_date, date_range, earliest, latest, avg_r2 = calculate_stats(
                            crash_dates_dt, predictions['r_squared']
                        )
                        
                        col1, col2, col3, col4, col5 = st.columns(5)
                        with col1:
                            st.metric("Average Date", avg_date.strftime('%Y-%m-%d'))
                        with col2:
                            st.metric("Date Range", f"{date_range} days")
                        with col3:
                            st.metric("Earliest Prediction", earliest.strftime('%Y-%m-%d'))
                        with col4:
                            st.metric("Latest Prediction", latest.strftime('%Y-%m-%d'))
                        with col5:
                            if avg_r2 is not None:
                                st.metric("Average RÂ²", f"{avg_r2:.3f}")
                            else:
                                st.metric("Average RÂ²", "N/A")
                        
                        # æœ€æ–°1ãƒ¶æœˆã®ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
                        one_month_ago = datetime.now() - timedelta(days=30)
                        recent_predictions = predictions[
                            pd.to_datetime(predictions['analysis_date']) >= one_month_ago
                        ] if 'analysis_date' in predictions.columns else pd.DataFrame()
                        
                        if not recent_predictions.empty:
                            st.write(f"**Recent predictions (last 30 days): {len(recent_predictions)} analyses**")
                            recent_crash_dates = recent_predictions['predicted_datetime_calculated'].dropna()
                            
                            if not recent_crash_dates.empty:
                                recent_dates_dt = []
                                for date in recent_crash_dates:
                                    if hasattr(date, 'to_pydatetime'):
                                        recent_dates_dt.append(date.to_pydatetime())
                                    else:
                                        recent_dates_dt.append(date)
                                
                                recent_avg_date, recent_date_range, recent_earliest, recent_latest, recent_avg_r2 = calculate_stats(
                                    recent_dates_dt, recent_predictions['r_squared']
                                )
                                
                                col1, col2, col3, col4, col5 = st.columns(5)
                                with col1:
                                    st.metric("Average Date", recent_avg_date.strftime('%Y-%m-%d'))
                                with col2:
                                    st.metric("Date Range", f"{recent_date_range} days")
                                with col3:
                                    st.metric("Earliest Prediction", recent_earliest.strftime('%Y-%m-%d'))
                                with col4:
                                    st.metric("Latest Prediction", recent_latest.strftime('%Y-%m-%d'))
                                with col5:
                                    if recent_avg_r2 is not None:
                                        st.metric("Average RÂ²", f"{recent_avg_r2:.3f}")
                                    else:
                                        st.metric("Average RÂ²", "N/A")
                        else:
                            st.info("No predictions in the last 30 days")
                else:
                    st.warning(f"No prediction history available for {selected_symbol}")
            
            with tab3:
                st.subheader(f"{selected_symbol} - Parameter Details")
                
                if not predictions.empty:
                    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
                    display_df = predictions.copy()
                    
                    # äºˆæ¸¬ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ—¥ä»˜åˆ—ã‚’è¿½åŠ 
                    if 'predicted_datetime_calculated' in display_df.columns:
                        display_df['predicted_crash_date'] = display_df['predicted_datetime_calculated'].apply(
                            lambda x: x.strftime('%Y-%m-%d %H:%M') if pd.notna(x) else 'N/A'
                        )
                    else:
                        display_df['predicted_crash_date'] = 'N/A'
                    
                    # ãƒ‡ãƒ¼ã‚¿æœŸé–“æƒ…å ±ã‚’æ•´ç†ï¼ˆå®‰å…¨ãªå‡¦ç†ï¼‰
                    if 'data_period_start' in display_df.columns and 'data_period_end' in display_df.columns:
                        def format_data_period(row):
                            try:
                                start_date = row['data_period_start']
                                end_date = row['data_period_end']
                                
                                if pd.notna(start_date) and pd.notna(end_date):
                                    # æ—¢ã«æ—¥ä»˜æ–‡å­—åˆ—ã®å ´åˆã¨datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆã‚’å‡¦ç†
                                    if isinstance(start_date, str):
                                        start_str = start_date
                                    else:
                                        start_str = pd.to_datetime(start_date).strftime('%Y-%m-%d')
                                    
                                    if isinstance(end_date, str):
                                        end_str = end_date
                                    else:
                                        end_str = pd.to_datetime(end_date).strftime('%Y-%m-%d')
                                    
                                    return f"{start_str} to {end_str}"
                                else:
                                    return 'N/A'
                            except Exception as e:
                                print(f"Data period formatting error: {e}")
                                return 'N/A'
                        
                        display_df['data_period'] = display_df.apply(format_data_period, axis=1)
                        
                        # å€‹åˆ¥ã‚«ãƒ©ãƒ ã‚‚è¿½åŠ ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
                        def format_date_safe(date_val):
                            try:
                                if pd.notna(date_val):
                                    if isinstance(date_val, str):
                                        return date_val
                                    else:
                                        return pd.to_datetime(date_val).strftime('%Y-%m-%d')
                                else:
                                    return 'N/A'
                            except:
                                return 'N/A'
                        
                        display_df['data_start'] = [format_date_safe(x) for x in display_df['data_period_start']]
                        display_df['data_end'] = [format_date_safe(x) for x in display_df['data_period_end']]
                        display_df['period_days'] = [f"{x} days" if pd.notna(x) else 'N/A' for x in display_df['window_days']]
                    else:
                        display_df['data_period'] = 'N/A'
                        display_df['data_start'] = 'N/A'
                        display_df['data_end'] = 'N/A'
                        display_df['period_days'] = 'N/A'
                    
                    # é‡è¦ãªåˆ—é †åºã§è¡¨ç¤º
                    priority_columns = [
                        'predicted_crash_date',    # æœ€é‡è¦ï¼šäºˆæ¸¬ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ—¥ä»˜
                        'r_squared',               # 2ç•ªç›®ï¼šãƒ¢ãƒ‡ãƒ«é©åˆåº¦
                        'confidence',              # 3ç•ªç›®ï¼šä¿¡é ¼åº¦
                        'data_start',              # 4ç•ªç›®ï¼šãƒ‡ãƒ¼ã‚¿é–‹å§‹æ—¥
                        'data_end',                # 5ç•ªç›®ï¼šãƒ‡ãƒ¼ã‚¿çµ‚äº†æ—¥
                        'period_days',             # 6ç•ªç›®ï¼šæœŸé–“æ—¥æ•°
                        'tc',                      # 7ç•ªç›®ï¼štcæ¯”ç‡å€¤ï¼ˆå‚è€ƒï¼‰
                        'beta', 'omega', 'phi',    # ãã®ä»–ã®LPPLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                        'A', 'B', 'C',
                        'rmse', 'quality'
                    ]
                    
                    # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿é¸æŠ
                    existing_display_cols = [col for col in priority_columns if col in display_df.columns]
                    final_df = display_df[existing_display_cols].copy()
                    
                    # æœ€æ–°ãƒ‡ãƒ¼ã‚¿æœŸé–“ã§ã‚½ãƒ¼ãƒˆ
                    if 'data_period_end' in predictions.columns:
                        final_df = final_df.loc[predictions.sort_values('data_period_end', ascending=False).index]
                    
                    # æ•°å€¤ã®ä¸¸ã‚å‡¦ç†
                    numeric_columns = ['r_squared', 'confidence', 'tc', 'beta', 'omega', 'phi', 'A', 'B', 'C', 'rmse']
                    for col in numeric_columns:
                        if col in final_df.columns:
                            final_df[col] = final_df[col].apply(lambda x: f"{x:.4f}" if pd.notna(x) else 'N/A')
                    
                    st.dataframe(
                        final_df,
                        use_container_width=True,
                        height=400,
                        column_config={
                            "predicted_crash_date": st.column_config.TextColumn(
                                "ğŸ¯ Predicted Crash Date",
                                help="Predicted crash date converted from tc ratio",
                            ),
                            "r_squared": st.column_config.TextColumn(
                                "ğŸ“Š RÂ² Score",
                                help="Model fit quality (higher is better)",
                            ),
                            "confidence": st.column_config.TextColumn(
                                "âœ… Confidence",
                                help="Prediction confidence level",
                            ),
                            "data_start": st.column_config.TextColumn(
                                "ğŸ“… Data Start",
                                help="Start date of fitting period",
                            ),
                            "data_end": st.column_config.TextColumn(
                                "ğŸ“… Data End", 
                                help="End date of fitting period",
                            ),
                            "period_days": st.column_config.TextColumn(
                                "ğŸ“Š Period Days",
                                help="Length of fitting period in days",
                            ),
                            "tc": st.column_config.TextColumn(
                                "ğŸ”¢ tc Ratio",
                                help="Critical time ratio (reference)",
                            ),
                        }
                    )
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    csv = final_df.to_csv(index=False)
                    st.download_button(
                        label="ğŸ“¥ Download Parameter History",
                        data=csv,
                        file_name=f"{selected_symbol}_parameters_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                else:
                    st.warning(f"No parameter data available for {selected_symbol}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    dashboard = SymbolVisualizationDashboard()
    dashboard.render_dashboard()

if __name__ == "__main__":
    main()