#!/usr/bin/env python3
"""
å“è³ªè©•ä¾¡ä»˜ããƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ

å¢ƒç•Œå¼µã‚Šä»˜ãã‚„ãã®ä»–ã®å•é¡Œã‚’é©åˆ‡ã«æ¤œå‡ºã—ã€
ãƒ¡ã‚¿æƒ…å ±ã‚’ä»˜ä¸ã—ã¦ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµæœã‚’è©•ä¾¡
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import warnings
import sys
import os
from dotenv import load_dotenv
warnings.filterwarnings('ignore')

# ç’°å¢ƒè¨­å®š
load_dotenv()
sys.path.append('.')

def main():
    print("ğŸ” å“è³ªè©•ä¾¡ä»˜ããƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    # 1. å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“Š Step 1: å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ...")
    test_quality_evaluator()
    
    # 2. å“è³ªè©•ä¾¡çµ±åˆå¤šåŸºæº–é¸æŠã®ãƒ†ã‚¹ãƒˆ
    print("\nğŸ¯ Step 2: å“è³ªè©•ä¾¡çµ±åˆå¤šåŸºæº–é¸æŠã®ãƒ†ã‚¹ãƒˆ...")
    test_quality_aware_selection()
    
    # 3. NASDAQãƒ‡ãƒ¼ã‚¿ã§ã®å®Ÿè¨¼ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“ˆ Step 3: NASDAQãƒ‡ãƒ¼ã‚¿ã§ã®å®Ÿè¨¼ãƒ†ã‚¹ãƒˆ...")
    test_nasdaq_with_quality_assessment()
    
    print("\nâœ… å“è³ªè©•ä¾¡ä»˜ããƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ãƒ†ã‚¹ãƒˆå®Œäº†")

def test_quality_evaluator():
    """å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ"""
    from src.fitting.fitting_quality_evaluator import FittingQualityEvaluator, FittingQuality
    
    evaluator = FittingQualityEvaluator()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: å¢ƒç•Œå¼µã‚Šä»˜ãï¼ˆNASDAQå•é¡Œï¼‰
    print("\n   ğŸ” ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: å¢ƒç•Œå¼µã‚Šä»˜ãï¼ˆNASDAQå•é¡Œï¼‰")
    params1 = {
        'tc': 1.001,  # ä¸‹é™ã«å¼µã‚Šä»˜ã
        'beta': 0.35,
        'omega': 6.5,
        'phi': 0.0,
        'A': 5.0,
        'B': 0.5,
        'C': 0.1
    }
    stats1 = {'r_squared': 0.95, 'rmse': 0.03}
    bounds1 = ([1.001, 0.1, 3.0, -3.14, -10, -10, -1.0], 
               [3.0, 0.8, 15.0, 3.14, 10, 10, 1.0])
    
    assessment1 = evaluator.evaluate_fitting(params1, stats1, bounds1)
    print(f"      å“è³ª: {assessment1.quality.value}")
    print(f"      ä¿¡é ¼åº¦: {assessment1.confidence:.2%}")
    print(f"      ä½¿ç”¨å¯èƒ½: {assessment1.is_usable}")
    print(f"      å•é¡Œç‚¹: {assessment1.issues}")
    print(f"      å¢ƒç•Œå¼µã‚Šä»˜ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {assessment1.metadata.get('boundary_stuck_params', 'ãªã—')}")
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: é«˜å“è³ªãƒ•ã‚£ãƒƒãƒˆ
    print("\n   ğŸ” ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: é«˜å“è³ªãƒ•ã‚£ãƒƒãƒˆ")
    params2 = {
        'tc': 1.25,
        'beta': 0.33,
        'omega': 6.36,
        'phi': 0.1,
        'A': 5.0,
        'B': 0.5,
        'C': 0.1
    }
    stats2 = {'r_squared': 0.92, 'rmse': 0.04}
    
    assessment2 = evaluator.evaluate_fitting(params2, stats2)
    print(f"      å“è³ª: {assessment2.quality.value}")
    print(f"      ä¿¡é ¼åº¦: {assessment2.confidence:.2%}")
    print(f"      ä½¿ç”¨å¯èƒ½: {assessment2.is_usable}")
    print(f"      å•é¡Œç‚¹: {assessment2.issues}")
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹3: éå­¦ç¿’ç–‘ã„
    print("\n   ğŸ” ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹3: éå­¦ç¿’ç–‘ã„")
    params3 = {
        'tc': 1.002,  # å¢ƒç•Œè¿‘ã
        'beta': 0.95,  # æ¥µç«¯ãªå€¤
        'omega': 18.0,  # æ¥µç«¯ãªå€¤
        'phi': 0.0,
        'A': 5.0,
        'B': 0.5,
        'C': 0.1
    }
    stats3 = {'r_squared': 0.98, 'rmse': 0.02}
    
    assessment3 = evaluator.evaluate_fitting(params3, stats3)
    print(f"      å“è³ª: {assessment3.quality.value}")
    print(f"      ä¿¡é ¼åº¦: {assessment3.confidence:.2%}")
    print(f"      ä½¿ç”¨å¯èƒ½: {assessment3.is_usable}")
    print(f"      å•é¡Œç‚¹: {assessment3.issues}")

def test_quality_aware_selection():
    """å“è³ªè©•ä¾¡çµ±åˆå¤šåŸºæº–é¸æŠã®ãƒ†ã‚¹ãƒˆ"""
    from src.fitting.multi_criteria_selection import MultiCriteriaSelector
    
    # åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå¢ƒç•Œå¼µã‚Šä»˜ããŒç™ºç”Ÿã—ã‚„ã™ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    print("\n   ğŸ“Š åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ...")
    dates = pd.date_range('2020-01-01', periods=500, freq='D')
    
    # å¢ƒç•Œè¿‘ãã«åæŸã—ã‚„ã™ã„ãƒ‘ã‚¿ãƒ¼ãƒ³
    t = np.linspace(0.1, 0.99, 500)
    tc_true = 1.02  # å¢ƒç•Œã«è¿‘ã„
    log_prices = (5.0 + 0.3 * (tc_true - t)**0.2 * 
                 (1 + 0.05 * np.cos(5 * np.log(tc_true - t))) + 
                 0.03 * np.random.randn(500))
    prices = np.exp(log_prices)
    
    data = pd.DataFrame({'Close': prices}, index=dates)
    print(f"      ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(data)}ç‚¹")
    
    # å¤šåŸºæº–é¸æŠå®Ÿè¡Œ
    print("\n   ğŸ¯ å“è³ªè©•ä¾¡ä»˜ãå¤šåŸºæº–é¸æŠå®Ÿè¡Œ...")
    selector = MultiCriteriaSelector()
    result = selector.perform_comprehensive_fitting(data)
    
    print(f"      ç·å€™è£œæ•°: {len(result.all_candidates)}")
    print(f"      å“è³ªè©•ä¾¡æ¸ˆã¿å€™è£œ: {len([c for c in result.all_candidates if c.quality_assessment])}")
    print(f"      ä½¿ç”¨å¯èƒ½å€™è£œ: {len([c for c in result.all_candidates if c.quality_assessment and c.quality_assessment.is_usable])}")
    
    # å“è³ªåˆ¥ã®åˆ†é¡
    quality_counts = {}
    for candidate in result.all_candidates:
        if candidate.quality_assessment:
            quality = candidate.quality_assessment.quality.value
            quality_counts[quality] = quality_counts.get(quality, 0) + 1
    
    print(f"\n   ğŸ“‹ å“è³ªåˆ¥åˆ†é¡:")
    for quality, count in quality_counts.items():
        print(f"      {quality}: {count}ä»¶")
    
    # å„é¸æŠåŸºæº–ã®çµæœã¨å“è³ª
    print(f"\n   ğŸ¯ å„é¸æŠåŸºæº–ã§ã®çµæœã¨å“è³ª:")
    for criteria, candidate in result.selections.items():
        if candidate and candidate.quality_assessment:
            qa = candidate.quality_assessment
            print(f"      {criteria.value}:")
            print(f"        tc={candidate.tc:.4f}, RÂ²={candidate.r_squared:.3f}")
            print(f"        å“è³ª={qa.quality.value}, ä¿¡é ¼åº¦={qa.confidence:.2%}")
            print(f"        ä½¿ç”¨å¯èƒ½={qa.is_usable}")
            if qa.issues:
                print(f"        å•é¡Œ: {qa.issues[:2]}")  # æœ€åˆã®2ã¤ã®å•é¡Œ

def test_nasdaq_with_quality_assessment():
    """NASDAQãƒ‡ãƒ¼ã‚¿ã§ã®å“è³ªè©•ä¾¡ä»˜ãåˆ†æ"""
    from src.data_sources.fred_data_client import FREDDataClient
    from src.fitting.multi_criteria_selection import MultiCriteriaSelector
    
    # NASDAQãƒ‡ãƒ¼ã‚¿å–å¾—
    print("\n   ğŸ“Š NASDAQãƒ‡ãƒ¼ã‚¿å–å¾—...")
    client = FREDDataClient()
    end_date = datetime.now()
    start_date = end_date - timedelta(days=730)  # 2å¹´åˆ†
    
    nasdaq_data = client.get_series_data(
        'NASDAQCOM',
        start_date.strftime('%Y-%m-%d'),
        end_date.strftime('%Y-%m-%d')
    )
    
    if nasdaq_data is None:
        print("      âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
        return
    
    print(f"      âœ… {len(nasdaq_data)}æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿å–å¾—")
    
    # å“è³ªè©•ä¾¡ä»˜ãåˆ†æå®Ÿè¡Œ
    print("\n   ğŸ” å“è³ªè©•ä¾¡ä»˜ãåˆ†æå®Ÿè¡Œ...")
    selector = MultiCriteriaSelector()
    result = selector.perform_comprehensive_fitting(nasdaq_data)
    
    print(f"      ç·å€™è£œæ•°: {len(result.all_candidates)}")
    
    # å“è³ªåˆ†æ
    boundary_stuck_count = 0
    usable_count = 0
    failed_count = 0
    
    for candidate in result.all_candidates:
        if candidate.quality_assessment:
            qa = candidate.quality_assessment
            
            if qa.quality.value == 'boundary_stuck':
                boundary_stuck_count += 1
            
            if qa.is_usable:
                usable_count += 1
            else:
                failed_count += 1
    
    print(f"\n   ğŸ“Š å“è³ªåˆ†æçµæœ:")
    print(f"      å¢ƒç•Œå¼µã‚Šä»˜ãå€™è£œ: {boundary_stuck_count}")
    print(f"      ä½¿ç”¨å¯èƒ½å€™è£œ: {usable_count}")
    print(f"      ä½¿ç”¨ä¸å¯å€™è£œ: {failed_count}")
    
    # å“è³ªã®è‰¯ã„å€™è£œã®ã¿ã‚’è¡¨ç¤º
    print(f"\n   âœ… å“è³ªè‰¯å¥½ãªå€™è£œ:")
    good_candidates = [c for c in result.all_candidates 
                      if c.quality_assessment and c.quality_assessment.is_usable]
    
    if good_candidates:
        # å“è³ªã®è‰¯ã„å€™è£œã‚’tcå€¤ã§ã‚½ãƒ¼ãƒˆ
        good_candidates.sort(key=lambda x: x.tc)
        
        for i, candidate in enumerate(good_candidates[:5]):  # ä¸Šä½5ä»¶
            qa = candidate.quality_assessment
            print(f"      å€™è£œ{i+1}: tc={candidate.tc:.4f}, RÂ²={candidate.r_squared:.3f}")
            print(f"              å“è³ª={qa.quality.value}, ä¿¡é ¼åº¦={qa.confidence:.2%}")
    else:
        print("      âš ï¸ å“è³ªè‰¯å¥½ãªå€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    # å¾“æ¥é¸æŠï¼ˆRÂ²æœ€å¤§ï¼‰vs å“è³ªè€ƒæ…®é¸æŠã®æ¯”è¼ƒ
    print(f"\n   ğŸ”„ å¾“æ¥é¸æŠ vs å“è³ªè€ƒæ…®é¸æŠã®æ¯”è¼ƒ:")
    
    # å¾“æ¥ã®RÂ²æœ€å¤§é¸æŠï¼ˆå“è³ªç„¡è¦–ï¼‰
    all_successful = [c for c in result.all_candidates if c.convergence_success]
    if all_successful:
        traditional_best = max(all_successful, key=lambda x: x.r_squared)
        print(f"      å¾“æ¥é¸æŠï¼ˆRÂ²æœ€å¤§ï¼‰:")
        print(f"        tc={traditional_best.tc:.4f}, RÂ²={traditional_best.r_squared:.3f}")
        if traditional_best.quality_assessment:
            print(f"        å“è³ª={traditional_best.quality_assessment.quality.value}")
            print(f"        ä½¿ç”¨å¯èƒ½={traditional_best.quality_assessment.is_usable}")
    
    # å“è³ªè€ƒæ…®é¸æŠ
    if good_candidates:
        quality_best = max(good_candidates, key=lambda x: x.quality_assessment.confidence)
        print(f"      å“è³ªè€ƒæ…®é¸æŠ:")
        print(f"        tc={quality_best.tc:.4f}, RÂ²={quality_best.r_squared:.3f}")
        print(f"        å“è³ª={quality_best.quality_assessment.quality.value}")
        print(f"        ä¿¡é ¼åº¦={quality_best.quality_assessment.confidence:.2%}")
    
    # çµæœã®å¯è¦–åŒ–
    visualize_quality_results(result, nasdaq_data)

def visualize_quality_results(result, data):
    """å“è³ªè©•ä¾¡çµæœã®å¯è¦–åŒ–"""
    print("\n   ğŸ“Š çµæœå¯è¦–åŒ–ä¸­...")
    
    # å€™è£œã®å“è³ªåˆ†å¸ƒ
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. tcå€¤ã¨å“è³ªã®æ•£å¸ƒå›³
    quality_colors = {
        'high_quality': 'green',
        'acceptable': 'blue',
        'boundary_stuck': 'red',
        'poor_convergence': 'orange',
        'overfitting': 'purple',
        'unstable': 'brown',
        'failed': 'gray'
    }
    
    for candidate in result.all_candidates:
        if candidate.quality_assessment:
            quality = candidate.quality_assessment.quality.value
            color = quality_colors.get(quality, 'black')
            alpha = 0.8 if candidate.quality_assessment.is_usable else 0.3
            
            ax1.scatter(candidate.tc, candidate.r_squared, 
                       c=color, alpha=alpha, s=50)
    
    ax1.set_xlabel('tc value')
    ax1.set_ylabel('RÂ² value')
    ax1.set_title('Candidate Quality Distribution (tc vs RÂ²)')
    # å‡¡ä¾‹ã‚’æ‰‹å‹•ã§ä½œæˆ
    legend_elements = [plt.scatter([], [], c=color, s=50, label=quality) 
                       for quality, color in quality_colors.items()]
    ax1.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')
    ax1.grid(True, alpha=0.3)
    
    # 2. å“è³ªã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å€™è£œæ•°
    quality_counts = {}
    for candidate in result.all_candidates:
        if candidate.quality_assessment:
            quality = candidate.quality_assessment.quality.value
            quality_counts[quality] = quality_counts.get(quality, 0) + 1
    
    if quality_counts:
        # å“è³ªã‚«ãƒ†ã‚´ãƒªã‚’ä¸¦ã³æ›¿ãˆ
        quality_order = ['high_quality', 'acceptable', 'boundary_stuck', 'poor_convergence', 
                        'overfitting', 'unstable', 'failed', 'critical_proximity']
        ordered_qualities = [q for q in quality_order if q in quality_counts]
        ordered_counts = [quality_counts[q] for q in ordered_qualities]
        ordered_colors = [quality_colors.get(q, 'gray') for q in ordered_qualities]
        
        bars = ax2.bar(range(len(ordered_qualities)), ordered_counts, 
                      color=ordered_colors, alpha=0.8, edgecolor='black', linewidth=1)
        ax2.set_xticks(range(len(ordered_qualities)))
        ax2.set_xticklabels(ordered_qualities, rotation=45, ha='right')
        
        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, count in zip(bars, ordered_counts):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    str(count), ha='center', va='bottom')
    else:
        ax2.text(0.5, 0.5, 'No quality data available', ha='center', va='center',
                transform=ax2.transAxes, fontsize=12)
    
    ax2.set_ylabel('Number of Candidates')
    ax2.set_title('Candidates by Quality Category')
    ax2.grid(True, alpha=0.3)
    
    # 3. ä½¿ç”¨å¯èƒ½ vs ä½¿ç”¨ä¸å¯ã®æ¯”è¼ƒ
    usable = [c for c in result.all_candidates 
              if c.quality_assessment and c.quality_assessment.is_usable]
    unusable = [c for c in result.all_candidates 
                if c.quality_assessment and not c.quality_assessment.is_usable]
    
    if usable:
        usable_tc = [c.tc for c in usable]
        ax3.hist(usable_tc, bins=20, alpha=0.7, color='green', label='Usable')
    
    if unusable:
        unusable_tc = [c.tc for c in unusable]
        ax3.hist(unusable_tc, bins=20, alpha=0.7, color='red', label='Not Usable')
    
    ax3.set_xlabel('tc value')
    ax3.set_ylabel('Number of Candidates')
    ax3.set_title('tc Distribution by Usability')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã¨äºˆæ¸¬
    ax4.plot(data.index, data['Close'], 'b-', linewidth=1, alpha=0.7, label='NASDAQ')
    
    # ä½¿ç”¨å¯èƒ½ãªå€™è£œã®äºˆæ¸¬ã‚’è¡¨ç¤º
    if usable:
        latest_date = data.index[-1]
        for candidate in usable[:3]:  # ä¸Šä½3ä»¶
            days_to_crash = (candidate.tc - 1.0) * len(data)
            predicted_date = latest_date + timedelta(days=days_to_crash)
            ax4.axvline(predicted_date, color='green', alpha=0.5, linestyle='--')
    
    ax4.set_xlabel('Date')
    ax4.set_ylabel('Price')
    ax4.set_title('NASDAQ Price with High-Quality Predictions')
    ax4.legend()
    
    plt.tight_layout()
    
    # ä¿å­˜
    os.makedirs('results/quality_assessment', exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f'results/quality_assessment/quality_aware_analysis_{timestamp}.png'
    plt.savefig(filename, dpi=300, bbox_inches='tight')
    print(f"      ğŸ“Š å¯è¦–åŒ–ä¿å­˜: {filename}")
    plt.show()

if __name__ == "__main__":
    main()