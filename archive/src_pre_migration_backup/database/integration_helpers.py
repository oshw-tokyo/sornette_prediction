#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆãƒ˜ãƒ«ãƒ‘ãƒ¼
æ—¢å­˜ã®åˆ†æžã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’çµ±åˆã™ã‚‹ãŸã‚ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
"""

from datetime import datetime, timedelta
from typing import Dict, Any, Optional
import pandas as pd
import os

from .results_database import ResultsDatabase
from ..fitting.multi_criteria_selection import SelectionResult, FittingCandidate

class AnalysisResultSaver:
    """åˆ†æžçµæžœã®è‡ªå‹•ä¿å­˜ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path: str = "results/analysis_results.db"):
        """
        åˆæœŸåŒ–
        
        Args:
            db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
        """
        self.db = ResultsDatabase(db_path)
        
    def save_lppl_analysis(self, symbol: str, data: pd.DataFrame, 
                          result: SelectionResult, data_source: str = "unknown") -> int:
        """
        LPPLåˆ†æžçµæžœã®ä¿å­˜
        
        Args:
            symbol: éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            result: åˆ†æžçµæžœ
            data_source: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å
            
        Returns:
            int: ä¿å­˜ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰ID
        """
        best = result.get_selected_result()
        if not best:
            raise ValueError("ä¿å­˜å¯èƒ½ãªåˆ†æžçµæžœãŒã‚ã‚Šã¾ã›ã‚“")
        
        # tcå€¤ã‹ã‚‰äºˆæ¸¬æ—¥ã‚’è¨ˆç®—
        predicted_date = self._calculate_predicted_date(best.tc, data.index[-1])
        days_to_crash = (predicted_date - datetime.now()).days if predicted_date else None
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ç”¨ã®ãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªä½œæˆ
        result_data = {
            'symbol': symbol,
            'data_source': data_source,
            'data_period_start': data.index[0].strftime('%Y-%m-%d'),
            'data_period_end': data.index[-1].strftime('%Y-%m-%d'),
            'data_points': len(data),
            'tc': best.tc,
            'beta': best.beta,
            'omega': best.omega,
            'phi': best.phi,
            'A': best.A,
            'B': best.B,
            'C': best.C,
            'r_squared': best.r_squared,
            'rmse': best.rmse,
            'quality': best.quality_assessment.quality.value if best.quality_assessment else 'unknown',
            'confidence': best.quality_assessment.confidence if best.quality_assessment else 0.0,
            'is_usable': best.quality_assessment.is_usable if best.quality_assessment else False,
            'predicted_crash_date': predicted_date.strftime('%Y-%m-%d') if predicted_date else None,
            'days_to_crash': days_to_crash,
            'fitting_method': 'multi_criteria',
            'window_days': len(data),
            'total_candidates': len(result.all_candidates),
            'successful_candidates': len([c for c in result.all_candidates if c.convergence_success]),
            'quality_metadata': self._extract_quality_metadata(best),
            'selection_criteria': self._extract_selection_criteria(result)
        }
        
        analysis_id = self.db.save_analysis_result(result_data)
        
        print(f"ðŸ“Š {symbol} åˆ†æžçµæžœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜: ID={analysis_id}")
        return analysis_id
    
    def save_visualization_with_analysis(self, analysis_id: int, chart_type: str, 
                                       file_path: str, title: str = "", 
                                       description: str = "") -> int:
        """
        å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ï¼ˆåˆ†æžçµæžœã¨é–¢é€£ä»˜ã‘ï¼‰
        
        Args:
            analysis_id: åˆ†æžçµæžœID
            chart_type: ãƒãƒ£ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—
            file_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            title: ã‚¿ã‚¤ãƒˆãƒ«
            description: èª¬æ˜Ž
            
        Returns:
            int: å¯è¦–åŒ–ãƒ¬ã‚³ãƒ¼ãƒ‰ID
        """
        if not os.path.exists(file_path):
            print(f"âš ï¸ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            return -1
        
        viz_id = self.db.save_visualization(
            analysis_id, chart_type, file_path, title, description
        )
        
        print(f"ðŸ“Š å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ä¿å­˜: ID={viz_id}, Type={chart_type}")
        return viz_id
    
    def _calculate_predicted_date(self, tc: float, last_date: pd.Timestamp) -> Optional[datetime]:
        """
        tcå€¤ã‹ã‚‰äºˆæ¸¬æ—¥ã‚’è¨ˆç®—
        
        Args:
            tc: tcå€¤ï¼ˆæ­£è¦åŒ–æ™‚é–“ï¼‰
            last_date: ãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚æ—¥
            
        Returns:
            datetime: äºˆæ¸¬æ—¥
        """
        try:
            if tc > 1.0:
                # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã‚’è¶…ãˆãŸäºˆæ¸¬
                days_beyond = (tc - 1.0) * 365  # 1å¹´ã‚’åŸºæº–ã¨ã—ãŸè¿‘ä¼¼
                return last_date + timedelta(days=days_beyond)
            else:
                # ãƒ‡ãƒ¼ã‚¿æœŸé–“å†…ã®äºˆæ¸¬ï¼ˆéŽåŽ»ï¼‰
                return None
        except:
            return None
    
    def _extract_quality_metadata(self, candidate: FittingCandidate) -> Dict[str, Any]:
        """å“è³ªè©•ä¾¡ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º"""
        if not candidate.quality_assessment:
            return {}
        
        qa = candidate.quality_assessment
        metadata = {
            'quality': qa.quality.value if hasattr(qa.quality, 'value') else str(qa.quality),
            'confidence': qa.confidence,
            'issues': qa.issues,
            'is_usable': qa.is_usable
        }
        
        # è¿½åŠ ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        if qa.metadata:
            metadata.update(qa.metadata)
        
        return metadata
    
    def _extract_selection_criteria(self, result: SelectionResult) -> Dict[str, Any]:
        """é¸æŠžåŸºæº–ã®æƒ…å ±æŠ½å‡º"""
        criteria = {
            'available_criteria': [],
            'selection_summary': {}
        }
        
        # åˆ©ç”¨å¯èƒ½ãªé¸æŠžåŸºæº–
        for criteria_type, candidate in result.selections.items():
            if candidate:
                criteria['available_criteria'].append(criteria_type.value)
                if criteria_type.value not in criteria['selection_summary']:
                    criteria['selection_summary'][criteria_type.value] = candidate.r_squared
        
        return criteria


class DatabaseAnalysisViewer:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®åˆ†æžçµæžœé–²è¦§ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path: str = "results/analysis_results.db"):
        """
        åˆæœŸåŒ–
        
        Args:
            db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
        """
        self.db = ResultsDatabase(db_path)
    
    def get_dashboard_data(self) -> Dict[str, Any]:
        """
        ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºç”¨ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
        
        Returns:
            Dict: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿
        """
        # åŸºæœ¬çµ±è¨ˆ
        stats = self.db.get_summary_statistics()
        
        # æœ€è¿‘ã®åˆ†æžçµæžœ
        recent_analyses = self.db.get_recent_analyses(limit=20)
        
        # éŠ˜æŸ„åˆ¥çµ±è¨ˆ
        symbol_stats = self._get_symbol_statistics()
        
        # å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰
        quality_trend = self._get_quality_trend()
        
        return {
            'statistics': stats,
            'recent_analyses': recent_analyses.to_dict('records'),
            'symbol_statistics': symbol_stats,
            'quality_trend': quality_trend,
            'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
    
    def _get_symbol_statistics(self) -> Dict[str, Any]:
        """éŠ˜æŸ„åˆ¥çµ±è¨ˆã®å–å¾—"""
        recent_analyses = self.db.get_recent_analyses(limit=100)
        
        if recent_analyses.empty:
            return {}
        
        symbol_stats = {}
        for symbol in recent_analyses['symbol'].unique():
            symbol_data = recent_analyses[recent_analyses['symbol'] == symbol]
            
            symbol_stats[symbol] = {
                'total_analyses': len(symbol_data),
                'usable_analyses': len(symbol_data[symbol_data['is_usable'] == True]),
                'average_r_squared': symbol_data['r_squared'].mean(),
                'latest_analysis': symbol_data['analysis_date'].max(),
                'latest_prediction': symbol_data.iloc[0]['predicted_crash_date'] if len(symbol_data) > 0 else None
            }
        
        return symbol_stats
    
    def _get_quality_trend(self) -> Dict[str, Any]:
        """å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰ã®å–å¾—"""
        recent_analyses = self.db.get_recent_analyses(limit=50)
        
        if recent_analyses.empty:
            return {}
        
        # æ—¥åˆ¥å“è³ªçµ±è¨ˆ
        recent_analyses['date'] = pd.to_datetime(recent_analyses['analysis_date']).dt.date
        daily_quality = recent_analyses.groupby('date').agg({
            'r_squared': 'mean',
            'confidence': 'mean',
            'is_usable': 'sum'
        }).to_dict('index')
        
        # æ—¥ä»˜ã‚’ã‚­ãƒ¼ã¨ã—ã¦æ–‡å­—åˆ—ã«å¤‰æ›
        daily_quality_str = {str(k): v for k, v in daily_quality.items()}
        
        return {
            'daily_quality': daily_quality_str,
            'overall_trend': {
                'improving': recent_analyses['r_squared'].iloc[:10].mean() > recent_analyses['r_squared'].iloc[-10:].mean(),
                'stable_quality': recent_analyses['confidence'].std() < 0.1
            }
        }


# ä½¿ç”¨ä¾‹
def example_integration():
    """çµ±åˆä¾‹ã®å®Ÿæ¼”"""
    print("ðŸ§ª ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆä¾‹")
    print("=" * 50)
    
    # åˆ†æžçµæžœã‚»ãƒ¼ãƒãƒ¼åˆæœŸåŒ–
    saver = AnalysisResultSaver("results/example_integration.db")
    
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ã®ä¿å­˜ä¾‹
    print("ðŸ“Š ã‚µãƒ³ãƒ—ãƒ«åˆ†æžçµæžœã®ä¿å­˜...")
    
    # å®Ÿéš›ã®ä½¿ç”¨ã§ã¯ã€MultiCriteriaSelector.perform_comprehensive_fitting() ã®çµæžœã‚’ä½¿ç”¨
    # ã“ã“ã§ã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    sample_data = pd.DataFrame({
        'Close': [100, 105, 103, 108, 110]
    }, index=pd.date_range('2024-01-01', periods=5))
    
    print("âœ… çµ±åˆæ©Ÿèƒ½æº–å‚™å®Œäº†")
    
    # ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
    viewer = DatabaseAnalysisViewer("results/example_integration.db")
    dashboard_data = viewer.get_dashboard_data()
    
    print(f"ðŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿: {len(dashboard_data)} ã‚»ã‚¯ã‚·ãƒ§ãƒ³")
    
    return saver, viewer


if __name__ == "__main__":
    example_integration()