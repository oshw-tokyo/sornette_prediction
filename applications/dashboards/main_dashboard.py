#!/usr/bin/env python3
"""
Symbol-Based Market Analysis Dashboard

Restored implementation with symbol selection sidebar and category-based classification.
Displays analysis results for selected symbols in 3 tabs with trading position prioritization.
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import sys
import os
import json
import numpy as np
from typing import Dict, List, Optional, Tuple

# ãƒ‘ã‚¹ã®è¨­å®š
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

# .envãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•èª­ã¿è¾¼ã¿ï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ï¼‰
try:
    from dotenv import load_dotenv
    dotenv_path = os.path.join(os.path.dirname(__file__), '../../.env')
    if os.path.exists(dotenv_path):
        load_dotenv(dotenv_path)
        print("âœ… ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: .env ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
    else:
        print("âš ï¸ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: .env ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
except ImportError:
    print("âš ï¸ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: python-dotenv ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")

from infrastructure.database.results_database import ResultsDatabase
from infrastructure.data_sources.unified_data_client import UnifiedDataClient

class SymbolAnalysisDashboard:
    """Symbol-Based Analysis Dashboard"""
    
    def __init__(self):
        self.db = ResultsDatabase()
        self.market_catalog = self.load_market_catalog()
        self.data_client = UnifiedDataClient()
        
        # Page configuration
        st.set_page_config(
            page_title="Symbol Analysis Dashboard",
            page_icon="ğŸ“Š",
            layout="wide",
            initial_sidebar_state="expanded"
        )
    
    def load_market_catalog(self) -> Dict:
        """Load market catalog for symbol categorization"""
        try:
            catalog_path = "infrastructure/data_sources/market_data_catalog.json"
            with open(catalog_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"Failed to load market catalog: {str(e)}")
            return {"symbols": {}}
    
    def get_symbols_by_category(self) -> Dict[str, List[Dict]]:
        """Organize symbols by asset class and instrument type"""
        categorized = {}
        
        if not self.market_catalog.get("symbols"):
            return categorized
        
        for symbol, info in self.market_catalog["symbols"].items():
            asset_class = info.get("asset_class", "unknown")
            instrument_type = info.get("instrument_type", "unknown")
            
            # Create category key
            category_key = f"{asset_class}_{instrument_type}"
            
            if category_key not in categorized:
                categorized[category_key] = {
                    "display_name": f"{asset_class.title()} - {instrument_type}",
                    "symbols": []
                }
            
            categorized[category_key]["symbols"].append({
                "symbol": symbol,
                "display_name": info.get("display_name", symbol),
                "description": info.get("description", ""),
                "bubble_analysis_suitability": info.get("bubble_analysis_suitability", "unknown")
            })
        
        return categorized
    
    # DEPRECATED: tcå€¤ã‹ã‚‰ã®æ—¥æ™‚å¤‰æ›ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜æ™‚ã«å®Ÿè¡Œæ¸ˆã¿ã®ãŸã‚ä¸è¦
    # å°†æ¥çš„ã«å¿…è¦ã«ãªã‚‹å ´åˆã«å‚™ãˆã¦ä¿æŒï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
    # def tc_to_datetime_with_hours(self, tc: float, data_end_date: datetime, window_days: int) -> datetime:
    #     """
    #     tcå€¤ã‚’æ—¥æ™‚ã«å¤‰æ›ï¼ˆæ™‚é–“ç²¾åº¦ã¾ã§å«ã‚€ï¼‰
    #     NOTE: ã“ã®æ©Ÿèƒ½ã¯integration_helpers.pyã§å®Ÿè¡Œæ¸ˆã¿ã®ãŸã‚ç¾åœ¨ã¯ä¸è¦
    #     """
    #     # pandas.Timestampã®å ´åˆã¯python datetimeã«å¤‰æ›
    #     if hasattr(data_end_date, 'to_pydatetime'):
    #         data_end_date = data_end_date.to_pydatetime()
    #     
    #     if tc > 1.0:
    #         # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã‚’è¶…ãˆãŸäºˆæ¸¬
    #         days_beyond = (tc - 1.0) * window_days
    #         days_int = int(days_beyond)
    #         hours = (days_beyond - days_int) * 24
    #         return data_end_date + timedelta(days=days_int, hours=hours)
    #     else:
    #         # ãƒ‡ãƒ¼ã‚¿æœŸé–“å†…ã®äºˆæ¸¬
    #         days_from_start = tc * window_days
    #         days_int = int(days_from_start)
    #         hours = (days_from_start - days_int) * 24
    #         data_start_date = data_end_date - timedelta(days=window_days)
    #         return data_start_date + timedelta(days=days_int, hours=hours)
    
    def calculate_crash_date_convergence(self, crash_dates: List[datetime], basis_dates: List[datetime]) -> Tuple[str, bool]:
        """
        ã‚¯ãƒ©ãƒƒã‚·ãƒ¥äºˆæ¸¬æ—¥ã®åæŸå€¤ã‚’è¨ˆç®—
        
        Args:
            crash_dates: äºˆæ¸¬ã•ã‚ŒãŸã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ—¥ã®ãƒªã‚¹ãƒˆ
            basis_dates: ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°åŸºæº–æ—¥ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            Tuple[str, bool]: (åæŸæ—¥ã¾ãŸã¯"åæŸã—ãªã„", åæŸãƒ•ãƒ©ã‚°)
        """
        try:
            if not crash_dates or len(crash_dates) < 3:
                return "ãƒ‡ãƒ¼ã‚¿ä¸è¶³", False
            
            # ç¾åœ¨ã‹ã‚‰3å¹´ä»¥å†…ã®äºˆæ¸¬ã®ã¿ã‚’æœ‰åŠ¹ã¨ã™ã‚‹
            now = datetime.now()
            three_years_later = now + timedelta(days=3*365)
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼šéå»ã®äºˆæ¸¬ã¨3å¹´ä»¥ä¸Šå…ˆã®äºˆæ¸¬ã‚’é™¤å¤–
            valid_predictions = []
            for crash_date, basis_date in zip(crash_dates, basis_dates):
                if crash_date > now and crash_date <= three_years_later:
                    valid_predictions.append((crash_date, basis_date))
            
            if len(valid_predictions) < 3:
                return "åæŸã—ãªã„", False
            
            # åŸºæº–æ—¥é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
            valid_predictions.sort(key=lambda x: x[1], reverse=True)
            recent_predictions = valid_predictions[:min(5, len(valid_predictions))]
            
            # æœ€æ–°5ä»¶ã®äºˆæ¸¬æ—¥ã®æ¨™æº–åå·®ã‚’è¨ˆç®—
            recent_crash_dates = [pred[0] for pred in recent_predictions]
            timestamps = [d.timestamp() for d in recent_crash_dates]
            
            if len(timestamps) < 3:
                return "ãƒ‡ãƒ¼ã‚¿ä¸è¶³", False
            
            # æ¨™æº–åå·®ã‚’æ—¥æ•°ã§è¨ˆç®—
            mean_timestamp = np.mean(timestamps)
            std_days = np.std(timestamps) / (24 * 3600)  # ç§’ã‚’æ—¥ã«å¤‰æ›
            
            # åæŸåˆ¤å®šï¼šæ¨™æº–åå·®ãŒ30æ—¥ä»¥å†…ãªã‚‰åæŸã¨ã¿ãªã™
            if std_days <= 30:
                convergence_date = datetime.fromtimestamp(mean_timestamp)
                
                # åæŸå‚¾å‘ã®ç¢ºèªï¼šæœ€æ–°3ä»¶ã®äºˆæ¸¬ãŒä¸€å®šæ–¹å‘ã«å‘ã‹ã£ã¦ã„ã‚‹ã‹
                if len(recent_crash_dates) >= 3:
                    trend_timestamps = [d.timestamp() for d in recent_crash_dates[:3]]
                    # æ™‚ç³»åˆ—çš„ã«å˜èª¿ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
                    trend_variation = np.std(np.diff(trend_timestamps)) / (24 * 3600)
                    
                    if trend_variation <= 15:  # 15æ—¥ä»¥å†…ã®å¤‰å‹•ãªã‚‰å®‰å®š
                        return convergence_date.strftime('%Y-%m-%d'), True
                
                return convergence_date.strftime('%Y-%m-%d'), True
            else:
                return "åæŸã—ãªã„", False
                
        except Exception as e:
            return "è¨ˆç®—ã‚¨ãƒ©ãƒ¼", False
    
    def calculate_multi_method_convergence(self, period_data: pd.DataFrame) -> Dict:
        """
        Multiple methods for convergence analysis
        
        Args:
            period_data: DataFrame with prediction data for the period
            
        Returns:
            Dict: Convergence metrics using multiple methods
        """
        try:
            from scipy import stats
            import numpy as np
            
            # Prepare crash dates as numeric values (days from now)
            crash_dates = []
            fitting_dates = []
            r_squared_values = []
            
            for _, row in period_data.iterrows():
                crash_date = pd.to_datetime(row['predicted_crash_date'])
                fitting_date = pd.to_datetime(row['fitting_basis_date'])
                
                # Days from now to crash
                days_to_crash = (crash_date - datetime.now()).days
                crash_dates.append(days_to_crash)
                fitting_dates.append(fitting_date)
                r_squared_values.append(row.get('r_squared', 0.5))
            
            crash_dates = np.array(crash_dates)
            r_squared_values = np.array(r_squared_values)
            
            # 1. Standard deviation method
            std_deviation = np.std(crash_dates)
            mean_days = np.mean(crash_dates)
            
            # 2. Coefficient of variation
            coefficient_variation = std_deviation / abs(mean_days) if abs(mean_days) > 0 else float('inf')
            
            # 3. Range method  
            prediction_range = np.max(crash_dates) - np.min(crash_dates)
            
            # 4. Weighted standard deviation (recent data weighted more)
            # Create exponential weights (more recent = higher weight)
            sorted_indices = np.argsort([fd for fd in fitting_dates])[::-1]  # Most recent first
            weights = np.exp(-0.1 * np.arange(len(crash_dates)))  # Exponential decay
            
            # Apply weights according to fitting date order
            weighted_crash_dates = crash_dates[sorted_indices]
            weighted_mean = np.average(weighted_crash_dates, weights=weights)
            weighted_variance = np.average((weighted_crash_dates - weighted_mean)**2, weights=weights)
            weighted_std = np.sqrt(weighted_variance)
            
            # 5. Trend analysis
            # Linear regression of crash dates over fitting dates
            fitting_timestamps = [fd.timestamp() for fd in fitting_dates]
            if len(fitting_timestamps) >= 3:
                slope, intercept, r_value, p_value, std_err = stats.linregress(fitting_timestamps, crash_dates)
                trend_r_squared = r_value**2
                trend_slope = slope * (24 * 3600)  # Convert to days per day
            else:
                trend_slope = 0
                trend_r_squared = 0
            
            # 6. Consensus date (weighted average of recent predictions)
            consensus_days = weighted_mean
            consensus_date = datetime.now() + timedelta(days=consensus_days)
            
            # 7. Convergence status based on multiple criteria
            if std_deviation < 5 and coefficient_variation < 0.05:
                convergence_status = "Excellent"
            elif std_deviation < 10 and coefficient_variation < 0.10:
                convergence_status = "Good"
            elif std_deviation < 20 and coefficient_variation < 0.20:
                convergence_status = "Moderate" 
            else:
                convergence_status = "Poor"
            
            return {
                'std_deviation': std_deviation,
                'coefficient_variation': coefficient_variation,
                'prediction_range': prediction_range,
                'weighted_std': weighted_std,
                'trend_slope': trend_slope,
                'trend_r_squared': trend_r_squared,
                'consensus_date': consensus_date,
                'convergence_status': convergence_status,
                'mean_days_to_crash': mean_days,
                'data_count': len(crash_dates)
            }
            
        except Exception as e:
            # Return default values on error
            return {
                'std_deviation': 999.0,
                'coefficient_variation': 999.0,
                'prediction_range': 999.0,
                'weighted_std': 999.0,
                'trend_slope': 0.0,
                'trend_r_squared': 0.0,
                'consensus_date': datetime.now(),
                'convergence_status': 'Error',
                'mean_days_to_crash': 0.0,
                'data_count': 0
            }
    
    def create_convergence_plot(self, period_data: pd.DataFrame, period_name: str, convergence_results: Dict):
        """
        Create a detailed convergence plot for a specific period
        
        Args:
            period_data: DataFrame with prediction data
            period_name: Name of the time period
            convergence_results: Results from calculate_multi_method_convergence
            
        Returns:
            plotly.graph_objects.Figure: Convergence analysis plot
        """
        try:
            fig = go.Figure()
            
            # Prepare data
            fitting_dates = []
            crash_dates = []
            r_squared_values = []
            quality_values = []
            
            for _, row in period_data.iterrows():
                fitting_dates.append(pd.to_datetime(row['fitting_basis_date']))
                crash_dates.append(pd.to_datetime(row['predicted_crash_date']))
                r_squared_values.append(row.get('r_squared', 0.5))
                quality_values.append(row.get('quality', 'unknown'))
            
            # Main scatter plot: fitting dates vs crash predictions
            fig.add_trace(go.Scatter(
                x=fitting_dates,
                y=crash_dates,
                mode='markers',
                marker=dict(
                    size=12,
                    color=r_squared_values,
                    colorscale='Viridis',
                    showscale=True,
                    colorbar=dict(title="RÂ² Score", x=1.02)
                ),
                name='Predictions',
                text=[f"RÂ²: {r2:.3f}<br>Quality: {q}<br>Days to crash: {(cd - datetime.now()).days}" 
                      for cd, r2, q in zip(crash_dates, r_squared_values, quality_values)],
                hovertemplate='Fitting Date: %{x}<br>Predicted Crash: %{y}<br>%{text}<extra></extra>'
            ))
            
            # Add consensus crash date line
            consensus_date = convergence_results['consensus_date']
            fig.add_hline(
                y=consensus_date,
                line_dash="dash",
                line_color="red",
                annotation_text=f"Consensus: {consensus_date.strftime('%Y-%m-%d')}",
                annotation_position="bottom right"
            )
            
            # Add convergence bands
            std_dev_days = convergence_results['std_deviation']
            upper_band = consensus_date + timedelta(days=std_dev_days)
            lower_band = consensus_date - timedelta(days=std_dev_days)
            
            # Add upper and lower bands
            fig.add_hline(
                y=upper_band,
                line_dash="dot",
                line_color="orange",
                opacity=0.5,
                annotation_text=f"+1Ïƒ ({std_dev_days:.0f}d)",
                annotation_position="top right"
            )
            fig.add_hline(
                y=lower_band,
                line_dash="dot", 
                line_color="orange",
                opacity=0.5,
                annotation_text=f"-1Ïƒ",
                annotation_position="bottom right"
            )
            
            # Trend line if significant
            if convergence_results['trend_r_squared'] > 0.5:
                # Add trend line
                x_trend = [min(fitting_dates), max(fitting_dates)]
                trend_slope_per_sec = convergence_results['trend_slope'] / (24 * 3600)
                
                # Calculate y values for trend line
                y_start = consensus_date
                days_span = (max(fitting_dates) - min(fitting_dates)).days
                y_end = consensus_date + timedelta(days=trend_slope_per_sec * days_span)
                
                fig.add_trace(go.Scatter(
                    x=x_trend,
                    y=[y_start, y_end],
                    mode='lines',
                    line=dict(color='purple', width=2, dash='dot'),
                    name=f'Trend (RÂ²={convergence_results["trend_r_squared"]:.2f})',
                    hovertemplate='Trend Line<extra></extra>'
                ))
            
            # Layout
            fig.update_layout(
                title=f"{period_name} Convergence Analysis - Status: {convergence_results['convergence_status']}",
                xaxis_title="Fitting Basis Date",
                yaxis_title="Predicted Crash Date", 
                height=500,
                hovermode='closest',
                plot_bgcolor='rgba(240, 240, 240, 0.8)',
                showlegend=True
            )
            
            return fig
            
        except Exception as e:
            # Return empty figure on error
            fig = go.Figure()
            fig.update_layout(
                title=f"{period_name} - Plot Error: {str(e)}",
                height=400
            )
            return fig
    
    def calculate_trading_priority_score(self, predicted_crash_date: datetime) -> float:
        """
        äºˆæ¸¬ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ—¥æ™‚ã«åŸºã¥ã„ã¦ãƒˆãƒ¬ãƒ¼ãƒ‰å„ªå…ˆåº¦ã‚’è¨ˆç®—
        
        Args:
            predicted_crash_date: äºˆæ¸¬ã•ã‚ŒãŸã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ—¥æ™‚
            
        Returns:
            float: å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©ç·Šæ€¥ï¼‰
        """
        try:
            if pd.isna(predicted_crash_date):
                return 0.0
            
            now = datetime.now()
            days_to_crash = (predicted_crash_date - now).days
            
            # æ—¥æ•°ã«åŸºã¥ãå„ªå…ˆåº¦ã‚¹ã‚³ã‚¢
            if days_to_crash <= 0:
                return 100  # æ—¢ã«éãã¦ã„ã‚‹å ´åˆã¯æœ€é«˜å„ªå…ˆåº¦
            elif days_to_crash <= 30:
                return 90   # 1ãƒ¶æœˆä»¥å†…
            elif days_to_crash <= 90:
                return 70   # 3ãƒ¶æœˆä»¥å†…
            elif days_to_crash <= 180:
                return 50   # 6ãƒ¶æœˆä»¥å†…
            elif days_to_crash <= 365:
                return 30   # 1å¹´ä»¥å†…
            else:
                return 10   # 1å¹´ä»¥ä¸Šå…ˆ
                
        except Exception:
            return 0.0
    
    def get_symbol_analysis_data(self, symbol: str, limit: int = 50, 
                                 period_selection: Optional[Dict] = None) -> pd.DataFrame:
        """Get analysis data for specific symbol with predicted crash dates"""
        try:
            analyses = self.db.get_recent_analyses(symbol=symbol, limit=limit)
            
            if analyses.empty:
                return pd.DataFrame()
            
            # Apply period filtering based on analysis basis date
            if period_selection:
                start_date = period_selection.get('start_date')
                end_date = period_selection.get('end_date')
                
                if start_date and end_date:
                    # Convert dates to datetime for filtering
                    start_datetime = pd.to_datetime(start_date)
                    end_datetime = pd.to_datetime(end_date) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)  # End of day
                    
                    # Filter based on analysis_basis_date (priority) or data_period_end (fallback)
                    filtered_analyses = []
                    for _, row in analyses.iterrows():
                        basis_date = None
                        if pd.notna(row.get('analysis_basis_date')):
                            basis_date = pd.to_datetime(row['analysis_basis_date'])
                        elif pd.notna(row.get('data_period_end')):
                            basis_date = pd.to_datetime(row['data_period_end'])
                        
                        if basis_date and start_datetime <= basis_date <= end_datetime:
                            filtered_analyses.append(row)
                    
                    if filtered_analyses:
                        analyses = pd.DataFrame(filtered_analyses)
                    else:
                        return pd.DataFrame()  # No data in selected period
            
            # Use database-stored predicted crash dates (no recalculation needed)
            # Convert string dates to datetime objects for processing
            if 'predicted_crash_date' in analyses.columns:
                analyses['predicted_crash_date'] = pd.to_datetime(analyses['predicted_crash_date'], errors='coerce')
            else:
                # Fallback: if column missing, create empty datetime column
                analyses['predicted_crash_date'] = pd.NaT
            
            # Calculate trading priority scores based on predicted dates
            analyses['trading_priority'] = analyses['predicted_crash_date'].apply(
                self.calculate_trading_priority_score
            )
            
            # Sort by analysis basis date (newest first) for temporal consistency
            # This ensures the chronological order is maintained after filtering
            basis_date_col = []
            for _, row in analyses.iterrows():
                if pd.notna(row.get('analysis_basis_date')):
                    basis_date_col.append(pd.to_datetime(row['analysis_basis_date']))
                elif pd.notna(row.get('data_period_end')):
                    basis_date_col.append(pd.to_datetime(row['data_period_end']))
                else:
                    basis_date_col.append(pd.NaT)
            
            analyses['sort_basis_date'] = basis_date_col
            analyses = analyses.sort_values('sort_basis_date', ascending=False)
            analyses = analyses.drop('sort_basis_date', axis=1)
            
            return analyses
            
        except Exception as e:
            st.error(f"Error retrieving analysis data: {str(e)}")
            return pd.DataFrame()
    
    def render_sidebar(self):
        """Render symbol selection sidebar with categorization"""
        
        with st.sidebar:
            st.title("ğŸ›ï¸ Symbol Selection")
            
            # Get available symbols from database
            try:
                all_analyses = self.db.get_recent_analyses(limit=1000)
                if all_analyses.empty:
                    st.warning("No analysis data available")
                    return None
                
                available_symbols = sorted(all_analyses['symbol'].unique().tolist())
            except Exception:
                st.error("Failed to load analysis data")
                return None
            
            # Get categorized symbols
            categorized_symbols = self.get_symbols_by_category()
            
            # Symbol selection with categories
            st.subheader("ğŸ“ˆ Select Symbol by Category")
            
            # Create category options
            category_options = ["All Symbols"] + list(categorized_symbols.keys())
            selected_category = st.selectbox(
                "Asset Category",
                category_options,
                format_func=lambda x: "All Symbols" if x == "All Symbols" 
                else categorized_symbols[x]["display_name"] if x in categorized_symbols 
                else x
            )
            
            # Filter symbols based on category
            if selected_category == "All Symbols":
                symbol_options = available_symbols
            else:
                category_symbols = [
                    s["symbol"] for s in categorized_symbols.get(selected_category, {}).get("symbols", [])
                ]
                symbol_options = [s for s in available_symbols if s in category_symbols]
            
            if not symbol_options:
                st.warning("No symbols available in selected category")
                return None
            
            # Symbol selection
            selected_symbol = st.selectbox(
                "Symbol",
                symbol_options,
                format_func=lambda x: f"{x} - {self.market_catalog.get('symbols', {}).get(x, {}).get('display_name', x)}"
            )
            
            # Display symbol info
            if selected_symbol in self.market_catalog.get("symbols", {}):
                symbol_info = self.market_catalog["symbols"][selected_symbol]
                
                st.subheader("ğŸ“Š Symbol Information")
                st.info(f"**{symbol_info.get('display_name', selected_symbol)}**")
                st.write(f"**Type**: {symbol_info.get('instrument_type', 'Unknown')}")
                st.write(f"**Asset Class**: {symbol_info.get('asset_class', 'Unknown')}")
                st.write(f"**Analysis Suitability**: {symbol_info.get('bubble_analysis_suitability', 'Unknown')}")
                
                if symbol_info.get('description'):
                    with st.expander("â„¹ï¸ Description"):
                        st.write(symbol_info['description'])
            
            # Display settings
            st.subheader("âš™ï¸ Display Settings")
            
            # åˆ†æåŸºæº–æ—¥ã®ç¯„å›²ã‚’å–å¾—
            try:
                all_analyses = self.db.get_recent_analyses(symbol=selected_symbol, limit=1000)
                if not all_analyses.empty:
                    # åˆ†æåŸºæº–æ—¥ã®å–å¾—ï¼ˆå„ªå…ˆé †ä½: analysis_basis_date > data_period_endï¼‰
                    basis_dates = []
                    for _, row in all_analyses.iterrows():
                        if pd.notna(row.get('analysis_basis_date')):
                            basis_dates.append(pd.to_datetime(row['analysis_basis_date']))
                        elif pd.notna(row.get('data_period_end')):
                            basis_dates.append(pd.to_datetime(row['data_period_end']))
                    
                    if basis_dates:
                        basis_dates = sorted(basis_dates)
                        min_date = basis_dates[0].date()
                        max_date = basis_dates[-1].date()
                        
                        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨ˆç®—
                        default_end = max_date
                        default_start = max(min_date, max_date - timedelta(days=120))  # 4ãƒ¶æœˆå‰
                        
                        # æœŸé–“é¸æŠUI
                        st.markdown("**ğŸ“… Analysis Period Selection**")
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            start_date = st.date_input(
                                "From (Fitting Basis Date)",
                                value=default_start,
                                min_value=min_date,
                                max_value=max_date,
                                help="Start date for analysis period (oldest fitting basis date to include)"
                            )
                        
                        with col2:
                            end_date = st.date_input(
                                "To (Fitting Basis Date)",
                                value=default_end,
                                min_value=min_date,
                                max_value=max_date,
                                help="End date for analysis period (newest fitting basis date to include)"
                            )
                        
                        # æ—¥ä»˜ç¯„å›²ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                        if start_date > end_date:
                            st.error("Start date must be earlier than end date")
                            start_date, end_date = default_start, default_end
                        
                        period_selection = {
                            'start_date': start_date,
                            'end_date': end_date
                        }
                    else:
                        st.warning("No valid basis dates found")
                        period_selection = None
                else:
                    st.warning("No analysis data for period selection")
                    period_selection = None
            except Exception as e:
                st.error(f"Error loading period data: {str(e)}")
                period_selection = None
            
            # Priority filtering
            priority_filter = st.selectbox(
                "Priority Filter",
                ["All", "High Priority (â‰¤90 days)", "Medium Priority (â‰¤180 days)", "Critical Only (â‰¤30 days)"],
                index=0
            )
            
            return selected_symbol, period_selection, priority_filter
    
    def get_symbol_price_data(self, symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """Get symbol price data from unified data client"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æœ€æ–°ã®åˆ†æçµæœã‚’å–å¾—ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ç‰¹å®š
            latest_analysis = self.db.get_recent_analyses(symbol=symbol, limit=1)
            preferred_source = None
            if not latest_analysis.empty:
                data_source = latest_analysis.iloc[0].get('data_source')
                if data_source:
                    preferred_source = 'fred' if data_source == 'fred' else 'alpha_vantage'
            
            # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãã§ãƒ‡ãƒ¼ã‚¿å–å¾—
            data, source_used = self.data_client.get_data_with_fallback(
                symbol, start_date, end_date, preferred_source=preferred_source
            )
            
            if data is not None and len(data) > 0:
                print(f"âœ… ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {symbol} ({source_used}) - {len(data)}æ—¥åˆ†")
                return data
            else:
                print(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {symbol}")
                return None
            
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def compute_extended_lppl_fit(self, prices: pd.Series, params: Dict, basis_date: pd.Timestamp, 
                                  target_date: pd.Timestamp) -> Dict:
        """Generate extended LPPL fit for Future Period display"""
        try:
            # å…ƒãƒ‡ãƒ¼ã‚¿ã®æœŸé–“
            data_start = prices.index[0]
            data_end = prices.index[-1]
            
            # Future Periodç”¨ã®æ—¥ä»˜ç¯„å›²ã‚’ç”Ÿæˆ
            future_dates = pd.date_range(start=basis_date, end=target_date, freq='D')
            future_dates = future_dates[future_dates > basis_date]  # åŸºæº–æ—¥ã¯é™¤å¤–
            
            if len(future_dates) == 0:
                return None
            
            # æ­£è¦åŒ–ã•ã‚ŒãŸæ™‚é–“è»¸ã‚’è¨ˆç®—
            total_days = (data_end - data_start).days
            future_days = [(date - data_start).days for date in future_dates]
            t_future = np.array(future_days) / total_days
            
            # LPPLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            tc = params['tc']
            beta = params['beta']
            omega = params['omega']
            phi = params['phi']
            A = params['A']
            B = params['B']
            C = params['C']
            
            # Future Periodç”¨ã®LPPLè¨ˆç®—
            tau_future = tc - t_future
            tau_power_beta = np.power(np.abs(tau_future), beta)
            
            with np.errstate(divide='ignore', invalid='ignore'):
                log_term = np.log(np.abs(tau_future))
                oscillation = np.cos(omega * log_term + phi)
            
            fitted_log_prices = A + B * tau_power_beta + C * tau_power_beta * oscillation
            fitted_prices = np.exp(fitted_log_prices)
            
            # æ­£è¦åŒ–ï¼ˆå…ƒã®ä¾¡æ ¼ç¯„å›²ãƒ™ãƒ¼ã‚¹ï¼‰
            price_min, price_max = prices.min(), prices.max()
            normalized_fitted = (fitted_prices - price_min) / (price_max - price_min)
            
            return {
                'future_dates': future_dates,
                'fitted_prices': fitted_prices,
                'normalized_fitted': normalized_fitted
            }
            
        except Exception as e:
            print(f"âš ï¸ Extended LPPL calculation error: {str(e)}")
            return None

    def compute_lppl_fit(self, prices: pd.Series, params: Dict) -> Dict:
        """Compute LPPL model fit and normalized data for visualization"""
        try:
            # ä¾¡æ ¼ã‚’å¯¾æ•°å¤‰æ›
            log_prices = np.log(prices)
            N = len(prices)
            
            # æ™‚é–“é…åˆ—ã‚’æ­£è¦åŒ–ï¼ˆ0-1ï¼‰
            t = np.linspace(0, 1, N)
            
            # LPPLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            tc = params['tc']
            beta = params['beta'] 
            omega = params['omega']
            phi = params['phi']
            A = params['A']
            B = params['B']
            C = params['C']
            
            # LPPLé–¢æ•°ã®è¨ˆç®—
            # log(p(t)) = A + B*(tc-t)^Î² + C*(tc-t)^Î² * cos(Ï‰*ln(tc-t) + Ï†)
            tau = tc - t
            tau_power_beta = np.power(np.abs(tau), beta)
            
            # è² ã®å€¤ã‚’é¿ã‘ã‚‹ãŸã‚ã«çµ¶å¯¾å€¤ã‚’ä½¿ç”¨
            with np.errstate(divide='ignore', invalid='ignore'):
                log_term = np.log(np.abs(tau))
                oscillation = np.cos(omega * log_term + phi)
                
            fitted_log_prices = A + B * tau_power_beta + C * tau_power_beta * oscillation
            fitted_prices = np.exp(fitted_log_prices)
            
            # æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®—ï¼ˆè«–æ–‡å†ç¾ãƒ†ã‚¹ãƒˆã®å³ä¸Šã‚°ãƒ©ãƒ•ç›¸å½“ï¼‰
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’0-1ã«æ­£è¦åŒ–
            price_min, price_max = prices.min(), prices.max()
            normalized_prices = (prices - price_min) / (price_max - price_min)
            normalized_fitted = (fitted_prices - price_min) / (price_max - price_min)
            
            return {
                'fitted_prices': fitted_prices,
                'fitted_log_prices': fitted_log_prices,
                'normalized_prices': normalized_prices,
                'normalized_fitted': normalized_fitted,
                'time_normalized': t
            }
            
        except Exception as e:
            st.error(f"LPPLè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def convert_tc_to_real_date(self, tc: float, data_start_date: str, data_end_date: str) -> datetime:
        """Convert tc value to actual prediction date"""
        try:
            start_dt = pd.to_datetime(data_start_date)
            end_dt = pd.to_datetime(data_end_date)
            
            # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®æ—¥æ•°ã‚’è¨ˆç®—
            total_days = (end_dt - start_dt).days
            
            # tcå€¤ã‚’å®Ÿéš›ã®æ—¥ä»˜ã«å¤‰æ›
            # tc > 1ã®å ´åˆã¯æœªæ¥ã®æ—¥ä»˜
            if tc > 1:
                days_beyond_end = (tc - 1) * total_days
                prediction_date = end_dt + timedelta(days=days_beyond_end)
            else:
                # tc < 1ã®å ´åˆã¯ãƒ‡ãƒ¼ã‚¿æœŸé–“å†…
                days_from_start = tc * total_days
                prediction_date = start_dt + timedelta(days=days_from_start)
            
            return prediction_date
            
        except Exception as e:
            st.error(f"æ—¥ä»˜å¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return datetime.now() + timedelta(days=30)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    def render_price_predictions_tab(self, symbol: str, analysis_data: pd.DataFrame):
        """Tab 1: LPPL Fitting Analysis - Overlays LPPL fits onto normalized market data for comprehensive analysis"""
        
        st.header(f"ğŸ“ˆ {symbol} - LPPL Fitting Analysis")
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã®ãƒ—ãƒ­ãƒƒãƒˆåˆ†å‰²ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        debug_mode = st.checkbox("ğŸ” Debug Mode: Split Integrated Plot into Two Separate Views", 
                                 value=False, 
                                 help="åˆ†æãƒ—ãƒ­ãƒƒãƒˆï¼šæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ç¢ºèªã€çµ±åˆãƒ—ãƒ­ãƒƒãƒˆï¼šæœŸé–“ç¯„å›²ã®è¤‡æ•°äºˆæ¸¬è¡¨ç¤º")
        
        if analysis_data.empty:
            st.warning("No analysis data available for this symbol")
            return
        
        # æœ€æ–°ã®åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        latest = analysis_data.iloc[0]
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # æœ€æ–°ã®äºˆæ¸¬ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ—¥ã‚’è¡¨ç¤ºï¼ˆtcå€¤ã‹ã‚‰å¤‰æ›ï¼‰
            if pd.notna(latest.get('tc')):
                tc = latest['tc']
                data_start = latest.get('data_period_start')
                data_end = latest.get('data_period_end')
                
                if data_start and data_end:
                    pred_date = self.convert_tc_to_real_date(tc, data_start, data_end)
                    st.metric(
                        "Latest Crash Prediction",
                        pred_date.strftime('%Y-%m-%d'),
                        help=f"Converted from tc={tc:.4f}"
                    )
                else:
                    st.metric("Latest Crash Prediction", "N/A")
            else:
                st.metric("Latest Crash Prediction", "N/A")
        
        with col2:
            st.metric(
                "Model Fit (RÂ²)",
                f"{latest['r_squared']:.4f}" if pd.notna(latest.get('r_squared')) else "N/A",
                help="Goodness of fit for LPPL model"
            )
        
        with col3:
            st.metric(
                "Quality",
                latest.get('quality', 'N/A'),
                help="Analysis quality assessment"
            )
        
        # æœ€æ–°ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        if pd.notna(latest.get('data_period_start')) and pd.notna(latest.get('data_period_end')):
            data_start = latest['data_period_start']
            data_end = latest['data_period_end']
            
            # Number of Resultsã‹ã‚‰é€†ç®—ã—ã¦ååˆ†ãªæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            # è¤‡æ•°ã®åˆ†æçµæœã®äºˆæ¸¬æ—¥ã¾ã§å«ã‚ã‚‹ãŸã‚ã€æœŸé–“ã‚’æ‹¡å¼µ
            max_pred_date = data_end
            for _, row in analysis_data.head(min(len(analysis_data), 10)).iterrows():
                if pd.notna(row.get('tc')):
                    row_start = row.get('data_period_start', data_start)
                    row_end = row.get('data_period_end', data_end)
                    if row_start and row_end:
                        pred_date = self.convert_tc_to_real_date(row.get('tc'), row_start, row_end)
                        if pred_date > pd.to_datetime(max_pred_date):
                            max_pred_date = pred_date.strftime('%Y-%m-%d')
            
            # Future Periodè¡¨ç¤ºã®ãŸã‚ã«ã•ã‚‰ã«æœŸé–“ã‚’æ‹¡å¼µï¼ˆäºˆæ¸¬æ—¥+60æ—¥ï¼‰
            max_pred_dt = pd.to_datetime(max_pred_date)
            extended_end = (max_pred_dt + timedelta(days=60)).strftime('%Y-%m-%d')
            print(f"ğŸ” Getting extended price data for {symbol}: {data_start} to {extended_end}")
            
            # å®Ÿéš›ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæ‹¡å¼µæœŸé–“ï¼‰
            price_data = self.get_symbol_price_data(symbol, data_start, extended_end)
            
            if price_data is not None and not price_data.empty and 'Close' in price_data.columns:
                print(f"âœ… Price data retrieved successfully: {len(price_data)} days for {symbol}")
                print(f"   Period: {price_data.index.min()} to {price_data.index.max()}")
                print(f"   Price range: ${price_data['Close'].min():.0f} - ${price_data['Close'].max():.0f}")
                # LPPLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                lppl_params = {
                    'tc': latest.get('tc', 1.0),
                    'beta': latest.get('beta', 0.33),
                    'omega': latest.get('omega', 6.0),
                    'phi': latest.get('phi', 0.0),
                    'A': latest.get('A', 0.0),
                    'B': latest.get('B', 0.0),
                    'C': latest.get('C', 0.0)
                }
                
                # LPPLãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚’è¨ˆç®—
                lppl_results = self.compute_lppl_fit(price_data['Close'], lppl_params)
                
                if lppl_results:
                    # è«–æ–‡å†ç¾ãƒ†ã‚¹ãƒˆå³ä¸Šã‚°ãƒ©ãƒ•ã«ç›¸å½“ã™ã‚‹æ­£è¦åŒ–è¡¨ç¤ºã‚’ä½œæˆ
                    fig = go.Figure()
                    
                    # æ­£è¦åŒ–ã•ã‚ŒãŸå®Ÿãƒ‡ãƒ¼ã‚¿
                    fig.add_trace(go.Scatter(
                        x=price_data.index,
                        y=lppl_results['normalized_prices'],
                        mode='lines',
                        name='Normalized Market Data',
                        line=dict(color='blue', width=2),
                        opacity=0.8
                    ))
                    
                    # æœ€æ–°ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°åŸºæº–æ—¥ã‚’å–å¾—
                    latest_fitting_basis = latest.get('analysis_basis_date', data_end)
                    latest_fitting_basis_dt = pd.to_datetime(latest_fitting_basis)
                    
                    # LPPLãƒ•ã‚£ãƒƒãƒˆï¼ˆåŸºæº–æ—¥ã¾ã§ï¼‰- æœ€æ–°ãƒ—ãƒ­ãƒƒãƒˆã®ã¿ã«é©ç”¨
                    basis_mask = price_data.index <= latest_fitting_basis_dt
                    fig.add_trace(go.Scatter(
                        x=price_data.index[basis_mask],
                        y=lppl_results['normalized_fitted'][basis_mask],
                        mode='lines',
                        name='LPPL Fit (Basis Period)',
                        line=dict(color='red', width=2.5)
                    ))
                    
                    # LPPLãƒ•ã‚£ãƒƒãƒˆï¼ˆåŸºæº–æ—¥ä»¥é™ï¼‰- Future Periodè¡¨ç¤º
                    # Individual Analysisã¨åŒã˜æ–¹å¼ã§å®Ÿè£…
                    if pd.notna(latest.get('tc')):
                        # Individual Analysisã¨åŒã˜æ–¹å¼ã§tcå¤‰æ›
                        integrated_pred_date = self.convert_tc_to_real_date(
                            latest['tc'], data_start, data_end)
                        
                        # Individual Analysisã¨åŒã˜æ–¹å¼ã§extended LPPLè¨ˆç®—
                        extended_lppl = self.compute_extended_lppl_fit(
                            price_data['Close'], lppl_params, 
                            latest_fitting_basis_dt, integrated_pred_date + timedelta(days=30))
                        
                        if extended_lppl and len(extended_lppl['future_dates']) > 0:
                            fig.add_trace(go.Scatter(
                                x=extended_lppl['future_dates'],
                                y=extended_lppl['normalized_fitted'],
                                mode='lines',
                                name='LPPL Fit (Future Period)',
                                line=dict(color='orange', width=2.5, dash='dot'),
                                opacity=0.8
                            ))
                        else:
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæº–æ—¥ä»¥é™ã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ã¿
                            future_mask = price_data.index > latest_fitting_basis_dt
                            if future_mask.any():
                                fig.add_trace(go.Scatter(
                                    x=price_data.index[future_mask],
                                    y=lppl_results['normalized_fitted'][future_mask],
                                    mode='lines',
                                    name='LPPL Fit (Future Period)',
                                    line=dict(color='orange', width=2.5, dash='dot')
                                ))
                    
                    # Number of Results ã§æŒ‡å®šã•ã‚ŒãŸæ•°ã®äºˆæ¸¬ç·šã‚’ç¸¦ç·šã§è¡¨ç¤º
                    # Analysis Period Selectionã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ã•ã‚ŒãŸanalysis_dataã®ä»¶æ•°ã‚’ä½¿ç”¨
                    display_count = len(analysis_data)  # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿å…¨ä»¶è¡¨ç¤º
                    
                    # ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°åŸºæº–æ—¥ã®å–å¾—ã¨ã‚½ãƒ¼ãƒˆï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
                    basis_dates = []
                    for _, pred in analysis_data.head(display_count).iterrows():
                        if pd.notna(pred.get('analysis_basis_date')):
                            basis_dates.append(pd.to_datetime(pred['analysis_basis_date']))
                        elif pd.notna(pred.get('data_period_end')):
                            basis_dates.append(pd.to_datetime(pred['data_period_end']))
                        else:
                            basis_dates.append(pd.to_datetime('1900-01-01'))  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    
                    # åŸºæº–æ—¥ã®ç¯„å›²ã‚’è¨ˆç®—ï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
                    if len([d for d in basis_dates if d.year > 1900]) > 1:
                        valid_dates = [d for d in basis_dates if d.year > 1900]
                        min_date = min(valid_dates)
                        max_date = max(valid_dates)
                        date_range = (max_date - min_date).days
                    else:
                        date_range = 0
                    
                    for i, (_, pred) in enumerate(analysis_data.head(display_count).iterrows()):
                        if pd.notna(pred.get('tc')):
                            pred_tc = pred['tc']
                            pred_start = pred.get('data_period_start', data_start)
                            pred_end = pred.get('data_period_end', data_end)
                            
                            if pred_start and pred_end:
                                pred_date = self.convert_tc_to_real_date(pred_tc, pred_start, pred_end)
                                
                                # ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°åŸºæº–æ—¥ã‚’å–å¾—
                                fitting_basis_date = basis_dates[i] if i < len(basis_dates) else pd.to_datetime('1900-01-01')
                                
                                # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è‰²ã®è¨ˆç®—ï¼ˆåŸºæº–æ—¥ãƒ™ãƒ¼ã‚¹ï¼‰
                                if date_range > 0 and fitting_basis_date.year > 1900:
                                    days_from_oldest = (fitting_basis_date - min_date).days
                                    gradient_ratio = days_from_oldest / date_range
                                    # å¤ã„äºˆæ¸¬ï¼šé’ç³»ã€æ–°ã—ã„äºˆæ¸¬ï¼šèµ¤ç³»
                                    red = int(50 + gradient_ratio * 200)  # 50-250
                                    green = int(50 + (1-gradient_ratio) * 100)  # 50-150
                                    blue = int(250 - gradient_ratio * 200)  # 50-250
                                    alpha = 0.8
                                else:
                                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è‰²
                                    red, green, blue = 255, 150, 150
                                    alpha = 0.7
                                
                                # äºˆæ¸¬ç·šã‚’ç¸¦ç·šã§è¡¨ç¤º
                                fig.add_shape(
                                    type="line",
                                    x0=pred_date,
                                    x1=pred_date,
                                    y0=0,
                                    y1=1,
                                    line=dict(
                                        color=f'rgba({red}, {green}, {blue}, {alpha})', 
                                        width=2, 
                                        dash="dash"
                                    )
                                )
                                
                                # äºˆæ¸¬ç·šã®ãƒ©ãƒ™ãƒ«ï¼ˆæœˆæ—¥ã®ã¿è¡¨ç¤ºï¼‰
                                label_text = pred_date.strftime('%m/%d')
                                fig.add_annotation(
                                    x=pred_date,
                                    y=0.95 - i * 0.05,
                                    text=label_text,
                                    showarrow=False,
                                    font=dict(size=10, color='white'),
                                    bgcolor=f"rgba(0, 0, 0, 0.7)",  # é»’ç³»èƒŒæ™¯
                                    bordercolor=f'rgba({red}, {green}, {blue}, 0.8)',
                                    borderwidth=1
                                )
                    
                    # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å‡¡ä¾‹ã‚’è¿½åŠ ï¼ˆæ•£å¸ƒå›³ã¨ã—ã¦è¡¨ç¤ºï¼‰
                    if date_range > 0 and len([d for d in basis_dates if d.year > 1900]) > 1:
                        # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
                        legend_dates = pd.date_range(min_date, max_date, periods=5)
                        legend_y = [0.85, 0.82, 0.79, 0.76, 0.73]  # Yåº§æ¨™
                        legend_colors = []
                        
                        for j, legend_date in enumerate(legend_dates):
                            days_from_oldest = (legend_date - min_date).days
                            gradient_ratio = days_from_oldest / date_range
                            red = int(50 + gradient_ratio * 200)
                            green = int(50 + (1-gradient_ratio) * 100)
                            blue = int(250 - gradient_ratio * 200)
                            legend_colors.append(f'rgb({red}, {green}, {blue})')
                        
                        # å‡¡ä¾‹ç”¨ã®æ•£å¸ƒå›³ã‚’è¿½åŠ 
                        fig.add_trace(go.Scatter(
                            x=[price_data.index.min()] * len(legend_dates),
                            y=legend_y,
                            mode='markers+text',
                            marker=dict(size=15, color=legend_colors),
                            text=[f"{date.strftime('%Y-%m')}: {(date-min_date).days}d" for date in legend_dates],
                            textposition='middle right',
                            textfont=dict(color='white', size=9),
                            showlegend=False,
                            hoverinfo='skip'
                        ))
                    
                    # ã‚°ãƒ©ãƒ•ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
                    fig.update_layout(
                        title=f"{symbol} - Normalized Price Data with LPPL Predictions",
                        xaxis_title="Date",
                        yaxis_title="Normalized Price",
                        height=600,
                        hovermode='x unified',
                        showlegend=True,
                        # èƒŒæ™¯è‰²ã‚’é»’ç³»ã«å¤‰æ›´
                        plot_bgcolor='rgba(20, 20, 30, 0.95)',
                        paper_bgcolor='rgba(15, 15, 25, 0.95)',
                        font=dict(color='white'),
                        # xè»¸ã®ç¯„å›²ã‚’äºˆæ¸¬ç·šã¾ã§æ‹¡å¼µ
                        xaxis=dict(
                            range=[
                                price_data.index.min(),
                                max(price_data.index.max(), 
                                    max([self.convert_tc_to_real_date(row.get('tc', 1.0), 
                                                                     row.get('data_period_start', data_start),
                                                                     row.get('data_period_end', data_end)) 
                                         for _, row in analysis_data.head(display_count).iterrows() 
                                         if pd.notna(row.get('tc'))], default=price_data.index.max()))
                            ],
                            gridcolor='rgba(100, 100, 100, 0.2)',
                            showgrid=True,
                            gridwidth=1
                        ),
                        yaxis=dict(
                            gridcolor='rgba(100, 100, 100, 0.2)',
                            showgrid=True,
                            gridwidth=1
                        )
                    )
                    
                    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼š2ã¤ã®ãƒ—ãƒ­ãƒƒãƒˆã‚’ç¸¦ä¸¦ã³ã§è¡¨ç¤º
                    st.markdown("---")
                    st.subheader("ğŸ“Š Analysis Views: Latest & Integrated Predictions")
                    
                    # Latest Analysis Detailsï¼ˆä¸Šéƒ¨ï¼‰- å¸¸ã«æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                    st.markdown("**ğŸ” Latest Analysis Details**")
                    st.caption("æœ€æ–°ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµæœã®è©³ç´°è¡¨ç¤ºï¼ˆæœŸé–“é¸æŠã«é–¢ä¿‚ãªãæœ€æ–°ãƒ‡ãƒ¼ã‚¿ï¼‰")
                    
                    # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ç„¡é–¢ä¿‚ã§æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    all_latest_analyses = self.db.get_recent_analyses(symbol=symbol, limit=1)
                    if not all_latest_analyses.empty:
                        absolute_latest = all_latest_analyses.iloc[0]
                    else:
                        absolute_latest = latest  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    
                    # æœ€æ–°åˆ†æãƒ—ãƒ­ãƒƒãƒˆä½œæˆï¼ˆabsolute_latestã‚’ä½¿ç”¨ï¼‰
                    latest_fig = go.Figure()
                    
                    # çµ¶å¯¾æœ€æ–°ãƒ‡ãƒ¼ã‚¿ç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨äºˆæ¸¬æ—¥ã‚’è¨ˆç®—
                    absolute_latest_data_start = absolute_latest.get('data_period_start')
                    absolute_latest_data_end = absolute_latest.get('data_period_end')
                    absolute_latest_fitting_basis = absolute_latest.get('analysis_basis_date', absolute_latest_data_end)
                    absolute_latest_fitting_basis_dt = pd.to_datetime(absolute_latest_fitting_basis)
                    
                    # çµ¶å¯¾æœ€æ–°ã®äºˆæ¸¬æ—¥è¨ˆç®—
                    if pd.notna(absolute_latest.get('tc')):
                        absolute_latest_pred_date = self.convert_tc_to_real_date(
                            absolute_latest['tc'], absolute_latest_data_start, absolute_latest_data_end)
                    else:
                        absolute_latest_pred_date = None
                    
                    # çµ¶å¯¾æœ€æ–°ç”¨ã®LPPLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                    absolute_latest_lppl_params = {
                        'tc': absolute_latest.get('tc', 1.0),
                        'beta': absolute_latest.get('beta', 0.33),
                        'omega': absolute_latest.get('omega', 6.0),
                        'phi': absolute_latest.get('phi', 0.0),
                        'A': absolute_latest.get('A', 0.0),
                        'B': absolute_latest.get('B', 0.0),
                        'C': absolute_latest.get('C', 0.0)
                    }
                    
                    # çµ¶å¯¾æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãprice_dataã¨LPPLçµæœã‚’å–å¾—
                    absolute_latest_price_data = self.get_symbol_price_data(symbol, absolute_latest_data_start, absolute_latest_data_end)
                    absolute_latest_lppl_results = None
                    latest_extended_lppl = None
                    
                    if absolute_latest_price_data is not None:
                        absolute_latest_lppl_results = self.compute_lppl_fit(absolute_latest_price_data['Close'], absolute_latest_lppl_params)
                        
                        if absolute_latest_lppl_results:
                            # çµ¶å¯¾æœ€æ–°ã®ç”Ÿãƒ‡ãƒ¼ã‚¿
                            latest_fig.add_trace(go.Scatter(
                                x=absolute_latest_price_data.index,
                                y=absolute_latest_lppl_results['normalized_prices'],
                                mode='lines',
                                name='Market Data',
                                line=dict(color='lightblue', width=2)
                            ))
                            
                            # çµ¶å¯¾æœ€æ–°ã®LPPLãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆåŸºæº–æ—¥ã¾ã§ï¼‰
                            basis_mask = absolute_latest_price_data.index <= absolute_latest_fitting_basis_dt
                            latest_fig.add_trace(go.Scatter(
                                x=absolute_latest_price_data.index[basis_mask],
                                y=absolute_latest_lppl_results['normalized_fitted'][basis_mask],
                                mode='lines',
                                name='LPPL Fit (Basis Period)',
                                line=dict(color='red', width=2.5)
                            ))
                            
                            # çµ¶å¯¾æœ€æ–°ã®LPPL Future Period
                            if absolute_latest_pred_date is not None:
                                latest_extended_lppl = self.compute_extended_lppl_fit(
                                    absolute_latest_price_data['Close'], absolute_latest_lppl_params, 
                                    absolute_latest_fitting_basis_dt, absolute_latest_pred_date + timedelta(days=30))
                    
                            # Future Periodè¡¨ç¤º
                            if latest_extended_lppl and len(latest_extended_lppl['future_dates']) > 0:
                                latest_fig.add_trace(go.Scatter(
                                    x=latest_extended_lppl['future_dates'],
                                    y=latest_extended_lppl['normalized_fitted'],
                                    mode='lines',
                                    name='LPPL Fit (Future Period)',
                                    line=dict(color='orange', width=2.5, dash='dot'),
                                    opacity=0.8
                                ))
                            
                            # çµ¶å¯¾æœ€æ–°ã®äºˆæ¸¬æ—¥ç¸¦ç·šï¼ˆæœ€å¾Œã«æç”»ã—ã¦Future Periodã‚ˆã‚Šä¸Šã«è¡¨ç¤ºï¼‰
                            if absolute_latest_pred_date is not None:
                                # Yè»¸ã®å®Ÿéš›ã®ç¯„å›²ã‚’è¨ˆç®—
                                y_min = absolute_latest_lppl_results['normalized_prices'].min()
                                y_max = absolute_latest_lppl_results['normalized_prices'].max()
                                
                                # LPPLãƒ•ã‚£ãƒƒãƒˆã®ç¯„å›²ã‚‚è€ƒæ…®
                                y_min = min(y_min, absolute_latest_lppl_results['normalized_fitted'].min())
                                y_max = max(y_max, absolute_latest_lppl_results['normalized_fitted'].max())
                                
                                # Future PeriodãŒã‚ã‚‹å ´åˆã¯ãã®ç¯„å›²ã‚‚è€ƒæ…®
                                if latest_extended_lppl and len(latest_extended_lppl['future_dates']) > 0:
                                    y_max = max(y_max, max(latest_extended_lppl['normalized_fitted']))
                                    y_min = min(y_min, min(latest_extended_lppl['normalized_fitted']))
                                
                                # å°‘ã—ä½™è£•ã‚’æŒãŸã›ã‚‹
                                y_range = y_max - y_min
                                y_min_extended = y_min - y_range * 0.02
                                y_max_extended = y_max + y_range * 0.02
                                
                                latest_fig.add_shape(
                                    type="line",
                                    x0=absolute_latest_pred_date, x1=absolute_latest_pred_date,
                                    y0=y_min_extended, y1=y_max_extended,
                                    line=dict(color='red', width=3, dash="dash"),  # èµ¤ç³»ã«å¤‰æ›´
                                    layer='above'  # ä»–ã®è¦ç´ ã‚ˆã‚Šä¸Šã«æç”»
                                )
                                latest_fig.add_annotation(
                                    x=absolute_latest_pred_date, 
                                    y=y_max_extended * 0.95,  # å®Ÿéš›ã®ç¯„å›²ã®ä¸Šéƒ¨ã«é…ç½®
                                    text=f"Latest Prediction\n{absolute_latest_pred_date.strftime('%m/%d')}",
                                    showarrow=False, font=dict(color='red', size=11),
                                    bgcolor="rgba(255, 200, 200, 0.3)"  # èµ¤ç³»ã®èƒŒæ™¯
                                )
                            
                            # Xè»¸ç¯„å›²ã‚’çµ¶å¯¾æœ€æ–°ã®äºˆæ¸¬æ—¥+30æ—¥ã¾ã§æ‹¡å¼µ
                            x_range_end = absolute_latest_pred_date + timedelta(days=30) if absolute_latest_pred_date else absolute_latest_price_data.index.max()
                            latest_fig.update_layout(
                                title="Latest Analysis (Most Recent - Absolute)",
                                height=400,
                                plot_bgcolor='rgba(20, 30, 40, 0.95)',
                                paper_bgcolor='rgba(15, 25, 35, 0.95)',
                                font=dict(color='white', size=10),
                                xaxis=dict(
                                    gridcolor='rgba(100, 100, 100, 0.2)',
                                    showgrid=True,
                                    gridwidth=1,
                                    range=[absolute_latest_price_data.index.min(), x_range_end]
                                ),
                                yaxis=dict(
                                    gridcolor='rgba(100, 100, 100, 0.2)',
                                    showgrid=True,
                                    gridwidth=1
                                )
                            )
                    
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆï¼‰
                    if len(latest_fig.data) == 0:
                        latest_fig.update_layout(
                            title="Latest Analysis - Data Not Available",
                            height=400,
                            plot_bgcolor='rgba(20, 30, 40, 0.95)',
                            paper_bgcolor='rgba(15, 25, 35, 0.95)',
                            font=dict(color='white', size=10)
                        )
                    
                    # Latest Analysis ãƒ—ãƒ­ãƒƒãƒˆã‚’è¡¨ç¤º
                    st.plotly_chart(latest_fig, use_container_width=True)
                    
                    # Integrated Predictionsï¼ˆçµ±åˆäºˆæ¸¬è¡¨ç¤ºï¼‰
                    st.markdown("**ğŸ“ˆ Integrated Predictions**")
                    st.caption("çµ±åˆäºˆæ¸¬è¡¨ç¤º - Latest AnalysisåŸºæº–ã«ã‚ˆã‚‹æœŸé–“å†…ã®å…¨äºˆæ¸¬æ—¥çµ±åˆ")
                    
                    # Latest AnalysisåŸºæº–ã§ã®æ–°ã—ã„Integrated Predictions
                    if absolute_latest_price_data is not None:
                        integrated_fig = go.Figure()
                        
                        # Latest AnalysisåŸºæº–ã§ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿
                        integrated_fig.add_trace(go.Scatter(
                            x=absolute_latest_price_data.index,
                            y=absolute_latest_lppl_results['normalized_prices'],
                            mode='lines',
                            name='Market Data (Latest Basis)',
                            line=dict(color='lightblue', width=2)
                        ))
                        
                        # æœŸé–“å†…ã®è¤‡æ•°äºˆæ¸¬æ—¥ã‚’åé›†ï¼ˆå¾Œã§æç”»ï¼‰
                        prediction_colors = ['red', 'orange', 'green', 'purple', 'brown', 'cyan', 'magenta', 'yellow', 'lime', 'pink']
                        prediction_count = 0
                        prediction_lines = []  # å¾Œã§æç”»ã™ã‚‹ãŸã‚ã®ç¸¦ç·šæƒ…å ±ã‚’ä¿å­˜
                        
                        for i, (_, analysis) in enumerate(analysis_data.iterrows()):
                            if pd.notna(analysis.get('tc')):
                                # å„åˆ†æã®äºˆæ¸¬æ—¥ã‚’è¨ˆç®—
                                analysis_data_start = analysis.get('data_period_start', absolute_latest_data_start)
                                analysis_data_end = analysis.get('data_period_end', absolute_latest_data_end)
                                analysis_pred_date = self.convert_tc_to_real_date(
                                    analysis['tc'], analysis_data_start, analysis_data_end)
                                
                                color = prediction_colors[prediction_count % len(prediction_colors)]
                                # ç¸¦ç·šæƒ…å ±ã‚’ä¿å­˜ï¼ˆå¾Œã§æç”»ï¼‰
                                prediction_lines.append({
                                    'date': analysis_pred_date,
                                    'color': color,
                                    'index': prediction_count
                                })
                                
                                prediction_count += 1
                        
                        # Latest AnalysisåŸºæº–ã§ã®LPPLãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
                        if absolute_latest_lppl_results:
                            # Basis Period
                            basis_mask = absolute_latest_price_data.index <= absolute_latest_fitting_basis_dt
                            integrated_fig.add_trace(go.Scatter(
                                x=absolute_latest_price_data.index[basis_mask],
                                y=absolute_latest_lppl_results['normalized_fitted'][basis_mask],
                                mode='lines',
                                name='LPPL Fit (Latest Basis)',
                                line=dict(color='red', width=2.5)
                            ))
                            
                            # Future Period
                            if latest_extended_lppl and len(latest_extended_lppl['future_dates']) > 0:
                                integrated_fig.add_trace(go.Scatter(
                                    x=latest_extended_lppl['future_dates'],
                                    y=latest_extended_lppl['normalized_fitted'],
                                    mode='lines',
                                    name='LPPL Fit (Future Period)',
                                    line=dict(color='orange', width=2.5, dash='dot'),
                                    opacity=0.8
                                ))
                        
                        # ç¸¦ç·šã‚’æœ€å¾Œã«æç”»ï¼ˆFuture Periodã‚ˆã‚Šä¸Šã«è¡¨ç¤ºï¼‰
                        if absolute_latest_lppl_results:
                            # Yè»¸ã®å®Ÿéš›ã®ç¯„å›²ã‚’è¨ˆç®—
                            y_min = absolute_latest_lppl_results['normalized_prices'].min()
                            y_max = absolute_latest_lppl_results['normalized_prices'].max()
                            y_min = min(y_min, absolute_latest_lppl_results['normalized_fitted'].min())
                            y_max = max(y_max, absolute_latest_lppl_results['normalized_fitted'].max())
                            
                            if latest_extended_lppl and len(latest_extended_lppl['future_dates']) > 0:
                                y_max = max(y_max, max(latest_extended_lppl['normalized_fitted']))
                                y_min = min(y_min, min(latest_extended_lppl['normalized_fitted']))
                            
                            y_range = y_max - y_min
                            y_min_extended = y_min - y_range * 0.02
                            y_max_extended = y_max + y_range * 0.02
                            
                            # ä¿å­˜ã—ãŸç¸¦ç·šæƒ…å ±ã‚’æç”»
                            for pred_info in prediction_lines:
                                integrated_fig.add_shape(
                                    type="line",
                                    x0=pred_info['date'], x1=pred_info['date'],
                                    y0=y_min_extended, y1=y_max_extended,
                                    line=dict(color=pred_info['color'], width=2, dash="dash"),
                                    layer='above'  # ä»–ã®è¦ç´ ã‚ˆã‚Šä¸Šã«æç”»
                                )
                                
                                # ãƒ©ãƒ™ãƒ«ã‚‚è¿½åŠ 
                                y_pos = y_max_extended * (0.95 - (pred_info['index'] % 10) * 0.03)
                                integrated_fig.add_annotation(
                                    x=pred_info['date'], 
                                    y=y_pos,
                                    text=f"P{pred_info['index']+1}: {pred_info['date'].strftime('%m/%d')}",
                                    showarrow=False, 
                                    font=dict(color=pred_info['color'], size=9),
                                    bgcolor="rgba(255, 255, 255, 0.7)"
                                )
                        
                        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
                        x_range_end = absolute_latest_pred_date + timedelta(days=60) if absolute_latest_pred_date else absolute_latest_price_data.index.max() + timedelta(days=30)
                        integrated_fig.update_layout(
                            title="Integrated Predictions (Latest Analysis Basis)",
                            height=400,
                            plot_bgcolor='rgba(20, 30, 40, 0.95)',
                            paper_bgcolor='rgba(15, 25, 35, 0.95)',
                            font=dict(color='white', size=10),
                            xaxis=dict(
                                gridcolor='rgba(100, 100, 100, 0.2)',
                                showgrid=True,
                                gridwidth=1,
                                range=[absolute_latest_price_data.index.min(), x_range_end]
                            ),
                            yaxis=dict(
                                gridcolor='rgba(100, 100, 100, 0.2)',
                                showgrid=True,
                                gridwidth=1
                            )
                        )
                        
                        st.plotly_chart(integrated_fig, use_container_width=True)
                        
                        # èª¬æ˜
                        st.info(f"ğŸ“Š Showing latest analysis basis with {prediction_count} integrated predictions from selected period")
                    
                    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼šè©³ç´°åˆ†æãƒ—ãƒ­ãƒƒãƒˆè¡¨ç¤º
                    if debug_mode:
                        st.markdown("---")
                        st.subheader("ğŸ” Debug Mode: Additional Detailed Analysis Plots")
                        
                        # Plot 1: æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°åˆ†æãƒ—ãƒ­ãƒƒãƒˆ
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("**ğŸ“Š Debug Plot 1: Alternative Latest View**")
                            st.caption("ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæœ€æ–°ãƒãƒ¼ã‚±ãƒƒãƒˆç”Ÿãƒ‡ãƒ¼ã‚¿ + æœ€æ–°LPPL + æœ€æ–°äºˆæ¸¬æ—¥ï¼ˆåˆ¥å®Ÿè£…ç¢ºèªï¼‰")
                            
                            latest_fig = go.Figure()
                            
                            # æœ€æ–°ã®ç”Ÿãƒ‡ãƒ¼ã‚¿
                            latest_fig.add_trace(go.Scatter(
                                x=price_data.index,
                                y=lppl_results['normalized_prices'],
                                mode='lines',
                                name='Latest Market Data',
                                line=dict(color='cyan', width=2)
                            ))
                            
                            # æœ€æ–°ã®LPPLãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆå…¨æœŸé–“ï¼‰
                            latest_fig.add_trace(go.Scatter(
                                x=price_data.index,
                                y=lppl_results['normalized_fitted'],
                                mode='lines',
                                name='Latest LPPL Fit (Full)',
                                line=dict(color='magenta', width=2.5)
                            ))
                            
                            # æœ€æ–°ã®äºˆæ¸¬æ—¥
                            if pd.notna(latest.get('tc')):
                                latest_pred_date = self.convert_tc_to_real_date(
                                    latest['tc'], data_start, data_end)
                                latest_fig.add_shape(
                                    type="line",
                                    x0=latest_pred_date, x1=latest_pred_date,
                                    y0=0, y1=1,
                                    line=dict(color='yellow', width=3, dash="solid")
                                )
                                latest_fig.add_annotation(
                                    x=latest_pred_date, y=0.9,
                                    text=f"Latest Prediction\n{latest_pred_date.strftime('%m/%d')}",
                                    showarrow=False, font=dict(color='yellow', size=12),
                                    bgcolor="rgba(255, 255, 0, 0.3)"
                                )
                            
                            latest_fig.update_layout(
                                title="Latest Analysis (Most Recent Fitting)",
                                height=400,
                                plot_bgcolor='rgba(20, 30, 20, 0.95)',
                                font=dict(color='white', size=10)
                            )
                            
                            st.plotly_chart(latest_fig, use_container_width=True)
                        
                        with col2:
                            st.markdown("**ğŸ“Š Debug Plot 2: Alternative Integration View**")
                            st.caption("ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæœŸé–“ç¯„å›²ãƒ‡ãƒ¼ã‚¿ + æœ€è¿‘LPPL + è¤‡æ•°äºˆæ¸¬æ—¥ï¼ˆåˆ¥å®Ÿè£…ç¢ºèªï¼‰")
                            
                            integration_fig = go.Figure()
                            
                            # æœŸé–“ç¯„å›²ã®ç”Ÿãƒ‡ãƒ¼ã‚¿
                            integration_fig.add_trace(go.Scatter(
                                x=price_data.index,
                                y=lppl_results['normalized_prices'],
                                mode='lines',
                                name='Period Market Data',
                                line=dict(color='lightblue', width=2)
                            ))
                            
                            # ã‚µã‚¤ãƒ‰ãƒãƒ¼æœŸé–“å†…ã®æœ€ã‚‚æœ€è¿‘ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
                            recent_analysis = analysis_data.iloc[0]  # æœ€ã‚‚æœ€è¿‘ã®ã‚‚ã®
                            if pd.notna(recent_analysis.get('tc')):
                                recent_params = {
                                    'tc': recent_analysis.get('tc', 1.0),
                                    'beta': recent_analysis.get('beta', 0.33),
                                    'omega': recent_analysis.get('omega', 6.0),
                                    'phi': recent_analysis.get('phi', 0.0),
                                    'A': recent_analysis.get('A', 0.0),
                                    'B': recent_analysis.get('B', 0.0),
                                    'C': recent_analysis.get('C', 0.0)
                                }
                                recent_lppl = self.compute_lppl_fit(price_data['Close'], recent_params)
                                
                                if recent_lppl:
                                    integration_fig.add_trace(go.Scatter(
                                        x=price_data.index,
                                        y=recent_lppl['normalized_fitted'],
                                        mode='lines',
                                        name='Recent Period LPPL Fit',
                                        line=dict(color='orange', width=2.5)
                                    ))
                            
                            # æœŸé–“å†…ã®è¤‡æ•°äºˆæ¸¬ç·š
                            display_count = min(len(analysis_data), 5)
                            for i, (_, pred) in enumerate(analysis_data.head(display_count).iterrows()):
                                if pd.notna(pred.get('tc')):
                                    pred_date = self.convert_tc_to_real_date(
                                        pred['tc'], pred.get('data_period_start', data_start), 
                                        pred.get('data_period_end', data_end))
                                    
                                    color_alpha = 0.8 - i * 0.15
                                    integration_fig.add_shape(
                                        type="line",
                                        x0=pred_date, x1=pred_date,
                                        y0=0, y1=1,
                                        line=dict(color=f'rgba(255, 100, 100, {color_alpha})', 
                                                 width=2, dash="dash")
                                    )
                            
                            integration_fig.update_layout(
                                title="Integration Analysis (Period Range)",
                                height=400,
                                plot_bgcolor='rgba(30, 20, 20, 0.95)',
                                font=dict(color='white', size=10)
                            )
                            
                            st.plotly_chart(integration_fig, use_container_width=True)
                        
                        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
                        with st.expander("ğŸ” Debug Information"):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.write("**Latest Analysis Info:**")
                                st.write(f"- Analysis Basis Date: {latest.get('analysis_basis_date', 'N/A')}")
                                st.write(f"- Data Period: {data_start} to {data_end}")
                                st.write(f"- TC Value: {latest.get('tc', 'N/A')}")
                                st.write(f"- Extended End: {extended_end}")
                                
                            with col2:
                                st.write("**Price Data Info:**")
                                st.write(f"- Price Data Range: {price_data.index.min()} to {price_data.index.max()}")
                                st.write(f"- Data Points: {len(price_data)}")
                                st.write(f"- Max Prediction Date: {max_pred_date}")
                    
                    # äºˆæ¸¬ã‚µãƒãƒªãƒ¼ã‚’è¡¨å½¢å¼ã§è¡¨ç¤º
                    st.subheader("ğŸ”® Prediction Summary")
                    
                    # è¡¨å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                    summary_data = []
                    valid_predictions = analysis_data.head(display_count)
                    
                    for i, (_, pred) in enumerate(valid_predictions.iterrows()):
                        if pd.notna(pred.get('tc')):
                            pred_tc = pred['tc']
                            pred_start = pred.get('data_period_start', data_start)
                            pred_end = pred.get('data_period_end', data_end)
                            
                            if pred_start and pred_end:
                                pred_date = self.convert_tc_to_real_date(pred_tc, pred_start, pred_end)
                                days_to_crash = (pred_date - datetime.now()).days
                                
                                # ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°åŸºæº–æ—¥ã‚’è¡¨ç¤º
                                fitting_basis = pred.get('analysis_basis_date', pred.get('data_period_end', 'N/A'))
                                if fitting_basis != 'N/A':
                                    fitting_basis_str = pd.to_datetime(fitting_basis).strftime('%Y-%m-%d')
                                else:
                                    fitting_basis_str = 'N/A'
                                
                                summary_data.append({
                                    'Fitting Basis Date': fitting_basis_str,
                                    'Predicted Crash Date': pred_date.strftime('%Y-%m-%d'),
                                    'Days to Crash': f"{days_to_crash:+d}",
                                    'tc Value': f"{pred_tc:.4f}",
                                    'Î² (Beta)': f"{pred.get('beta', 0):.4f}",
                                    'Ï‰ (Omega)': f"{pred.get('omega', 0):.2f}",
                                    'RÂ² Score': f"{pred.get('r_squared', 0):.4f}",
                                    'Quality': pred.get('quality', 'N/A')
                                })
                    
                    if summary_data:
                        # DataFrameã«å¤‰æ›ã—ã¦è¡¨ç¤º
                        summary_df = pd.DataFrame(summary_data)
                        st.dataframe(
                            summary_df,
                            use_container_width=True,
                            hide_index=True,
                            column_config={
                                "Fitting Basis Date": st.column_config.TextColumn("Fitting Basis Date", help="Date when the fitting was performed"),
                                "Predicted Crash Date": st.column_config.TextColumn("Predicted Crash Date", help="Date when crash is predicted"),
                                "Days to Crash": st.column_config.TextColumn("Days to Crash", help="Days from today to predicted crash"),
                                "tc Value": st.column_config.TextColumn("tc Value", help="Critical time parameter"),
                                "Î² (Beta)": st.column_config.TextColumn("Î² (Beta)", help="Critical exponent (typically ~0.33)"),
                                "Ï‰ (Omega)": st.column_config.TextColumn("Ï‰ (Omega)", help="Angular frequency of oscillations"),
                                "RÂ² Score": st.column_config.TextColumn("RÂ² Score", help="Goodness of fit (higher is better)"),
                                "Quality": st.column_config.TextColumn("Quality", help="Overall analysis quality assessment")
                            }
                        )
                        st.caption(f"ğŸ“Š Showing {len(summary_data)} prediction results from the selected analysis period")
                    else:
                        st.warning("No valid predictions found in the selected period")
                    
                    # å€‹åˆ¥ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµæœè¡¨ç¤ºæ©Ÿèƒ½ã‚’è¿½åŠ 
                    st.subheader("ğŸ“Š Individual Fitting Results")
                    
                    # è¡¨ç¤ºæ•°ã‚’çµ±åˆãƒ—ãƒ­ãƒƒãƒˆã¨ä¸€è‡´ã•ã›ã‚‹ï¼ˆAnalysis Period Selectionã¨é€£å‹•ï¼‰
                    individual_display_count = len(analysis_data)  # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿å…¨ä»¶è¡¨ç¤º
                    
                    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®ã§ä¸Šé™è¨­å®šï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿æ™‚ï¼‰
                    is_limited = individual_display_count > 20
                    if is_limited:
                        individual_display_count = 20
                        st.markdown(f"*Displaying latest {individual_display_count} results out of {len(analysis_data)} total analyses (performance optimization)*")
                        # ä¸Šéƒ¨ã«è­¦å‘Šè¡¨ç¤º
                        st.warning(f"âš ï¸ **Performance Note**: Showing the most recent {individual_display_count} individual analyses from the selected period for optimal performance. To view older analyses, please adjust the period selection in the sidebar.")
                    else:
                        st.markdown(f"*Displaying all {individual_display_count} individual analyses from the selected period*")
                    
                    st.caption("Each plot shows an individual analysis with its own fitting period and prediction")
                    
                    for i, (_, individual) in enumerate(analysis_data.head(individual_display_count).iterrows()):
                        if pd.notna(individual.get('tc')):
                            ind_tc = individual['tc']
                            ind_start = individual.get('data_period_start')
                            ind_end = individual.get('data_period_end')
                            
                            if ind_start and ind_end:
                                # ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°åŸºæº–æ—¥ã‚’å–å¾—
                                fitting_basis_date = individual.get('analysis_basis_date', ind_end)
                                fitting_basis_dt = pd.to_datetime(fitting_basis_date)
                                
                                st.markdown(f"---")
                                st.markdown(f"**Analysis #{i+1} - Fitting Basis: {fitting_basis_dt.strftime('%Y-%m-%d')}**")
                                
                                # ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿æµç”¨ï¼‰
                                individual_data = self.get_symbol_price_data(symbol, ind_start, ind_end)
                                
                                if individual_data is not None and not individual_data.empty and 'Close' in individual_data.columns:
                                    # LPPLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                                    individual_params = {
                                        'tc': individual.get('tc', 1.0),
                                        'beta': individual.get('beta', 0.33),
                                        'omega': individual.get('omega', 6.0),
                                        'phi': individual.get('phi', 0.0),
                                        'A': individual.get('A', 0.0),
                                        'B': individual.get('B', 0.0),
                                        'C': individual.get('C', 0.0)
                                    }
                                    
                                    # LPPLãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚’è¨ˆç®—
                                    individual_lppl = self.compute_lppl_fit(individual_data['Close'], individual_params)
                                    
                                    if individual_lppl:
                                        # å€‹åˆ¥ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
                                        individual_fig = go.Figure()
                                        
                                        # å®Ÿãƒ‡ãƒ¼ã‚¿
                                        individual_fig.add_trace(go.Scatter(
                                            x=individual_data.index,
                                            y=individual_lppl['normalized_prices'],
                                            mode='lines',
                                            name='Market Data',
                                            line=dict(color='lightblue', width=2)
                                        ))
                                        
                                        # LPPLãƒ•ã‚£ãƒƒãƒˆï¼ˆåŸºæº–æ—¥ã¾ã§ï¼‰
                                        basis_mask = individual_data.index <= fitting_basis_dt
                                        individual_fig.add_trace(go.Scatter(
                                            x=individual_data.index[basis_mask],
                                            y=individual_lppl['normalized_fitted'][basis_mask],
                                            mode='lines',
                                            name='LPPL Fit (Basis Period)',
                                            line=dict(color='red', width=2.5)
                                        ))
                                        
                                        # LPPLãƒ•ã‚£ãƒƒãƒˆï¼ˆåŸºæº–æ—¥ä»¥é™ï¼‰- æ‹¡å¼µç‰ˆFuture Period
                                        future_mask = individual_data.index > fitting_basis_dt
                                        
                                        # æ‹¡å¼µFuture Periodè¨ˆç®—
                                        individual_pred_date = self.convert_tc_to_real_date(ind_tc, ind_start, ind_end)
                                        extended_individual_lppl = self.compute_extended_lppl_fit(
                                            individual_data['Close'], individual_params, 
                                            fitting_basis_dt, individual_pred_date + timedelta(days=30))
                                        
                                        if extended_individual_lppl and len(extended_individual_lppl['future_dates']) > 0:
                                            # æ‹¡å¼µFuture Periodè¡¨ç¤º
                                            individual_fig.add_trace(go.Scatter(
                                                x=extended_individual_lppl['future_dates'],
                                                y=extended_individual_lppl['normalized_fitted'],
                                                mode='lines',
                                                name='LPPL Fit (Future Period)',
                                                line=dict(color='orange', width=2.5, dash='dot'),
                                                opacity=0.8
                                            ))
                                        elif future_mask.any():
                                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå…ƒã®Future Period
                                            individual_fig.add_trace(go.Scatter(
                                                x=individual_data.index[future_mask],
                                                y=individual_lppl['normalized_fitted'][future_mask],
                                                mode='lines',
                                                name='LPPL Fit (Future Period)',
                                                line=dict(color='orange', width=2.5, dash='dot')
                                            ))
                                        
                                        # äºˆæ¸¬ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ—¥ã®ç¸¦ç·šï¼ˆãƒ‡ãƒ¼ã‚¿ç¯„å›²å…¨ä½“ã«è¡¨ç¤ºï¼‰
                                        # Yè»¸ã®ç¯„å›²ã‚’å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã‚‹
                                        y_min = min(individual_lppl['normalized_prices'].min(), 
                                                   individual_lppl['normalized_fitted'].min())
                                        y_max = max(individual_lppl['normalized_prices'].max(), 
                                                   individual_lppl['normalized_fitted'].max())
                                        
                                        # Future Periodã®ãƒ‡ãƒ¼ã‚¿ã‚‚è€ƒæ…®
                                        if extended_individual_lppl and len(extended_individual_lppl['future_dates']) > 0:
                                            y_max = max(y_max, max(extended_individual_lppl['normalized_fitted']))
                                        
                                        # ç¸¦ç·šã‚’æœ€å¾Œã«æç”»ï¼ˆä»–ã®ãƒ—ãƒ­ãƒƒãƒˆã‚ˆã‚Šä¸Šã«è¡¨ç¤ºï¼‰
                                        individual_fig.add_shape(
                                            type="line",
                                            x0=individual_pred_date,
                                            x1=individual_pred_date,
                                            y0=y_min * 0.98,  # å°‘ã—ä¸‹ã‹ã‚‰
                                            y1=y_max * 1.02,  # å°‘ã—ä¸Šã¾ã§
                                            line=dict(color='rgba(255, 100, 100, 0.8)', width=3, dash="dash"),
                                            layer='above'  # ä»–ã®è¦ç´ ã‚ˆã‚Šä¸Šã«æç”»
                                        )
                                        
                                        individual_fig.add_annotation(
                                            x=individual_pred_date,
                                            y=0.9,
                                            text=individual_pred_date.strftime('%m/%d'),
                                            showarrow=False,
                                            font=dict(size=10, color='white'),
                                            bgcolor="rgba(0, 0, 0, 0.7)"
                                        )
                                        
                                        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆXè»¸ç¯„å›²ã‚’äºˆæ¸¬æ—¥+30æ—¥ã¾ã§æ‹¡å¼µï¼‰
                                        x_range_end = max(individual_data.index.max(), 
                                                        individual_pred_date + timedelta(days=30))
                                        individual_fig.update_layout(
                                            title=f"Individual Analysis - Fitted on {fitting_basis_dt.strftime('%Y-%m-%d')}",
                                            height=400,
                                            plot_bgcolor='rgba(20, 20, 30, 0.95)',
                                            paper_bgcolor='rgba(15, 15, 25, 0.95)',
                                            font=dict(color='white'),
                                            xaxis=dict(
                                                gridcolor='rgba(100, 100, 100, 0.2)',
                                                showgrid=True,
                                                gridwidth=1,
                                                range=[individual_data.index.min(), x_range_end]
                                            ),
                                            yaxis=dict(
                                                gridcolor='rgba(100, 100, 100, 0.2)',
                                                showgrid=True,
                                                gridwidth=1
                                            )
                                        )
                                        
                                        st.plotly_chart(individual_fig, use_container_width=True)
                                        
                                        # å€‹åˆ¥çµæœã®çµ±è¨ˆ
                                        col1, col2, col3, col4 = st.columns(4)
                                        with col1:
                                            st.metric("Predicted Crash", individual_pred_date.strftime('%Y-%m-%d'))
                                        with col2:
                                            st.metric("RÂ² Score", f"{individual.get('r_squared', 0):.4f}")
                                        with col3:
                                            st.metric("Quality", individual.get('quality', 'N/A'))
                                        with col4:
                                            st.metric("tc Value", f"{ind_tc:.4f}")
                                    else:
                                        st.error(f"LPPL calculation failed for analysis #{i+1}")
                                else:
                                    st.warning(f"Unable to retrieve data for analysis #{i+1}")
                    
                    # ä¸‹éƒ¨ã«ã‚‚è­¦å‘Šè¡¨ç¤ºï¼ˆ20ä»¶åˆ¶é™ãŒã‚ã‚‹å ´åˆï¼‰
                    if is_limited:
                        st.markdown("---")
                        st.warning(f"âš ï¸ **Performance Note**: You have reached the display limit of {individual_display_count} analyses. There are {len(analysis_data) - individual_display_count} additional older analyses available. To view these, please adjust the period selection in the sidebar to focus on a different time range.")
                else:
                    st.error("LPPL ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            else:
                # ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
                if price_data is None:
                    st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {symbol} ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    st.info(f"æœŸé–“: {data_start} ã‹ã‚‰ {data_end}")
                    st.info("UnifiedDataClientã®åˆæœŸåŒ–ã¾ãŸã¯APIèªè¨¼ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                elif price_data.empty:
                    st.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™: {symbol} ã®æŒ‡å®šæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                    st.info(f"æœŸé–“: {data_start} ã‹ã‚‰ {data_end}")
                elif 'Close' not in price_data.columns:
                    st.warning(f"âš ï¸ ä¾¡æ ¼åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {symbol} ãƒ‡ãƒ¼ã‚¿ã«'Close'åˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
                    st.info(f"åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(price_data.columns)}")
                else:
                    st.warning("â“ ä¸æ˜ãªãƒ‡ãƒ¼ã‚¿å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                    
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã‚‚è¡¨ç¤º
                st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±")
                st.json({
                    "Symbol": symbol,
                    "Data Source": latest.get('data_source', 'N/A'),
                    "Period Start": data_start,
                    "Period End": data_end,
                    "Data Points": latest.get('data_points', 'N/A'),
                    "Analysis Basis Date": latest.get('analysis_basis_date', 'N/A')
                })
        else:
            st.error("âŒ ãƒ‡ãƒ¼ã‚¿æœŸé–“æƒ…å ±ãŒä¸å®Œå…¨ã§ã™")
            st.info("data_period_start ã¾ãŸã¯ data_period_end ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            st.subheader("ğŸ“Š åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±")
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
            debug_info = {}
            for col in ['data_period_start', 'data_period_end', 'data_source', 'analysis_basis_date', 'data_points']:
                val = latest.get(col)
                debug_info[col] = str(val) if val is not None else "None"
            
            st.json(debug_info)
    
    def render_prediction_convergence_tab(self, symbol: str, analysis_data: pd.DataFrame):
        """Tab 2: Prediction Convergence Analysis"""
        
        st.header(f"ğŸ¯ {symbol} - Prediction Convergence Analysis")
        
        if analysis_data.empty:
            st.warning("No analysis data available for this symbol")
            return
        
        valid_data = analysis_data.dropna(subset=['predicted_crash_date'])
        
        if valid_data.empty:
            st.warning("No valid prediction data available")
            return
        
        # Add fitting_basis_date column to valid_data for multi-period analysis
        fitting_basis_dates_valid = []
        for _, row in valid_data.iterrows():
            # å„ªå…ˆé †ä½: analysis_basis_date > data_period_end > analysis_date
            for col in ['analysis_basis_date', 'data_period_end', 'data_end', 'end_date', 'analysis_date']:
                if col in valid_data.columns and pd.notna(row.get(col)):
                    fitting_basis_dates_valid.append(pd.to_datetime(row[col]))
                    break
            else:
                fitting_basis_dates_valid.append(pd.to_datetime(row.get('analysis_date', datetime.now())))
        
        valid_data = valid_data.copy()  # Make a copy to avoid modifying the original
        valid_data['fitting_basis_date'] = fitting_basis_dates_valid
        
        # Main scatter plot: Analysis date vs Predicted crash date
        st.subheader("ğŸ“Š Crash Prediction Convergence")
        
        fig = go.Figure()
        
        # Prepare data for plotting
        plot_data = valid_data.copy()
        
        # Get fitting basis dates (ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°åŸºæº–æ—¥ã‚’å„ªå…ˆçš„ã«å–å¾—)
        fitting_basis_dates = []
        for _, row in plot_data.iterrows():
            # å„ªå…ˆé †ä½: analysis_basis_date > data_period_end > analysis_date
            for col in ['analysis_basis_date', 'data_period_end', 'data_end', 'end_date', 'analysis_date']:
                if col in plot_data.columns and pd.notna(row.get(col)):
                    fitting_basis_dates.append(pd.to_datetime(row[col]))
                    break
            else:
                fitting_basis_dates.append(pd.to_datetime(row.get('analysis_date', datetime.now())))
        
        plot_data['fitting_basis_date'] = fitting_basis_dates
        
        # Convert predicted crash dates
        crash_dates = []
        for date in plot_data['predicted_crash_date']:
            if hasattr(date, 'to_pydatetime'):
                crash_dates.append(date.to_pydatetime())
            else:
                crash_dates.append(date)
        plot_data['crash_date_converted'] = crash_dates
        
        # ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°åŸºæº–æ—¥ã‹ã‚‰äºˆæ¸¬ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ—¥ã¾ã§ã®æ—¥æ•°ã‚’è¨ˆç®—
        hover_texts = []
        for _, row in plot_data.iterrows():
            fitting_basis_date = row['fitting_basis_date']
            crash_date = row['crash_date_converted']
            
            # åŸºæº–æ—¥ã‹ã‚‰ã‚¯ãƒ©ãƒƒã‚·ãƒ¥äºˆæƒ³æ—¥ã¾ã§ã®æ—¥æ•°ã‚’è¨ˆç®—
            days_to_crash = (crash_date - fitting_basis_date).days
            
            hover_text = (f"Days to Crash: {days_to_crash} days<br>"
                         f"RÂ²: {row['r_squared']:.3f}<br>"
                         f"Quality: {row['quality']}")
            hover_texts.append(hover_text)
        
        # Color by RÂ² score
        fig.add_trace(go.Scatter(
            x=plot_data['fitting_basis_date'],
            y=plot_data['crash_date_converted'],
            mode='markers',
            marker=dict(
                size=10,
                color=plot_data['r_squared'],
                colorscale='Viridis',
                showscale=True,
                colorbar=dict(title="RÂ² Score")
            ),
            text=hover_texts,
            hovertemplate='Fitting Basis Date: %{x}<br>Predicted Crash: %{y}<br>%{text}<extra></extra>',
            name='Predictions'
        ))
        
        # Add y=x reference line (predictions that match fitting date)
        x_range = [plot_data['fitting_basis_date'].min(), plot_data['fitting_basis_date'].max()]
        y_range = [plot_data['crash_date_converted'].min(), plot_data['crash_date_converted'].max()]
        
        # Extend the line to cover the full plot range
        line_start = min(x_range[0], y_range[0])
        line_end = max(x_range[1], y_range[1])
        
        # Always add the y=x line
        fig.add_trace(go.Scatter(
            x=[line_start, line_end],
            y=[line_start, line_end],
            mode='lines',
            line=dict(color='lightblue', width=1, dash='solid'),  # é’ç³»ã€ç´°ç·šã€å®Ÿç·š
            name='y=x (Same Day Prediction)',
            hovertemplate='Same Day Prediction Line<br>Prediction Date = Fitting Date<extra></extra>',
            showlegend=True,
            legendgroup='reference',
            legendrank=1000  # Put at the end of legend
        ))
        
        fig.update_layout(
            title=f"{symbol} - Prediction Convergence Analysis",
            xaxis_title="Fitting Basis Date",
            yaxis_title="Predicted Crash Date",
            height=600,
            hovermode='closest'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Multi-period convergence analysis
        st.subheader("ğŸ“ˆ Multi-Period Convergence Analysis")
        st.caption("Convergence analysis for **fixed time periods** with multiple methods")
        
        # é‡è¦ãªåŒºåˆ¥ã®èª¬æ˜
        with st.expander("ğŸ“‹ **Important**: Difference from Main Scatter Plot"):
            st.markdown("""
            **ğŸ” Main Scatter Plot (above)**:
            - **Follows sidebar period selection** (Analysis Period Selection)
            - Shows data filtered by your selected date range
            - **Dynamic**: Changes when you adjust sidebar settings
            
            **ğŸ“Š Multi-Period Convergence Analysis (below)**:
            - **Uses fixed periods** (1 Month, 3 Months, etc.)
            - **Independent from sidebar selection**
            - Each tab shows exactly the specified lookback period from today
            - **Consistent**: Always shows the same fixed time window
            
            **âš¡ Purpose**: This allows you to compare convergence across standardized time windows regardless of your current sidebar settings.
            """)
        
        # Define analysis periods (fixed periods only) - 3 Months first for default
        analysis_periods = {
            "3 Months": 90,
            "1 Month": 30,
            "6 Months": 180,
            "1 Year": 365,
            "2 Years": 730
        }
        
        # Create tabs for different periods (3 Months will be selected by default)
        period_tabs = st.tabs(list(analysis_periods.keys()))
        
        for tab_idx, (period_name, days) in enumerate(analysis_periods.items()):
            with period_tabs[tab_idx]:
                # Fixed period analysis (independent from sidebar selection)
                cutoff_date = datetime.now() - timedelta(days=days)
                period_data = valid_data[valid_data['fitting_basis_date'] >= cutoff_date].copy()
                
                # æœŸé–“ã®èª¬æ˜ã‚’æ˜ç¢ºåŒ–
                start_date_str = cutoff_date.strftime('%Y-%m-%d')
                end_date_str = datetime.now().strftime('%Y-%m-%d')
                st.info(f"**Fixed Period Analysis**: Latest {period_name} ({len(period_data)} analyses)")
                st.caption(f"ğŸ“… **Analysis Period**: {start_date_str} to {end_date_str} (fitting basis dates)")
                st.caption(f"âš ï¸ **Note**: This analysis is **independent** from sidebar period selection - uses fixed {period_name} lookback")
                
                if len(period_data) < 3:
                    st.warning(f"âš ï¸ **Insufficient data** for convergence analysis ({len(period_data)} analyses). Need at least 3.")
                    
                    # ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å ´åˆã®èª¬æ˜ã¨ä»£æ›¿æ¡ˆ
                    if len(period_data) > 0:
                        latest_fitting_date = period_data['fitting_basis_date'].max()
                        st.info(f"ğŸ“Š **Available data**: {len(period_data)} analyses (latest: {latest_fitting_date.strftime('%Y-%m-%d')})")
                        st.info("ğŸ’¡ **Suggestion**: Try a longer period (e.g., 3 Months or 6 Months) for sufficient data")
                    else:
                        st.info("ğŸ“Š **No data** available for this period")
                        st.info("ğŸ’¡ **Suggestion**: Check if analyses exist in the database or try a different time period")
                    
                    # å¯¾ç…§ã¨ã—ã¦ã€å…¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿é‡ã‚’è¡¨ç¤º
                    st.info(f"ğŸ“ˆ **Total available**: {len(valid_data)} analyses in database")
                    continue
                
                # Calculate convergence metrics using multiple methods
                convergence_results = self.calculate_multi_method_convergence(period_data)
                
                # ğŸ¯ åæŸã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æœ€ä¸Šéƒ¨ã«å¤§ããè¡¨ç¤º
                convergence_status = convergence_results['convergence_status']
                status_colors = {
                    'Excellent': 'ğŸŸ¢',
                    'Good': 'ğŸ”µ', 
                    'Moderate': 'ğŸŸ¡',
                    'Poor': 'ğŸ”´',
                    'Error': 'âš«'
                }
                status_icon = status_colors.get(convergence_status, 'â“')
                
                st.markdown(f"### {status_icon} **Convergence Status: {convergence_status}**")
                
                # ç°¡æ½”ãªèª¬æ˜ã‚’è¿½åŠ 
                if convergence_status == 'Excellent':
                    st.success(f"âœ… **Highly convergent** - Std Dev: {convergence_results['std_deviation']:.1f} days, CV: {convergence_results['coefficient_variation']:.3f}")
                elif convergence_status == 'Good':
                    st.info(f"âœ… **Good convergence** - Std Dev: {convergence_results['std_deviation']:.1f} days, CV: {convergence_results['coefficient_variation']:.3f}")
                elif convergence_status == 'Moderate':
                    st.warning(f"âš ï¸ **Moderate convergence** - Std Dev: {convergence_results['std_deviation']:.1f} days, CV: {convergence_results['coefficient_variation']:.3f}")
                else:  # Poor or Error
                    st.error(f"âŒ **Poor/No convergence** - Std Dev: {convergence_results['std_deviation']:.1f} days, CV: {convergence_results['coefficient_variation']:.3f}")
                
                # ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹äºˆæ¸¬æ—¥ã‚‚ç›®ç«‹ã¤ä½ç½®ã«è¡¨ç¤º
                st.markdown(f"ğŸ¯ **Consensus Crash Date**: **{convergence_results['consensus_date'].strftime('%Y-%m-%d')}**")
                
                # Display detailed convergence results
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**ğŸ“Š Convergence Metrics**")
                    
                    # Standard deviation method
                    st.metric(
                        "Standard Deviation (Days)", 
                        f"{convergence_results['std_deviation']:.1f}",
                        help="Lower values indicate better convergence"
                    )
                    
                    # Coefficient of variation
                    st.metric(
                        "Coefficient of Variation", 
                        f"{convergence_results['coefficient_variation']:.3f}",
                        help="Standard deviation / mean. Lower values indicate better convergence"
                    )
                    
                    # Range method
                    st.metric(
                        "Prediction Range (Days)", 
                        f"{convergence_results['prediction_range']:.0f}",
                        help="Difference between max and min predictions"
                    )
                    
                
                with col2:
                    st.markdown("**ğŸ¯ Advanced Metrics**")
                    
                    # Weighted convergence (recent data weighted more)
                    st.metric(
                        "Weighted Std Dev (Days)", 
                        f"{convergence_results['weighted_std']:.1f}",
                        help="Recent analyses weighted more heavily"
                    )
                    
                    # Trend analysis
                    trend_slope = convergence_results['trend_slope']
                    trend_direction = "Stabilizing" if abs(trend_slope) < 0.1 else ("Converging" if trend_slope < 0 else "Diverging")
                    st.metric(
                        "Trend Direction", 
                        trend_direction,
                        delta=f"{trend_slope:.3f} days/analysis",
                        help="Negative slope = converging, Positive = diverging"
                    )
                    
                    # RÂ² of trend
                    st.metric(
                        "Trend Consistency (RÂ²)", 
                        f"{convergence_results['trend_r_squared']:.3f}",
                        help="How consistently predictions are trending"
                    )
                    
                    # Most probable crash date
                    st.metric(
                        "Consensus Crash Date",
                        convergence_results['consensus_date'].strftime('%Y-%m-%d'),
                        help="Weighted average of recent predictions"
                    )
                
                # Convergence visualization for this period
                st.markdown(f"**ğŸ“Š {period_name} Convergence Plot**")
                
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
                if len(period_data) == 0:
                    st.warning(f"No data available for {period_name} plot")
                else:
                    st.info(f"Generating plot with {len(period_data)} data points")
                
                period_fig = self.create_convergence_plot(period_data, period_name, convergence_results)
                
                # ãƒ—ãƒ­ãƒƒãƒˆãŒç©ºã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
                if len(period_fig.data) == 0:
                    st.error(f"âš ï¸ Plot generation failed for {period_name}. Check data availability.")
                    st.info("Possible causes: Missing 'fitting_basis_date' or 'predicted_crash_date' columns in data")
                else:
                    st.plotly_chart(period_fig, use_container_width=True)
                
                # Method explanations
                with st.expander(f"ğŸ“Š {period_name} Analysis Methods"):
                    st.markdown(f"""
                    **Convergence Analysis Methods for {period_name}:**
                    
                    1. **Standard Deviation Method**: 
                       - Calculates std dev of crash predictions
                       - Lower values = better convergence
                       - Current: {convergence_results['std_deviation']:.1f} days
                    
                    2. **Coefficient of Variation**: 
                       - Normalized measure (std dev / mean)
                       - Accounts for different prediction ranges
                       - Current: {convergence_results['coefficient_variation']:.3f}
                    
                    3. **Weighted Analysis**:
                       - Recent predictions weighted more heavily
                       - Uses exponential decay weighting
                       - Weighted Std Dev: {convergence_results['weighted_std']:.1f} days
                    
                    4. **Trend Analysis**:
                       - Linear regression of predictions over time
                       - Slope: {convergence_results['trend_slope']:.3f} days/analysis
                       - RÂ²: {convergence_results['trend_r_squared']:.3f}
                    
                    **Convergence Status Criteria:**
                    - **Excellent**: Std Dev < 5 days, CV < 0.05
                    - **Good**: Std Dev < 10 days, CV < 0.10  
                    - **Moderate**: Std Dev < 20 days, CV < 0.20
                    - **Poor**: Above moderate thresholds
                    
                    **Data Quality**: {len(period_data)} analyses, RÂ² range: {period_data['r_squared'].min():.3f} - {period_data['r_squared'].max():.3f}
                    """)
        
        # Analysis explanation
        with st.expander("ğŸ“Š Chart Explanation"):
            st.markdown("""
            **Purpose**: Analyze whether crash predictions are converging to a specific date
            
            **Interpretation**:
            - **Horizontal axis**: Fitting basis date (final day of data used for fitting)
            - **Vertical axis**: Predicted crash date from that analysis
            - **Color intensity**: RÂ² score (darker = better fit)
            - **Hover info**: Shows days from fitting basis to predicted crash
            
            **Convergence patterns**:
            - **Converging predictions**: Points form a horizontal line â†’ consistent crash date
            - **Diverging predictions**: Points spread vertically â†’ unstable predictions
            - **Trend analysis**: Look for patterns as fitting basis dates progress
            """)
        
    
    def render_parameters_tab(self, symbol: str, analysis_data: pd.DataFrame):
        """Tab 3: Parameter Details Table"""
        
        st.header(f"ğŸ“‹ {symbol} - Parameter Details")
        
        if analysis_data.empty:
            st.warning("No analysis data available for this symbol")
            return
        
        # Prepare detailed parameter table
        display_df = analysis_data.copy()
        
        # Add formatted predicted crash date
        if 'predicted_crash_date' in display_df.columns:
            display_df['predicted_crash_date_formatted'] = display_df['predicted_crash_date'].apply(
                lambda x: x.strftime('%Y-%m-%d %H:%M') if pd.notna(x) else 'N/A'
            )
        else:
            display_df['predicted_crash_date_formatted'] = 'N/A'
        
        # Add fitting basis date (ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°åŸºæº–æ—¥) - most important date
        if 'analysis_basis_date' in display_df.columns:
            display_df['fitting_basis_date_formatted'] = display_df['analysis_basis_date'].apply(
                lambda x: pd.to_datetime(x).strftime('%Y-%m-%d') if pd.notna(x) else 'N/A'
            )
        elif 'data_period_end' in display_df.columns:
            # Fallback to data period end
            display_df['fitting_basis_date_formatted'] = display_df['data_period_end'].apply(
                lambda x: pd.to_datetime(x).strftime('%Y-%m-%d') if pd.notna(x) else 'N/A'
            )
        else:
            display_df['fitting_basis_date_formatted'] = 'N/A'
        
        # Calculate data period (number of days used for fitting)
        data_period_days = []
        for _, row in display_df.iterrows():
            try:
                # Priority 1: Use window_days if available
                if 'window_days' in display_df.columns and pd.notna(row.get('window_days')):
                    days = int(row['window_days'])
                    data_period_days.append(f"{days} days")
                # Priority 2: Calculate from start and end dates
                elif ('data_period_start' in display_df.columns and 'data_period_end' in display_df.columns and
                      pd.notna(row.get('data_period_start')) and pd.notna(row.get('data_period_end'))):
                    start_dt = pd.to_datetime(row['data_period_start'])
                    end_dt = pd.to_datetime(row['data_period_end'])
                    days = (end_dt - start_dt).days + 1  # +1 to include both start and end
                    data_period_days.append(f"{days} days")
                # Priority 3: Use data_points as fallback
                elif 'data_points' in display_df.columns and pd.notna(row.get('data_points')):
                    points = int(row['data_points'])
                    data_period_days.append(f"{points} days")
                else:
                    data_period_days.append('N/A')
                    
            except Exception:
                data_period_days.append('N/A')
        
        display_df['data_period_days'] = data_period_days
        
        # Define column priority for display (left to right)
        priority_columns = [
            'predicted_crash_date_formatted',  # Most important
            'fitting_basis_date_formatted',    # ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°åŸºæº–æ—¥ (replaces analysis_date)
            'data_period_days',                # Number of days (replaces data_period)
            'r_squared',
            'quality',                         # Quality and Confidence together
            'confidence',
            'tc',
            'beta', 'omega', 'phi',
            'A', 'B', 'C',
            'rmse'
        ]
        
        # Select existing columns in priority order
        existing_columns = [col for col in priority_columns if col in display_df.columns]
        
        final_df = display_df[existing_columns].copy()
        
        # Sort by fitting basis date (most recent first - analysis_basis_date)
        sort_col = None
        if 'analysis_basis_date' in analysis_data.columns:
            sort_col = 'analysis_basis_date'
        elif 'data_period_end' in analysis_data.columns:
            sort_col = 'data_period_end'
        elif 'predicted_crash_date' in analysis_data.columns:
            sort_col = 'predicted_crash_date'
        
        if sort_col:
            final_df = final_df.loc[analysis_data.sort_values(sort_col, na_position='last', ascending=False).index]
        
        # Format numeric columns
        numeric_columns = ['r_squared', 'confidence', 'tc', 'beta', 'omega', 'phi', 'A', 'B', 'C', 'rmse']
        for col in numeric_columns:
            if col in final_df.columns:
                final_df[col] = final_df[col].apply(
                    lambda x: f"{x:.4f}" if pd.notna(x) else 'N/A'
                )
        
        # Display the table
        st.subheader("ğŸ“Š Analysis Results (sorted by fitting basis date)")
        
        st.dataframe(
            final_df,
            use_container_width=True,
            height=400,
            column_config={
                "predicted_crash_date_formatted": st.column_config.TextColumn(
                    "ğŸ¯ Predicted Crash Date",
                    help="Predicted crash date/time converted from tc ratio",
                    width="large"
                ),
                "fitting_basis_date_formatted": st.column_config.TextColumn(
                    "ğŸ“… Fitting Basis Date",
                    help="ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°åŸºæº–æ—¥ - Final day of fitting period (most important for sorting)",
                    width="medium"
                ),
                "data_period_days": st.column_config.TextColumn(
                    "ğŸ“Š Data Period",
                    help="Number of days used for fitting analysis",
                    width="small"
                ),
                "r_squared": st.column_config.TextColumn(
                    "ğŸ“Š RÂ² Score",
                    help="Model fit quality (higher = better, 0-1 scale)"
                ),
                "quality": st.column_config.TextColumn(
                    "ğŸ¯ Quality",
                    help="Analysis quality assessment (high_quality/acceptable/poor)"
                ),
                "confidence": st.column_config.TextColumn(
                    "âœ… Confidence",
                    help="Prediction confidence level (0-1 scale, similar to Quality)"
                ),
                "tc": st.column_config.TextColumn(
                    "ğŸ”¢ tc Ratio",
                    help="Critical time ratio used for crash prediction"
                )
            }
        )
        
        # Explanatory text for Quality and Confidence metrics
        st.subheader("ğŸ“– Metric Definitions")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **ğŸ¯ Quality Assessment:**
            - `high_quality`: RÂ² > 0.85, stable parameters
            - `acceptable`: RÂ² > 0.60, reasonable fit  
            - `poor`: RÂ² < 0.60, unstable fitting
            
            Quality is determined by statistical criteria including RÂ² score, parameter stability, and fitting convergence.
            """)
        
        with col2:
            st.markdown("""
            **âœ… Confidence Level:**
            - Range: 0.0 - 1.0 (higher = more confident)
            - Based on: fitting quality, parameter consistency
            - Similar to Quality but expressed as continuous value
            
            Confidence represents the overall reliability of the LPPL model prediction for this analysis.
            """)
        
        # Summary statistics
        st.subheader("ğŸ“ˆ Summary Statistics")
        
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            highest_r2 = analysis_data['r_squared'].max()
            st.metric("Highest RÂ²", f"{highest_r2:.3f}" if pd.notna(highest_r2) else "N/A")
        
        with col2:
            avg_r2 = analysis_data['r_squared'].mean()
            st.metric("Average RÂ²", f"{avg_r2:.3f}" if pd.notna(avg_r2) else "N/A")
        
        with col3:
            high_quality_count = len(analysis_data[analysis_data['quality'] == 'high_quality'])
            st.metric("High Quality", f"{high_quality_count}/{len(analysis_data)}")
        
        with col4:
            valid_predictions = len(analysis_data.dropna(subset=['predicted_crash_date']))
            st.metric("Valid Predictions", f"{valid_predictions}/{len(analysis_data)}")
        
        with col5:
            if 'predicted_crash_date' in analysis_data.columns:
                future_predictions = len(analysis_data[
                    analysis_data['predicted_crash_date'] > datetime.now()
                ])
                st.metric("Future Predictions", future_predictions)
        
        # Reference information from Sornette paper reproduction
        st.subheader("ğŸ“š Reference: Sornette Paper Reproduction")
        
        with st.expander("ğŸ¯ 1987 Black Monday Paper Reproduction Results"):
            st.markdown("""
            **Historical Crash Validation Results** (from our 100/100 score reproduction):
            
            ğŸ“Š **1987 Black Monday LPPL Analysis**:
            - **Paper Reproduction Score**: 100/100 âœ…
            - **RÂ² Range**: Typically 0.85-0.95 for high-quality fits
            - **Î² (Beta) Parameter**: ~0.33 (critical exponent from theory)
            - **Ï‰ (Omega) Parameter**: ~6-8 (log-periodic oscillation frequency)
            - **Data Period**: 706 days pre-crash analysis
            - **Total Return**: +65.2% (bubble formation criteria met)
            - **Peak Return**: +85.1% (accelerating growth confirmed)
            - **Crash Magnitude**: -28.2% (major crash threshold exceeded)
            
            ğŸ“– **Interpretation Guidelines**:
            - **RÂ² > 0.8**: Excellent fit quality (paper-level accuracy)
            - **RÂ² 0.6-0.8**: Good fit quality (acceptable for analysis)
            - **RÂ² < 0.6**: Lower confidence (use with caution)
            - **Î² â‰ˆ 0.33**: Theoretical expectation from critical phenomena
            - **Ï‰ = 6-8**: Optimal log-periodic frequency range
            
            ğŸ”¬ **Scientific Validation**:
            - Our implementation achieves **identical results** to published paper
            - All parameters fall within theoretical bounds
            - Crash prediction accuracy validated historically
            
            ğŸ“‹ **Quality Benchmarks**:
            - **High Quality**: RÂ² > 0.8, Î² = 0.2-0.5, Ï‰ = 4-12
            - **Research Grade**: Matches or exceeds paper reproduction metrics
            - **Trading Grade**: High quality + recent data validation
            """)
        
        # Download functionality
        csv = final_df.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ Download Parameter Data",
            data=csv,
            file_name=f"{symbol}_parameters_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    def run(self):
        """Main dashboard execution"""
        
        st.title("ğŸ“Š LPPL Market Analysis Dashboard")
        st.markdown("*Symbol-based analysis with trading position prioritization*")
        
        # Render sidebar and get selections
        sidebar_result = self.render_sidebar()
        
        if sidebar_result is None:
            st.info("Please select a symbol from the sidebar to view analysis results.")
            return
        
        selected_symbol, period_selection, priority_filter = sidebar_result
        
        # Determine display limit based on period selection
        # If period selection is applied, we don't need a limit since filtering is done by date
        display_limit = 1000 if period_selection else 50
        
        # Get analysis data
        with st.spinner(f"Loading analysis data for {selected_symbol}..."):
            analysis_data = self.get_symbol_analysis_data(selected_symbol, display_limit, period_selection)
        
        if analysis_data.empty:
            st.warning(f"No analysis data found for {selected_symbol}")
            return
        
        # Apply priority filter based on days to crash
        if priority_filter != "All" and 'predicted_crash_date' in analysis_data.columns:
            now = datetime.now()
            if priority_filter == "Critical Only (â‰¤30 days)":
                analysis_data = analysis_data[
                    analysis_data['predicted_crash_date'].apply(
                        lambda x: (x - now).days <= 30 if pd.notna(x) else False
                    )
                ]
            elif priority_filter == "High Priority (â‰¤90 days)":
                analysis_data = analysis_data[
                    analysis_data['predicted_crash_date'].apply(
                        lambda x: (x - now).days <= 90 if pd.notna(x) else False
                    )
                ]
            elif priority_filter == "Medium Priority (â‰¤180 days)":
                analysis_data = analysis_data[
                    analysis_data['predicted_crash_date'].apply(
                        lambda x: (x - now).days <= 180 if pd.notna(x) else False
                    )
                ]
        
        if analysis_data.empty:
            st.warning("No data matches the selected priority filter")
            return
        
        # Main content tabs - updated tab names for clarity
        tab1, tab2, tab3 = st.tabs([
            "ğŸ“ˆ LPPL Fitting Analysis", 
            "ğŸ“Š Prediction Convergence", 
            "ğŸ“‹ Parameters"
        ])
        
        with tab1:
            self.render_price_predictions_tab(selected_symbol, analysis_data)
        
        with tab2:
            self.render_prediction_convergence_tab(selected_symbol, analysis_data)
        
        with tab3:
            self.render_parameters_tab(selected_symbol, analysis_data)

def main():
    """Main execution function"""
    app = SymbolAnalysisDashboard()
    app.run()

if __name__ == "__main__":
    main()