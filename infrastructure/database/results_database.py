#!/usr/bin/env python3
"""
åˆ†æçµæœãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†
LPPLãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµæœã¨å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æ°¸ç¶šåŒ–
"""

import sqlite3
import json
import pandas as pd
from datetime import datetime
from typing import Dict, List, Optional, Any
import os
import base64
from pathlib import Path

class ResultsDatabase:
    """åˆ†æçµæœãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path: str = "results/analysis_results.db"):
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        
        Args:
            db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.db_path = db_path
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(os.path.dirname(db_path), exist_ok=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self._init_database()
        
    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆæœŸåŒ–"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # åˆ†æçµæœãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS analysis_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    analysis_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    data_source TEXT,
                    data_period_start DATE,
                    data_period_end DATE,
                    data_points INTEGER,
                    
                    -- LPPLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                    tc REAL,
                    beta REAL,
                    omega REAL,
                    phi REAL,
                    A REAL,
                    B REAL,
                    C REAL,
                    
                    -- ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å“è³ª
                    r_squared REAL,
                    rmse REAL,
                    quality TEXT,
                    confidence REAL,
                    is_usable BOOLEAN,
                    
                    -- äºˆæ¸¬æƒ…å ±
                    predicted_crash_date DATE,
                    days_to_crash INTEGER,
                    
                    -- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                    fitting_method TEXT,
                    window_days INTEGER,
                    total_candidates INTEGER,
                    successful_candidates INTEGER,
                    
                    -- JSONå½¢å¼ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿
                    quality_metadata TEXT,
                    selection_criteria TEXT
                )
            ''')
            
            # å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS visualizations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    analysis_id INTEGER,
                    chart_type TEXT NOT NULL,
                    chart_title TEXT,
                    file_path TEXT,
                    image_data BLOB,
                    creation_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    description TEXT,
                    
                    FOREIGN KEY (analysis_id) REFERENCES analysis_results (id)
                )
            ''')
            
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS data_sources (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    source_name TEXT NOT NULL,
                    last_update TIMESTAMP,
                    data_points INTEGER,
                    date_range_start DATE,
                    date_range_end DATE,
                    api_status TEXT,
                    notes TEXT
                )
            ''')
            
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®šãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS schedule_config (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    schedule_name TEXT UNIQUE NOT NULL,
                    frequency TEXT NOT NULL,  -- 'daily', 'weekly', 'monthly'
                    day_of_week INTEGER,      -- 0=æœˆæ›œ, 6=æ—¥æ›œ (weeklyç”¨)
                    hour INTEGER DEFAULT 9,
                    minute INTEGER DEFAULT 0,
                    timezone TEXT DEFAULT 'UTC',
                    symbols TEXT,             -- JSONé…åˆ—å½¢å¼
                    enabled BOOLEAN DEFAULT 1,
                    last_run TIMESTAMP,
                    next_run TIMESTAMP,
                    created_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    auto_backfill_limit INTEGER DEFAULT 30
                )
            ''')
            
            # analysis_resultsãƒ†ãƒ¼ãƒ–ãƒ«ã®æ‹¡å¼µï¼ˆæ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã«åˆ—è¿½åŠ ï¼‰
            self._add_column_if_not_exists(cursor, 'analysis_results', 'schedule_name', 'TEXT')
            self._add_column_if_not_exists(cursor, 'analysis_results', 'analysis_basis_date', 'DATE')
            self._add_column_if_not_exists(cursor, 'analysis_results', 'is_scheduled', 'BOOLEAN DEFAULT 0')
            self._add_column_if_not_exists(cursor, 'analysis_results', 'backfill_batch_id', 'TEXT')
            self._add_column_if_not_exists(cursor, 'analysis_results', 'is_expired', 'BOOLEAN DEFAULT 0')
            
            # æ›œæ—¥ãƒ¡ã‚¿æƒ…å ±ã®è¿½åŠ ï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºæœ€é©åŒ–ï¼‰
            self._add_column_if_not_exists(cursor, 'analysis_results', 'basis_day_of_week', 'INTEGER')  # 0=æœˆæ›œ, 6=æ—¥æ›œ
            self._add_column_if_not_exists(cursor, 'analysis_results', 'analysis_frequency', 'TEXT')     # weekly, daily
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_symbol_date ON analysis_results (symbol, analysis_date)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_quality ON analysis_results (quality, is_usable)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_schedule_enabled ON schedule_config (enabled)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_schedule_basis ON analysis_results (schedule_name, analysis_basis_date)')
            
            # åˆ†æåŸºæº–æ—¥ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆæœ€é‡è¦ï¼šãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºæœ€é©åŒ–ï¼‰
            cursor.execute('CREATE UNIQUE INDEX IF NOT EXISTS unique_symbol_basis_date ON analysis_results (symbol, analysis_basis_date)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_symbol_basis_date ON analysis_results (symbol, analysis_basis_date DESC)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_frequency_basis ON analysis_results (analysis_frequency, analysis_basis_date DESC)')
            
            conn.commit()
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†: {self.db_path}")
    
    def _add_column_if_not_exists(self, cursor, table_name: str, column_name: str, column_def: str):
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã«åˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ã¿è¿½åŠ """
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = [row[1] for row in cursor.fetchall()]
        
        if column_name not in columns:
            cursor.execute(f"ALTER TABLE {table_name} ADD COLUMN {column_name} {column_def}")
            print(f"  âœ… åˆ—è¿½åŠ : {table_name}.{column_name}")
    
    def save_analysis_result(self, result_data: Dict[str, Any]) -> int:
        """
        åˆ†æçµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        
        Args:
            result_data: åˆ†æçµæœãƒ‡ãƒ¼ã‚¿
            
        Returns:
            int: ä¿å­˜ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰ã®ID
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
            required_fields = ['symbol', 'tc', 'beta', 'omega', 'r_squared']
            for field in required_fields:
                if field not in result_data:
                    raise ValueError(f"å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ '{field}' ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            
            # ğŸ”§ Issue I048ä¿®æ­£: analysis_basis_date ã‚’è‡ªå‹•è¨­å®šï¼ˆdata_period_end ã‚’ä½¿ç”¨ï¼‰
            analysis_basis_date = result_data.get('analysis_basis_date') or result_data.get('data_period_end')
            
            # é‡è¤‡é˜²æ­¢: åŒä¸€éŠ˜æŸ„ãƒ»åŒä¸€åŸºæº–æ—¥ã¯æ›´æ–°ã€æ–°è¦ã¯æŒ¿å…¥ï¼ˆUPSERTï¼‰
            cursor.execute('''
                INSERT OR REPLACE INTO analysis_results (
                    symbol, data_source, data_period_start, data_period_end, data_points,
                    tc, beta, omega, phi, A, B, C,
                    r_squared, rmse, quality, confidence, is_usable,
                    predicted_crash_date, days_to_crash,
                    fitting_method, window_days, total_candidates, successful_candidates,
                    quality_metadata, selection_criteria, analysis_basis_date
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                result_data['symbol'],
                result_data.get('data_source', 'unknown'),
                result_data.get('data_period_start'),
                result_data.get('data_period_end'),
                result_data.get('data_points', 0),
                result_data['tc'],
                result_data['beta'],
                result_data['omega'],
                result_data.get('phi', 0.0),
                result_data.get('A', 0.0),
                result_data.get('B', 0.0),
                result_data.get('C', 0.0),
                result_data['r_squared'],
                result_data.get('rmse', 0.0),
                result_data.get('quality', 'unknown'),
                result_data.get('confidence', 0.0),
                result_data.get('is_usable', False),
                result_data.get('predicted_crash_date'),
                result_data.get('days_to_crash'),
                result_data.get('fitting_method', 'multi_criteria'),
                result_data.get('window_days', 0),
                result_data.get('total_candidates', 0),
                result_data.get('successful_candidates', 0),
                json.dumps(result_data.get('quality_metadata', {})),
                json.dumps(result_data.get('selection_criteria', {})),
                analysis_basis_date
            ))
            
            analysis_id = cursor.lastrowid
            conn.commit()
            
            print(f"ğŸ“Š åˆ†æçµæœä¿å­˜å®Œäº†: ID={analysis_id}, Symbol={result_data['symbol']}")
            return analysis_id
    
    def save_visualization(self, analysis_id: int, chart_type: str, file_path: str, 
                          title: str = "", description: str = "") -> int:
        """
        å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        
        Args:
            analysis_id: é–¢é€£ã™ã‚‹åˆ†æçµæœID
            chart_type: ãƒãƒ£ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—
            file_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            title: ãƒãƒ£ãƒ¼ãƒˆã‚¿ã‚¤ãƒˆãƒ«
            description: èª¬æ˜
            
        Returns:
            int: ä¿å­˜ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰ã®ID
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’BLOBã¨ã—ã¦èª­ã¿è¾¼ã¿
            image_data = None
            if os.path.exists(file_path):
                with open(file_path, 'rb') as f:
                    image_data = f.read()
            
            cursor.execute('''
                INSERT INTO visualizations (
                    analysis_id, chart_type, chart_title, file_path, 
                    image_data, description
                ) VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                analysis_id, chart_type, title, file_path, 
                image_data, description
            ))
            
            viz_id = cursor.lastrowid
            conn.commit()
            
            print(f"ğŸ“Š å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: ID={viz_id}, Type={chart_type}")
            return viz_id
    
    def get_recent_analyses(self, limit: int = 50, symbol: str = None) -> pd.DataFrame:
        """
        æœ€è¿‘ã®åˆ†æçµæœã‚’å–å¾—
        
        Args:
            limit: å–å¾—ä»¶æ•°åˆ¶é™
            symbol: ç‰¹å®šéŠ˜æŸ„ã®ã¿å–å¾—ã™ã‚‹å ´åˆ
            
        Returns:
            DataFrame: åˆ†æçµæœ
        """
        with sqlite3.connect(self.db_path) as conn:
            query = '''
                SELECT 
                    id, symbol, analysis_date, data_source,
                    data_period_start, data_period_end, data_points,
                    tc, beta, omega, phi, A, B, C,
                    r_squared, rmse, quality, confidence, is_usable,
                    predicted_crash_date, days_to_crash,
                    window_days, total_candidates, successful_candidates
                FROM analysis_results
            '''
            
            params = []
            if symbol:
                query += ' WHERE symbol = ?'
                params.append(symbol)
            
            # âš ï¸ CRITICAL: åˆ†æåŸºæº–æ—¥ã§ã‚½ãƒ¼ãƒˆï¼ˆanalysis_dateã§ã¯ãªã„ï¼‰
            query += ' ORDER BY analysis_basis_date DESC, analysis_date DESC LIMIT ?'
            params.append(limit)
            
            return pd.read_sql_query(query, conn, params=params)
    
    def get_recent_analyses_by_frequency(self, symbol: str = None, frequency: str = 'weekly', limit: int = 50) -> pd.DataFrame:
        """
        é »åº¦åˆ¥æœ€è¿‘ã®åˆ†æçµæœã‚’å–å¾—ï¼ˆé€±æ¬¡ãƒ‡ãƒ¼ã‚¿å„ªå…ˆè¡¨ç¤ºï¼‰
        
        Args:
            symbol: ç‰¹å®šéŠ˜æŸ„ã®ã¿å–å¾—ã™ã‚‹å ´åˆ
            frequency: å–å¾—é »åº¦ ('weekly', 'daily', 'monthly')
            limit: å–å¾—ä»¶æ•°åˆ¶é™
            
        Returns:
            DataFrame: åˆ†æçµæœ
        """
        with sqlite3.connect(self.db_path) as conn:
            query = '''
                SELECT 
                    id, symbol, analysis_date, data_source,
                    data_period_start, data_period_end, data_points,
                    tc, beta, omega, phi, A, B, C,
                    r_squared, rmse, quality, confidence, is_usable,
                    predicted_crash_date, days_to_crash,
                    window_days, total_candidates, successful_candidates,
                    schedule_name, analysis_basis_date, analysis_frequency,
                    basis_day_of_week
                FROM analysis_results
                WHERE analysis_frequency = ?
            '''
            params = [frequency]
            
            if symbol:
                query += ' AND symbol = ?'
                params.append(symbol)
            
            # âš ï¸ CRITICAL: åˆ†æåŸºæº–æ—¥ã§ã‚½ãƒ¼ãƒˆï¼ˆanalysis_dateã§ã¯ãªã„ï¼‰
            query += ' ORDER BY analysis_basis_date DESC, analysis_date DESC LIMIT ?'
            params.append(limit)
            
            return pd.read_sql_query(query, conn, params=params)
    
    def get_latest_analysis_per_frequency(self, symbol: str) -> pd.DataFrame:
        """
        éŠ˜æŸ„åˆ¥ãƒ»é »åº¦åˆ¥ã®æœ€æ–°åˆ†æçµæœã‚’å–å¾—
        
        Args:
            symbol: å¯¾è±¡éŠ˜æŸ„
            
        Returns:
            DataFrame: é »åº¦åˆ¥æœ€æ–°åˆ†æçµæœ
        """
        with sqlite3.connect(self.db_path) as conn:
            query = '''
                SELECT DISTINCT
                    a1.id, a1.symbol, a1.analysis_date, a1.data_source,
                    a1.data_period_start, a1.data_period_end, a1.data_points,
                    a1.tc, a1.beta, a1.omega, a1.phi, a1.A, a1.B, a1.C,
                    a1.r_squared, a1.rmse, a1.quality, a1.confidence, a1.is_usable,
                    a1.predicted_crash_date, a1.days_to_crash,
                    a1.window_days, a1.total_candidates, a1.successful_candidates,
                    a1.schedule_name, a1.analysis_basis_date, a1.analysis_frequency,
                    a1.basis_day_of_week
                FROM analysis_results a1
                INNER JOIN (
                    SELECT analysis_frequency, MAX(analysis_basis_date) as max_basis_date
                    FROM analysis_results 
                    WHERE symbol = ? AND analysis_frequency IS NOT NULL
                    GROUP BY analysis_frequency
                ) a2 ON a1.analysis_frequency = a2.analysis_frequency 
                    AND a1.analysis_basis_date = a2.max_basis_date
                WHERE a1.symbol = ?
                ORDER BY a1.analysis_frequency, a1.analysis_basis_date DESC
            '''
            
            return pd.read_sql_query(query, conn, params=[symbol, symbol])
    
    def get_analysis_details(self, analysis_id: int) -> Dict[str, Any]:
        """
        ç‰¹å®šåˆ†æã®è©³ç´°æƒ…å ±ã‚’å–å¾—
        
        Args:
            analysis_id: åˆ†æID
            
        Returns:
            Dict: è©³ç´°æƒ…å ±
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # åˆ†æçµæœå–å¾—
            cursor.execute('SELECT * FROM analysis_results WHERE id = ?', (analysis_id,))
            result = cursor.fetchone()
            
            if not result:
                return {}
            
            # ã‚«ãƒ©ãƒ åå–å¾—
            columns = [desc[0] for desc in cursor.description]
            analysis_data = dict(zip(columns, result))
            
            # JSON ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹
            if analysis_data.get('quality_metadata'):
                analysis_data['quality_metadata'] = json.loads(analysis_data['quality_metadata'])
            
            if analysis_data.get('selection_criteria'):
                analysis_data['selection_criteria'] = json.loads(analysis_data['selection_criteria'])
            
            # é–¢é€£å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿å–å¾—
            cursor.execute('''
                SELECT chart_type, chart_title, file_path, description, creation_date
                FROM visualizations 
                WHERE analysis_id = ?
                ORDER BY creation_date DESC
            ''', (analysis_id,))
            
            visualizations = []
            for viz in cursor.fetchall():
                viz_cols = ['chart_type', 'chart_title', 'file_path', 'description', 'creation_date']
                visualizations.append(dict(zip(viz_cols, viz)))
            
            analysis_data['visualizations'] = visualizations
            
            return analysis_data
    
    def get_visualization_image(self, analysis_id: int, chart_type: str) -> Optional[bytes]:
        """
        å¯è¦–åŒ–ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            analysis_id: åˆ†æID
            chart_type: ãƒãƒ£ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—
            
        Returns:
            bytes: ç”»åƒãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT image_data FROM visualizations 
                WHERE analysis_id = ? AND chart_type = ?
                ORDER BY creation_date DESC LIMIT 1
            ''', (analysis_id, chart_type))
            
            result = cursor.fetchone()
            return result[0] if result else None
    
    def get_summary_statistics(self) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ¦‚è¦çµ±è¨ˆã‚’å–å¾—
        
        Returns:
            Dict: çµ±è¨ˆæƒ…å ±
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # åŸºæœ¬çµ±è¨ˆ
            cursor.execute('SELECT COUNT(*) FROM analysis_results')
            total_analyses = cursor.fetchone()[0]
            
            cursor.execute('SELECT COUNT(DISTINCT symbol) FROM analysis_results')
            unique_symbols = cursor.fetchone()[0]
            
            cursor.execute('SELECT COUNT(*) FROM analysis_results WHERE is_usable = 1')
            usable_analyses = cursor.fetchone()[0]
            
            # æœ€æ–°åˆ†ææ—¥
            cursor.execute('SELECT MAX(analysis_date) FROM analysis_results')
            latest_analysis = cursor.fetchone()[0]
            
            # å“è³ªåˆ¥çµ±è¨ˆ
            cursor.execute('''
                SELECT quality, COUNT(*) 
                FROM analysis_results 
                GROUP BY quality
            ''')
            quality_stats = dict(cursor.fetchall())
            
            # RÂ²çµ±è¨ˆ
            cursor.execute('''
                SELECT 
                    AVG(r_squared) as avg_r_squared,
                    MIN(r_squared) as min_r_squared,
                    MAX(r_squared) as max_r_squared
                FROM analysis_results 
                WHERE r_squared IS NOT NULL
            ''')
            r_squared_stats = cursor.fetchone()
            
            return {
                'total_analyses': total_analyses,
                'unique_symbols': unique_symbols,
                'usable_analyses': usable_analyses,
                'usable_rate': usable_analyses / max(total_analyses, 1),
                'latest_analysis': latest_analysis,
                'quality_distribution': quality_stats,
                'r_squared_stats': {
                    'average': r_squared_stats[0] if r_squared_stats[0] else 0,
                    'minimum': r_squared_stats[1] if r_squared_stats[1] else 0,
                    'maximum': r_squared_stats[2] if r_squared_stats[2] else 0
                }
            }
    
    def cleanup_old_records(self, days_to_keep: int = 90):
        """
        å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        
        Args:
            days_to_keep: ä¿æŒæ—¥æ•°
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute('''
                DELETE FROM analysis_results 
                WHERE analysis_date < datetime('now', '-{} days')
            '''.format(days_to_keep))
            
            deleted_count = cursor.rowcount
            conn.commit()
            
            print(f"ğŸ“Š å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰å‰Šé™¤: {deleted_count}ä»¶")


# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ
def test_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
    db = ResultsDatabase("results/test_analysis.db")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    sample_result = {
        'symbol': 'TEST_NASDAQ',
        'data_source': 'fred',
        'data_period_start': '2024-01-01',
        'data_period_end': '2024-12-31',
        'data_points': 250,
        'tc': 1.15,
        'beta': 0.33,
        'omega': 7.4,
        'phi': 0.1,
        'A': 10.0,
        'B': -1.0,
        'C': 0.1,
        'r_squared': 0.95,
        'rmse': 0.01,
        'quality': 'high_quality',
        'confidence': 0.92,
        'is_usable': True,
        'predicted_crash_date': '2025-01-15',
        'days_to_crash': 45,
        'fitting_method': 'multi_criteria',
        'window_days': 365,
        'total_candidates': 50,
        'successful_candidates': 35
    }
    
    # ä¿å­˜ãƒ†ã‚¹ãƒˆ
    analysis_id = db.save_analysis_result(sample_result)
    print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä¿å­˜: ID={analysis_id}")
    
    # å–å¾—ãƒ†ã‚¹ãƒˆ
    recent = db.get_recent_analyses(limit=5)
    print(f"âœ… æœ€è¿‘ã®åˆ†æå–å¾—: {len(recent)}ä»¶")
    
    # çµ±è¨ˆãƒ†ã‚¹ãƒˆ
    stats = db.get_summary_statistics()
    print(f"âœ… çµ±è¨ˆæƒ…å ±: ç·åˆ†ææ•°={stats['total_analyses']}, ä½¿ç”¨å¯èƒ½ç‡={stats['usable_rate']:.1%}")
    
    return db


if __name__ == "__main__":
    test_database()