#!/usr/bin/env python3
"""
ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ 
- ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸãƒ»ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—ã®ã‚±ãƒ¼ã‚¹ã‚’è¨˜éŒ²
- é‡è¤‡è§£æé˜²æ­¢æ©Ÿèƒ½
- å¤±æ•—ç†ç”±ã®è©³ç´°è¿½è·¡
"""

import sqlite3
import json
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List, Tuple
from pathlib import Path

class FittingFailureTracker:
    """ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—è¿½è·¡ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path: Optional[str] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ï¼ˆæœªæŒ‡å®šæ™‚ã¯è‡ªå‹•è¨­å®šï¼‰
        """
        if db_path is None:
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹
            project_root = Path(__file__).parent.parent.parent
            db_path = project_root / "results" / "analysis_results.db"
        
        self.db_path = str(db_path)
        self._init_failure_tables()
    
    def _init_failure_tables(self):
        """å¤±æ•—è¿½è·¡ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆæœŸåŒ–"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # 1. ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—è¨˜éŒ²ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS fitting_failures (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT NOT NULL,
            analysis_basis_date DATE NOT NULL,
            analysis_date TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
            
            -- ãƒ‡ãƒ¼ã‚¿å–å¾—æƒ…å ±
            data_source TEXT NOT NULL,
            data_period_start DATE,
            data_period_end DATE,
            data_points INTEGER,
            data_retrieval_success BOOLEAN NOT NULL DEFAULT TRUE,
            
            -- ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—æƒ…å ±
            failure_stage TEXT NOT NULL,  -- 'data_retrieval', 'data_processing', 'fitting_execution', 'quality_check'
            failure_category TEXT NOT NULL,  -- 'api_failure', 'rate_limit', 'insufficient_data', 'optimization_failed', 'quality_rejected'
            failure_reason TEXT NOT NULL,
            failure_details TEXT,  -- JSONå½¢å¼ã®è©³ç´°æƒ…å ±
            failure_metadata TEXT,  -- JSONå½¢å¼ã®å¤±æ•—ç¨®åˆ¥ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            
            -- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            schedule_name TEXT,
            backfill_batch_id TEXT,
            retry_count INTEGER DEFAULT 0,
            last_retry_date TIMESTAMP,
            
            -- åˆ¶ç´„
            UNIQUE(symbol, analysis_basis_date, schedule_name)
        )""")
        
        # 2. è§£æçŠ¶æ…‹è¿½è·¡ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆé‡è¤‡é˜²æ­¢ç”¨ï¼‰
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS analysis_status (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT NOT NULL,
            analysis_basis_date DATE NOT NULL,
            schedule_name TEXT,
            
            -- çŠ¶æ…‹æƒ…å ±
            status TEXT NOT NULL,  -- 'pending', 'in_progress', 'success', 'failed', 'skipped'
            data_available BOOLEAN DEFAULT FALSE,
            fitting_attempted BOOLEAN DEFAULT FALSE,
            fitting_successful BOOLEAN DEFAULT FALSE,
            
            -- æ™‚é–“è¨˜éŒ²
            started_at TIMESTAMP,
            completed_at TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            
            -- çµæœå‚ç…§
            analysis_result_id INTEGER,  -- analysis_resultsãƒ†ãƒ¼ãƒ–ãƒ«ã®ID
            failure_record_id INTEGER,   -- fitting_failuresãƒ†ãƒ¼ãƒ–ãƒ«ã®ID
            
            -- åˆ¶ç´„
            UNIQUE(symbol, analysis_basis_date, schedule_name),
            
            -- å¤–éƒ¨ã‚­ãƒ¼
            FOREIGN KEY(analysis_result_id) REFERENCES analysis_results(id),
            FOREIGN KEY(failure_record_id) REFERENCES fitting_failures(id)
        )""")
        
        # 3. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_fitting_failures_symbol_date ON fitting_failures(symbol, analysis_basis_date)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_fitting_failures_schedule ON fitting_failures(schedule_name, analysis_date)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_analysis_status_symbol_date ON analysis_status(symbol, analysis_basis_date)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_analysis_status_schedule ON analysis_status(schedule_name)")
        
        conn.commit()
        conn.close()
        
        print("âœ… ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—è¿½è·¡ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–å®Œäº†")
    
    def check_analysis_needed(self, symbol: str, analysis_basis_date: str, 
                            schedule_name: str = None) -> Dict[str, Any]:
        """
        è§£æãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
        
        Args:
            symbol: éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«
            analysis_basis_date: åˆ†æåŸºæº–æ—¥
            schedule_name: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å
            
        Returns:
            dict: è§£æå¿…è¦æ€§ã¨ç†ç”±
        """
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # æ—¢å­˜ã®è§£æçŠ¶æ…‹ç¢ºèª
            query = """
            SELECT status, data_available, fitting_attempted, fitting_successful,
                   analysis_result_id, failure_record_id, completed_at
            FROM analysis_status
            WHERE symbol = ? AND analysis_basis_date = ? 
            AND (schedule_name = ? OR schedule_name IS NULL)
            ORDER BY updated_at DESC LIMIT 1
            """
            
            cursor.execute(query, (symbol, analysis_basis_date, schedule_name))
            result = cursor.fetchone()
            
            if not result:
                # æœªè§£æ
                return {
                    'needed': True,
                    'reason': 'no_previous_analysis',
                    'action': 'full_analysis',
                    'status': None
                }
            
            status, data_available, fitting_attempted, fitting_successful, result_id, failure_id, completed_at = result
            
            # æˆåŠŸæ¸ˆã¿ã®å ´åˆ
            if status == 'success' and fitting_successful and result_id:
                return {
                    'needed': False,
                    'reason': 'already_successful',
                    'action': 'skip',
                    'status': status,
                    'result_id': result_id
                }
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—æ¸ˆã¿ãƒ»ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—ã®å ´åˆ
            if status == 'failed' and data_available and failure_id:
                # å¤±æ•—è©³ç´°ç¢ºèª
                cursor.execute("SELECT failure_category, retry_count FROM fitting_failures WHERE id = ?", 
                             (failure_id,))
                failure_info = cursor.fetchone()
                
                if failure_info:
                    failure_category, retry_count = failure_info
                    
                    # ãƒªãƒˆãƒ©ã‚¤å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                    if retry_count < 3 and failure_category not in ['insufficient_data', 'invalid_symbol']:
                        return {
                            'needed': True,
                            'reason': 'retry_fitting',
                            'action': 'retry_fitting_only',
                            'status': status,
                            'retry_count': retry_count
                        }
                    else:
                        return {
                            'needed': False,
                            'reason': 'permanent_failure',
                            'action': 'skip',
                            'status': status,
                            'failure_category': failure_category
                        }
            
            # é€²è¡Œä¸­ã®å ´åˆ
            if status == 'in_progress':
                # 24æ™‚é–“ä»¥ä¸ŠçµŒéã—ã¦ã„ã‚Œã°å†å®Ÿè¡Œ
                if completed_at:
                    last_update = datetime.fromisoformat(completed_at)
                    if datetime.now() - last_update > timedelta(hours=24):
                        return {
                            'needed': True,
                            'reason': 'stale_in_progress',
                            'action': 'full_analysis',
                            'status': status
                        }
                
                return {
                    'needed': False,
                    'reason': 'currently_in_progress',
                    'action': 'skip',
                    'status': status
                }
            
            # ãã®ä»–ã®å ´åˆã¯å†è§£æ
            return {
                'needed': True,
                'reason': 'incomplete_previous_analysis',
                'action': 'full_analysis',
                'status': status
            }
            
        finally:
            conn.close()
    
    def start_analysis(self, symbol: str, analysis_basis_date: str, 
                      schedule_name: str = None) -> int:
        """
        è§£æé–‹å§‹ã‚’è¨˜éŒ²
        
        Args:
            symbol: éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«
            analysis_basis_date: åˆ†æåŸºæº–æ—¥
            schedule_name: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å
            
        Returns:
            int: analysis_status ãƒ¬ã‚³ãƒ¼ãƒ‰ID
        """
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã®æ›´æ–°ã¾ãŸã¯æ–°è¦ä½œæˆ
            cursor.execute("""
            INSERT OR REPLACE INTO analysis_status 
            (symbol, analysis_basis_date, schedule_name, status, started_at, updated_at)
            VALUES (?, ?, ?, 'in_progress', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            """, (symbol, analysis_basis_date, schedule_name))
            
            status_id = cursor.lastrowid
            conn.commit()
            
            print(f"ğŸ”„ è§£æé–‹å§‹è¨˜éŒ²: {symbol} ({analysis_basis_date}) - ID: {status_id}")
            return status_id
            
        finally:
            conn.close()
    
    def record_data_retrieval(self, status_id: int, data_source: str, 
                            data_points: int, period_start: str, period_end: str):
        """
        ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸã‚’è¨˜éŒ²
        
        Args:
            status_id: analysis_status ãƒ¬ã‚³ãƒ¼ãƒ‰ID
            data_source: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
            data_points: ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°
            period_start: ãƒ‡ãƒ¼ã‚¿æœŸé–“é–‹å§‹æ—¥
            period_end: ãƒ‡ãƒ¼ã‚¿æœŸé–“çµ‚äº†æ—¥
        """
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
            UPDATE analysis_status 
            SET data_available = TRUE, updated_at = CURRENT_TIMESTAMP
            WHERE id = ?
            """, (status_id,))
            
            conn.commit()
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸè¨˜éŒ²: ID {status_id} - {data_points}æ—¥åˆ†")
            
        finally:
            conn.close()
    
    def record_success(self, status_id: int, analysis_result_id: int):
        """
        ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°æˆåŠŸã‚’è¨˜éŒ²
        
        Args:
            status_id: analysis_status ãƒ¬ã‚³ãƒ¼ãƒ‰ID
            analysis_result_id: analysis_results ãƒ†ãƒ¼ãƒ–ãƒ«ã®ID
        """
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
            UPDATE analysis_status 
            SET status = 'success', 
                fitting_attempted = TRUE,
                fitting_successful = TRUE,
                analysis_result_id = ?,
                completed_at = CURRENT_TIMESTAMP,
                updated_at = CURRENT_TIMESTAMP
            WHERE id = ?
            """, (analysis_result_id, status_id))
            
            conn.commit()
            print(f"âœ… ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°æˆåŠŸè¨˜éŒ²: ID {status_id} â†’ çµæœID {analysis_result_id}")
            
        finally:
            conn.close()
    
    def record_failure(self, status_id: int, symbol: str, analysis_basis_date: str,
                      data_source: str, failure_stage: str, failure_category: str,
                      failure_reason: str, failure_details: Dict[str, Any] = None,
                      failure_metadata: Dict[str, Any] = None,
                      data_info: Dict[str, Any] = None, schedule_name: str = None,
                      backfill_batch_id: str = None) -> int:
        """
        ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—ã‚’è¨˜éŒ²
        
        Args:
            status_id: analysis_status ãƒ¬ã‚³ãƒ¼ãƒ‰ID
            symbol: éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«
            analysis_basis_date: åˆ†æåŸºæº–æ—¥
            data_source: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
            failure_stage: å¤±æ•—æ®µéš ('data_retrieval', 'data_processing', 'fitting_execution', 'quality_check')
            failure_category: å¤±æ•—ã‚«ãƒ†ã‚´ãƒª ('api_failure', 'rate_limit', 'insufficient_data', 'optimization_failed', 'quality_rejected')
            failure_reason: å¤±æ•—ç†ç”±
            failure_details: å¤±æ•—è©³ç´°
            failure_metadata: å¤±æ•—ç¨®åˆ¥ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            data_info: ãƒ‡ãƒ¼ã‚¿æƒ…å ±
            schedule_name: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å
            backfill_batch_id: ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ãƒãƒƒãƒID
            
        Returns:
            int: fitting_failures ãƒ¬ã‚³ãƒ¼ãƒ‰ID
        """
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            if data_info is None:
                data_info = {}
            
            data_points = data_info.get('data_points', 0)
            period_start = data_info.get('period_start')
            period_end = data_info.get('period_end')
            data_retrieval_success = data_info.get('retrieval_success', True)
            
            # å¤±æ•—è©³ç´°ã‚’JSONåŒ–
            details_json = json.dumps(failure_details, ensure_ascii=False) if failure_details else None
            metadata_json = json.dumps(failure_metadata, ensure_ascii=False) if failure_metadata else None
            
            # æ—¢å­˜ã®å¤±æ•—ãƒ¬ã‚³ãƒ¼ãƒ‰ç¢ºèªï¼ˆé‡è¤‡æŒ¿å…¥é˜²æ­¢ï¼‰
            cursor.execute("""
            SELECT id, retry_count FROM fitting_failures 
            WHERE symbol = ? AND analysis_basis_date = ? AND schedule_name = ?
            """, (symbol, analysis_basis_date, schedule_name))
            
            existing = cursor.fetchone()
            
            if existing:
                # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã®æ›´æ–°ï¼ˆãƒªãƒˆãƒ©ã‚¤ã‚«ã‚¦ãƒ³ãƒˆå¢—åŠ ï¼‰
                existing_id, retry_count = existing
                cursor.execute("""
                UPDATE fitting_failures 
                SET failure_stage = ?, failure_category = ?, failure_reason = ?,
                    failure_details = ?, failure_metadata = ?, retry_count = ?, 
                    last_retry_date = CURRENT_TIMESTAMP,
                    analysis_date = CURRENT_TIMESTAMP
                WHERE id = ?
                """, (failure_stage, failure_category, failure_reason, 
                     details_json, metadata_json, retry_count + 1, existing_id))
                
                failure_id = existing_id
                print(f"ğŸ”„ å¤±æ•—ãƒ¬ã‚³ãƒ¼ãƒ‰æ›´æ–°: {symbol} - ãƒªãƒˆãƒ©ã‚¤{retry_count + 1}å›ç›®")
            else:
                # æ–°è¦å¤±æ•—ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ
                cursor.execute("""
                INSERT INTO fitting_failures 
                (symbol, analysis_basis_date, data_source, data_period_start, data_period_end,
                 data_points, data_retrieval_success, failure_stage, failure_category,
                 failure_reason, failure_details, failure_metadata, schedule_name, backfill_batch_id, retry_count)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 0)
                """, (symbol, analysis_basis_date, data_source, period_start, period_end,
                     data_points, data_retrieval_success, failure_stage, failure_category,
                     failure_reason, details_json, metadata_json, schedule_name, backfill_batch_id))
                
                failure_id = cursor.lastrowid
                print(f"âŒ å¤±æ•—ãƒ¬ã‚³ãƒ¼ãƒ‰æ–°è¦ä½œæˆ: {symbol} ({failure_category})")
            
            # analysis_status ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°
            cursor.execute("""
            UPDATE analysis_status 
            SET status = 'failed',
                fitting_attempted = TRUE,
                fitting_successful = FALSE,
                failure_record_id = ?,
                completed_at = CURRENT_TIMESTAMP,
                updated_at = CURRENT_TIMESTAMP
            WHERE id = ?
            """, (failure_id, status_id))
            
            conn.commit()
            return failure_id
            
        finally:
            conn.close()
    
    def get_failure_statistics(self, schedule_name: str = None) -> Dict[str, Any]:
        """
        å¤±æ•—çµ±è¨ˆã®å–å¾—
        
        Args:
            schedule_name: ç‰¹å®šã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®çµ±è¨ˆï¼ˆæœªæŒ‡å®šæ™‚ã¯å…¨ä½“ï¼‰
            
        Returns:
            dict: å¤±æ•—çµ±è¨ˆæƒ…å ±
        """
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # åŸºæœ¬çµ±è¨ˆ
            where_clause = "WHERE schedule_name = ?" if schedule_name else ""
            params = [schedule_name] if schedule_name else []
            
            # å¤±æ•—ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
            cursor.execute(f"""
            SELECT failure_category, COUNT(*) as count
            FROM fitting_failures {where_clause}
            GROUP BY failure_category
            ORDER BY count DESC
            """, params)
            
            category_stats = dict(cursor.fetchall())
            
            # å¤±æ•—æ®µéšåˆ¥çµ±è¨ˆ
            cursor.execute(f"""
            SELECT failure_stage, COUNT(*) as count
            FROM fitting_failures {where_clause}
            GROUP BY failure_stage
            ORDER BY count DESC
            """, params)
            
            stage_stats = dict(cursor.fetchall())
            
            # æœ€è¿‘ã®å¤±æ•—ï¼ˆ7æ—¥ä»¥å†…ï¼‰
            cursor.execute(f"""
            SELECT COUNT(*) FROM fitting_failures 
            {where_clause} {"AND" if where_clause else "WHERE"} 
            analysis_date >= date('now', '-7 days')
            """, params)
            
            recent_failures = cursor.fetchone()[0]
            
            # æˆåŠŸãƒ»å¤±æ•—ãƒ»é€²è¡Œä¸­ã®çµ±è¨ˆ
            cursor.execute(f"""
            SELECT status, COUNT(*) as count
            FROM analysis_status {where_clause}
            GROUP BY status
            ORDER BY count DESC
            """, params)
            
            status_stats = dict(cursor.fetchall())
            
            return {
                'failure_by_category': category_stats,
                'failure_by_stage': stage_stats,
                'recent_failures_7days': recent_failures,
                'analysis_status': status_stats,
                'total_failures': sum(category_stats.values()),
                'total_analyses': sum(status_stats.values())
            }
            
        finally:
            conn.close()
    
    def get_retry_candidates(self, max_retry_count: int = 2) -> List[Dict[str, Any]]:
        """
        ãƒªãƒˆãƒ©ã‚¤å€™è£œã®å–å¾—
        
        Args:
            max_retry_count: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
            
        Returns:
            list: ãƒªãƒˆãƒ©ã‚¤å€™è£œãƒªã‚¹ãƒˆ
        """
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            query = """
            SELECT f.symbol, f.analysis_basis_date, f.schedule_name,
                   f.failure_category, f.retry_count, f.failure_reason,
                   f.data_points, f.last_retry_date
            FROM fitting_failures f
            JOIN analysis_status s ON (
                s.symbol = f.symbol AND 
                s.analysis_basis_date = f.analysis_basis_date AND
                s.schedule_name = f.schedule_name
            )
            WHERE f.retry_count < ? 
            AND f.failure_category NOT IN ('insufficient_data', 'invalid_symbol')
            AND s.status = 'failed'
            AND (f.last_retry_date IS NULL OR f.last_retry_date < date('now', '-1 day'))
            ORDER BY f.analysis_basis_date DESC, f.retry_count ASC
            """
            
            cursor.execute(query, (max_retry_count,))
            results = cursor.fetchall()
            
            candidates = []
            for row in results:
                candidates.append({
                    'symbol': row[0],
                    'analysis_basis_date': row[1],
                    'schedule_name': row[2],
                    'failure_category': row[3],
                    'retry_count': row[4],
                    'failure_reason': row[5],
                    'data_points': row[6],
                    'last_retry_date': row[7]
                })
            
            return candidates
            
        finally:
            conn.close()

# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ
def test_failure_tracker():
    """å¤±æ•—è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸ§ª ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    tracker = FittingFailureTracker()
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
    test_symbol = "TEST_BTC"
    test_date = "2025-08-10"
    test_schedule = "test_schedule"
    
    print(f"ğŸ“‹ ãƒ†ã‚¹ãƒˆå¯¾è±¡: {test_symbol} ({test_date})")
    
    # 1. è§£æå¿…è¦æ€§ãƒã‚§ãƒƒã‚¯
    check_result = tracker.check_analysis_needed(test_symbol, test_date, test_schedule)
    print(f"ğŸ” è§£æå¿…è¦æ€§: {check_result}")
    
    # 2. è§£æé–‹å§‹
    if check_result['needed']:
        status_id = tracker.start_analysis(test_symbol, test_date, test_schedule)
        
        # 3. ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸè¨˜éŒ²
        tracker.record_data_retrieval(status_id, "coingecko", 365, "2024-08-10", "2025-08-10")
        
        # 4. å¤±æ•—è¨˜éŒ²
        failure_details = {
            "error": "Optimization failed to converge",
            "attempted_methods": ["SLSQP", "L-BFGS-B"],
            "parameter_bounds": {"tc": [1.0, 3.0], "beta": [0.1, 1.0]}
        }
        
        failure_id = tracker.record_failure(
            status_id, test_symbol, test_date, "coingecko",
            "fitting_execution", "optimization_failed",
            "scipy optimization did not converge after 100 iterations",
            failure_details,
            {"data_points": 365, "period_start": "2024-08-10", "period_end": "2025-08-10"},
            test_schedule
        )
        
        print(f"ğŸ“Š å¤±æ•—è¨˜éŒ²ID: {failure_id}")
        
        # 5. å†åº¦è§£æå¿…è¦æ€§ãƒã‚§ãƒƒã‚¯
        recheck_result = tracker.check_analysis_needed(test_symbol, test_date, test_schedule)
        print(f"ğŸ” å†ãƒã‚§ãƒƒã‚¯çµæœ: {recheck_result}")
    
    # 6. çµ±è¨ˆå–å¾—
    stats = tracker.get_failure_statistics(test_schedule)
    print(f"ğŸ“Š å¤±æ•—çµ±è¨ˆ: {stats}")
    
    # 7. ãƒªãƒˆãƒ©ã‚¤å€™è£œå–å¾—
    retry_candidates = tracker.get_retry_candidates()
    print(f"ğŸ”„ ãƒªãƒˆãƒ©ã‚¤å€™è£œæ•°: {len(retry_candidates)}")

if __name__ == "__main__":
    test_failure_tracker()