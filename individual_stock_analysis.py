#!/usr/bin/env python3
"""
å€‹åˆ¥æ ªæ™‚ç³»åˆ—äºˆæ¸¬ä¸€è²«æ€§åˆ†æ

Alpha Vantage APIã‚’ä½¿ç”¨ã—ã¦å€‹åˆ¥æ ªã®
LPPLäºˆæ¸¬ä¸€è²«æ€§ã‚’åˆ†æã™ã‚‹
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import sys
import os
from dotenv import load_dotenv
import warnings
warnings.filterwarnings('ignore')

# ç’°å¢ƒè¨­å®š
load_dotenv()
sys.path.append('.')

def main():
    print("ğŸ“Š å€‹åˆ¥æ ªæ™‚ç³»åˆ—äºˆæ¸¬ä¸€è²«æ€§åˆ†æ")
    print("=" * 60)
    
    # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    from src.data_sources.unified_data_client import UnifiedDataClient
    from src.analysis.time_series_prediction_analyzer import TimeSeriesPredictionAnalyzer
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    data_client = UnifiedDataClient()
    
    if not data_client.available_sources:
        print("âŒ åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    print(f"âœ… åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {data_client.available_sources}")
    
    # åˆ†æå¯¾è±¡éŠ˜æŸ„ï¼ˆå€‹åˆ¥æ ªä¸­å¿ƒï¼‰
    individual_stocks = {
        'AAPL': 'Apple Inc.',
        'MSFT': 'Microsoft Corporation', 
        'GOOGL': 'Alphabet Inc.',
        'TSLA': 'Tesla Inc.',
        'AMZN': 'Amazon.com Inc.'
    }
    
    market_indices = {
        'NASDAQ': 'NASDAQ Composite',
        'SP500': 'S&P 500'
    }
    
    # å…¨åˆ†æå¯¾è±¡
    all_symbols = {**individual_stocks, **market_indices}
    
    print(f"ğŸ“‹ åˆ†æå¯¾è±¡:")
    print(f"   å€‹åˆ¥æ ª: {list(individual_stocks.keys())}")
    print(f"   æŒ‡æ•°: {list(market_indices.keys())}")
    
    # åˆ†ææœŸé–“è¨­å®š
    end_date = datetime.now()
    start_date = end_date - timedelta(days=60)  # 2ãƒ¶æœˆé–“ã®åˆ†æï¼ˆçŸ­ç¸®ç‰ˆï¼‰
    
    print(f"ğŸ“… åˆ†ææœŸé–“: {start_date.date()} - {end_date.date()}")
    print()
    
    # çµæœä¿å­˜ç”¨
    os.makedirs('results/individual_stock_analysis', exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    analyzer = TimeSeriesPredictionAnalyzer()
    all_results = {}
    
    # å„éŠ˜æŸ„ã®åˆ†æå®Ÿè¡Œ
    for i, (symbol, name) in enumerate(all_symbols.items(), 1):
        print(f"ğŸ” [{i}/{len(all_symbols)}] {symbol} ({name}) åˆ†æé–‹å§‹...")
        
        try:
            # ä¸€è²«æ€§åˆ†æå®Ÿè¡Œ
            metrics = analyzer.analyze_symbol_consistency(
                symbol,
                data_client,
                start_date,
                end_date,
                analysis_interval_days=14  # 2é€±é–“é–“éš”ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰
            )
            
            all_results[symbol] = {
                'metrics': metrics,
                'name': name,
                'category': 'stock' if symbol in individual_stocks else 'index'
            }
            
            # ç°¡æ˜“ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
            print(f"   ğŸ“Š {symbol} çµæœã‚µãƒãƒªãƒ¼:")
            print(f"      ä¸€è²«æ€§ã‚¹ã‚³ã‚¢: {metrics.consistency_score:.3f}")
            print(f"      äºˆæ¸¬æ•°: {metrics.usable_predictions}/{metrics.total_predictions}")
            if metrics.convergence_date:
                days_to_convergence = (metrics.convergence_date - datetime.now()).days
                print(f"      åæŸäºˆæ¸¬: {metrics.convergence_date.date()} ({days_to_convergence}æ—¥å¾Œ)")
            print()
            
            # è©³ç´°ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            detail_file = f'results/individual_stock_analysis/{symbol.lower()}_consistency_{timestamp}.csv'
            analyzer.save_results(symbol, detail_file)
            
            # å¯è¦–åŒ–
            viz_file = f'results/individual_stock_analysis/{symbol.lower()}_consistency_{timestamp}.png'
            analyzer.visualize_consistency(symbol, viz_file)
            
        except Exception as e:
            print(f"âŒ {symbol} åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            continue
    
    # ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generate_individual_stock_report(all_results, timestamp)
    
    print("âœ… å€‹åˆ¥æ ªåˆ†æå®Œäº†")
    print(f"ğŸ“ çµæœä¿å­˜å…ˆ: results/individual_stock_analysis/")

def generate_individual_stock_report(results: dict, timestamp: str):
    """å€‹åˆ¥æ ªåˆ†æã®ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ å€‹åˆ¥æ ª vs æŒ‡æ•° æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†é¡
    stocks = {k: v for k, v in results.items() if v['category'] == 'stock'}
    indices = {k: v for k, v in results.items() if v['category'] == 'index'}
    
    print(f"ğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼:")
    print(f"   å€‹åˆ¥æ ª: {len(stocks)}éŠ˜æŸ„")
    print(f"   æŒ‡æ•°: {len(indices)}éŠ˜æŸ„")
    
    # è©³ç´°æ¯”è¼ƒ
    all_data = []
    
    for symbol, data in results.items():
        metrics = data['metrics']
        all_data.append({
            'Symbol': symbol,
            'Name': data['name'],
            'Category': data['category'],
            'Consistency Score': f"{metrics.consistency_score:.3f}",
            'Total Predictions': metrics.total_predictions,
            'Usable Predictions': metrics.usable_predictions,
            'Usable Rate': f"{metrics.usable_predictions/max(metrics.total_predictions,1):.1%}",
            'Prediction Std (days)': f"{metrics.prediction_std_days:.1f}",
            'Convergence Date': metrics.convergence_date.date() if metrics.convergence_date else 'N/A',
            'Mean Confidence': f"{metrics.confidence_mean:.2%}"
        })
    
    # çµæœã‚’DataFrameã«å¤‰æ›ã—ã¦ã‚½ãƒ¼ãƒˆ
    import pandas as pd
    df = pd.DataFrame(all_data)
    df_sorted = df.sort_values('Consistency Score', ascending=False)
    
    print(f"\nğŸ† ä¸€è²«æ€§ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
    for i, row in df_sorted.head(10).iterrows():
        rank = df_sorted.index.get_loc(i) + 1
        category_icon = "ğŸ“ˆ" if row['Category'] == 'stock' else "ğŸ“Š"
        print(f"   {rank:2d}. {category_icon} {row['Symbol']} ({row['Name'][:20]}...)")
        print(f"        ä¸€è²«æ€§: {row['Consistency Score']}, äºˆæ¸¬æ•°: {row['Usable Predictions']}")
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
    if stocks and indices:
        stock_scores = [results[s]['metrics'].consistency_score for s in stocks]
        index_scores = [results[s]['metrics'].consistency_score for s in indices]
        
        print(f"\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥æ¯”è¼ƒ:")
        print(f"   å€‹åˆ¥æ ªå¹³å‡ä¸€è²«æ€§: {np.mean(stock_scores):.3f}")
        print(f"   æŒ‡æ•°å¹³å‡ä¸€è²«æ€§: {np.mean(index_scores):.3f}")
        
        if np.mean(stock_scores) > np.mean(index_scores):
            print(f"   ğŸ’¡ å€‹åˆ¥æ ªã®æ–¹ãŒäºˆæ¸¬ä¸€è²«æ€§ãŒé«˜ã„å‚¾å‘")
        else:
            print(f"   ğŸ’¡ æŒ‡æ•°ã®æ–¹ãŒäºˆæ¸¬ä¸€è²«æ€§ãŒé«˜ã„å‚¾å‘")
    
    # è­¦å‘ŠéŠ˜æŸ„
    low_consistency = [s for s, d in results.items() 
                      if d['metrics'].consistency_score < 0.5]
    
    if low_consistency:
        print(f"\nâš ï¸ ä½ä¸€è²«æ€§éŠ˜æŸ„ (< 0.5):")
        for symbol in low_consistency:
            data = results[symbol]
            print(f"   - {symbol} ({data['name'][:30]}): {data['metrics'].consistency_score:.3f}")
    
    # é«˜ãƒªã‚¹ã‚¯åæŸäºˆæ¸¬
    near_term_predictions = []
    for symbol, data in results.items():
        if data['metrics'].convergence_date:
            days_to_convergence = (data['metrics'].convergence_date - datetime.now()).days
            if 0 < days_to_convergence < 180:  # 6ãƒ¶æœˆä»¥å†…
                near_term_predictions.append((symbol, data, days_to_convergence))
    
    if near_term_predictions:
        near_term_predictions.sort(key=lambda x: x[2])  # æ—¥æ•°ã§ã‚½ãƒ¼ãƒˆ
        
        print(f"\nğŸš¨ çŸ­æœŸåæŸäºˆæ¸¬ (6ãƒ¶æœˆä»¥å†…):")
        for symbol, data, days in near_term_predictions:
            category_icon = "ğŸ“ˆ" if data['category'] == 'stock' else "ğŸ“Š"
            print(f"   {category_icon} {symbol}: {data['metrics'].convergence_date.date()} ({days}æ—¥å¾Œ)")
            print(f"      ä¸€è²«æ€§: {data['metrics'].consistency_score:.3f}, ä¿¡é ¼åº¦: {data['metrics'].convergence_confidence:.2%}")
    
    # CSVãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    report_file = f'results/individual_stock_analysis/individual_stock_report_{timestamp}.csv'
    df_sorted.to_csv(report_file, index=False)
    print(f"\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
    
    # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    print(f"\nğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
    if low_consistency:
        print("   1. ä½ä¸€è²«æ€§éŠ˜æŸ„ã®åˆ†ææœŸé–“ãƒ»æ‰‹æ³•è¦‹ç›´ã—")
    if near_term_predictions:
        print("   2. çŸ­æœŸåæŸäºˆæ¸¬éŠ˜æŸ„ã®ç›£è¦–å¼·åŒ–")
    print("   3. é«˜ä¸€è²«æ€§éŠ˜æŸ„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†æ")
    print("   4. ã‚ˆã‚Šé•·æœŸé–“ã§ã®ãƒ‡ãƒ¼ã‚¿åˆ†æå®Ÿè¡Œ")

def quick_individual_test():
    """å€‹åˆ¥æ ªã®ç°¡æ˜“ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ”¬ å€‹åˆ¥æ ªåˆ†æç°¡æ˜“ãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    from src.data_sources.unified_data_client import UnifiedDataClient
    from src.analysis.time_series_prediction_analyzer import TimeSeriesPredictionAnalyzer
    
    # 1éŠ˜æŸ„ã®ã¿ã§ãƒ†ã‚¹ãƒˆ
    client = UnifiedDataClient()
    analyzer = TimeSeriesPredictionAnalyzer()
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=30)  # 1ãƒ¶æœˆ
    
    # Appleã§ãƒ†ã‚¹ãƒˆ
    print("ğŸ Apple (AAPL) ç°¡æ˜“åˆ†æ:")
    metrics = analyzer.analyze_symbol_consistency(
        'AAPL', client, start_date, end_date, analysis_interval_days=15
    )
    
    print(analyzer.generate_report('AAPL'))

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='å€‹åˆ¥æ ªæ™‚ç³»åˆ—äºˆæ¸¬ä¸€è²«æ€§åˆ†æ')
    parser.add_argument('--quick', action='store_true', help='ç°¡æ˜“ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ')
    
    args = parser.parse_args()
    
    if args.quick:
        quick_individual_test()
    else:
        main()