#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„æ­´å²çš„ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 

ç›®çš„: è¤‡æ•°ã®æ­´å²çš„ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚’ä½“ç³»çš„ã«æ¤œè¨¼ã—ã€LPPLãƒ¢ãƒ‡ãƒ«ã®æ±ç”¨æ€§ã‚’è©•ä¾¡
"""

import sys
import os
from datetime import datetime
import json

sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from tests.historical_crashes.base_crash_validator import ReproducibleTestCase
from tests.historical_crashes.black_monday_1987_validator import run_black_monday_reproduction_test
from tests.historical_crashes.dotcom_bubble_2000_validator import run_dotcom_bubble_test

class ComprehensiveHistoricalValidator:
    """åŒ…æ‹¬çš„æ­´å²çš„æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.test_cases = {}
        self.validation_results = {}
        self.setup_test_cases()
    
    def setup_test_cases(self):
        """å†ç¾å¯èƒ½ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®è¨­å®š"""
        
        # 1987å¹´ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒ³ãƒ‡ãƒ¼ï¼ˆå®Ÿè¨¼æ¸ˆã¿åŸºæº–ï¼‰
        self.test_cases['black_monday_1987'] = ReproducibleTestCase(
            test_name="1987å¹´ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒ³ãƒ‡ãƒ¼å†ç¾æ¤œè¨¼",
            test_function=run_black_monday_reproduction_test,
            expected_score_range=(90, 100)  # å®Ÿè¨¼æ¸ˆã¿ãªã®ã§é«˜ã„ã‚¹ã‚³ã‚¢ã‚’æœŸå¾…
        )
        
        # 2000å¹´ãƒ‰ãƒƒãƒˆã‚³ãƒ ãƒãƒ–ãƒ«ï¼ˆæ–°è¦æ¤œè¨¼ï¼‰
        self.test_cases['dotcom_bubble_2000'] = ReproducibleTestCase(
            test_name="2000å¹´ãƒ‰ãƒƒãƒˆã‚³ãƒ ãƒãƒ–ãƒ«å´©å£Šæ¤œè¨¼",
            test_function=run_dotcom_bubble_test,
            expected_score_range=(60, 100)  # æŠ€è¡“æ ªç‰¹æœ‰ã®é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’æœŸå¾…
        )
    
    def run_all_validations(self):
        """å…¨ã¦ã®æ­´å²çš„æ¤œè¨¼ã‚’å®Ÿè¡Œ"""
        print("ğŸ¯ åŒ…æ‹¬çš„æ­´å²çš„ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹\n")
        print("=" * 60)
        
        results_summary = {
            'execution_timestamp': datetime.now().isoformat(),
            'total_tests': len(self.test_cases),
            'successful_tests': 0,
            'failed_tests': 0,
            'test_results': {}
        }
        
        for test_id, test_case in self.test_cases.items():
            print(f"\n{'='*60}")
            print(f"ğŸ§ª å®Ÿè¡Œä¸­: {test_case.test_name}")
            print(f"{'='*60}")
            
            try:
                success = test_case.run_test()
                result = test_case.get_last_result()
                
                if success and result:
                    results_summary['successful_tests'] += 1
                    results_summary['test_results'][test_id] = {
                        'status': 'success',
                        'prediction_score': result.get('prediction_score', 0),
                        'adjusted_score': result.get('adjusted_prediction_score', result.get('prediction_score', 0)),
                        'crash_date': result.get('crash_date'),
                        'data_points': result.get('data_points', 0),
                        'validation_type': result.get('validation_type', test_id)
                    }
                else:
                    results_summary['failed_tests'] += 1
                    results_summary['test_results'][test_id] = {
                        'status': 'failed',
                        'error': 'Test execution failed or returned invalid result'
                    }
                
                # çµæœä¿å­˜
                self.validation_results[test_id] = result
                
            except Exception as e:
                print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                results_summary['failed_tests'] += 1
                results_summary['test_results'][test_id] = {
                    'status': 'error',
                    'error': str(e)
                }
        
        # ç·åˆåˆ†æã®å®Ÿè¡Œ
        self.analyze_comprehensive_results(results_summary)
        
        # çµæœã®ä¿å­˜
        self.save_results(results_summary)
        
        return results_summary
    
    def analyze_comprehensive_results(self, results_summary):
        """åŒ…æ‹¬çš„çµæœã®åˆ†æ"""
        print(f"\n{'='*60}")
        print("ğŸ“Š åŒ…æ‹¬çš„æ­´å²çš„æ¤œè¨¼ ç·åˆåˆ†æ")
        print(f"{'='*60}")
        
        total_tests = results_summary['total_tests']
        successful_tests = results_summary['successful_tests']
        success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0
        
        print(f"\nğŸ¯ å®Ÿè¡Œã‚µãƒãƒªãƒ¼:")
        print(f"   ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
        print(f"   æˆåŠŸãƒ†ã‚¹ãƒˆ: {successful_tests}")
        print(f"   å¤±æ•—ãƒ†ã‚¹ãƒˆ: {results_summary['failed_tests']}")
        print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
        
        # æˆåŠŸã—ãŸãƒ†ã‚¹ãƒˆã®è©³ç´°åˆ†æ
        successful_results = [
            result for result in results_summary['test_results'].values()
            if result['status'] == 'success'
        ]
        
        if successful_results:
            print(f"\nğŸ“ˆ æˆåŠŸãƒ†ã‚¹ãƒˆè©³ç´°åˆ†æ:")
            
            scores = [r['prediction_score'] for r in successful_results]
            avg_score = sum(scores) / len(scores)
            max_score = max(scores)
            min_score = min(scores)
            
            print(f"   å¹³å‡äºˆæ¸¬ã‚¹ã‚³ã‚¢: {avg_score:.1f}/100")
            print(f"   æœ€é«˜ã‚¹ã‚³ã‚¢: {max_score}/100")
            print(f"   æœ€ä½ã‚¹ã‚³ã‚¢: {min_score}/100")
            
            # å€‹åˆ¥çµæœã®è©³ç´°
            print(f"\nğŸ“‹ å€‹åˆ¥ãƒ†ã‚¹ãƒˆçµæœ:")
            for test_id, result in results_summary['test_results'].items():
                if result['status'] == 'success':
                    score = result['prediction_score']
                    adjusted = result.get('adjusted_score', score)
                    points = result.get('data_points', 'N/A')
                    
                    print(f"   {test_id}:")
                    print(f"     äºˆæ¸¬ã‚¹ã‚³ã‚¢: {score}/100")
                    if adjusted != score:
                        print(f"     èª¿æ•´å¾Œã‚¹ã‚³ã‚¢: {adjusted}/100")
                    print(f"     ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {points}æ—¥")
                    print(f"     è©•ä¾¡: {'âœ… å„ªç§€' if score >= 80 else 'âš ï¸ è‰¯å¥½' if score >= 60 else 'ğŸ”¶ è¦æ”¹å–„'}")
        
        # LPPLãƒ¢ãƒ‡ãƒ«æ±ç”¨æ€§ã®è©•ä¾¡
        print(f"\nğŸ”¬ LPPLãƒ¢ãƒ‡ãƒ«æ±ç”¨æ€§è©•ä¾¡:")
        
        if success_rate >= 80:
            print("âœ… å„ªç§€: LPPLãƒ¢ãƒ‡ãƒ«ã¯è¤‡æ•°ã®æ­´å²çš„ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã§é«˜ã„äºˆæ¸¬èƒ½åŠ›ã‚’å®Ÿè¨¼")
            print("âœ… ç§‘å­¦çš„ä¾¡å€¤: ç†è«–ã®æ±ç”¨æ€§ã¨å®Ÿç”¨æ€§ã‚’ç¢ºèª")
            print("âœ… å®Ÿç”¨ä¾¡å€¤: æ§˜ã€…ãªå¸‚å ´çŠ¶æ³ã§ã®äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ãŒå¯èƒ½")
        elif success_rate >= 60:
            print("âš ï¸ è‰¯å¥½: LPPLãƒ¢ãƒ‡ãƒ«ã¯æ¦‚ã­æœ‰åŠ¹ã ãŒæ”¹å–„ã®ä½™åœ°ã‚ã‚Š")
            print("ğŸ”¬ ç ”ç©¶ä¾¡å€¤: ç‰¹å®šã®å¸‚å ´æ¡ä»¶ã§ã®äºˆæ¸¬ç²¾åº¦å‘ä¸ŠãŒèª²é¡Œ")
        else:
            print("ğŸ”¶ è¦æ”¹å–„: LPPLãƒ¢ãƒ‡ãƒ«ã®æ±ç”¨æ€§ã«èª²é¡Œã‚ã‚Š")
            print("ğŸ› ï¸ æ”¹å–„å¿…è¦: ãƒ¢ãƒ‡ãƒ«ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®æ‰‹æ³•æ”¹è‰¯ãŒæ€¥å‹™")
        
        # ä»Šå¾Œã®å±•é–‹ææ¡ˆ
        print(f"\nğŸš€ ä»Šå¾Œã®å±•é–‹ææ¡ˆ:")
        
        if success_rate >= 80:
            print("1. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™º")
            print("2. å•†ç”¨äºˆæ¸¬ã‚µãƒ¼ãƒ“ã‚¹ã®æ§‹ç¯‰")
            print("3. é‡‘èæ©Ÿé–¢ã¨ã®é€£æºå¼·åŒ–")
            print("4. å›½éš›å¸‚å ´ã¸ã®å±•é–‹")
        else:
            print("1. å¤±æ•—ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®è©³ç´°åˆ†æ")
            print("2. ãƒ¢ãƒ‡ãƒ«ç²¾åº¦å‘ä¸Šæ‰‹æ³•ã®ç ”ç©¶")
            print("3. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†æ‰‹æ³•ã®æ”¹è‰¯")
            print("4. è¿½åŠ ã®æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåé›†")
    
    def save_results(self, results_summary):
        """çµæœã®ä¿å­˜"""
        # JSONå½¢å¼ã§ã®è©³ç´°çµæœä¿å­˜
        results_dir = 'analysis_results/historical_validation'
        os.makedirs(results_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # è©³ç´°çµæœJSON
        json_file = f"{results_dir}/comprehensive_validation_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(results_summary, f, indent=2, ensure_ascii=False, default=str)
        
        # ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³
        report_file = f"{results_dir}/validation_report_{timestamp}.md"
        self.generate_markdown_report(results_summary, report_file)
        
        print(f"\nğŸ“„ çµæœä¿å­˜:")
        print(f"   è©³ç´°JSON: {json_file}")
        print(f"   ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
    
    def generate_markdown_report(self, results_summary, report_file):
        """ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        
        total_tests = results_summary['total_tests']
        successful_tests = results_summary['successful_tests']
        success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0
        
        successful_results = [
            result for result in results_summary['test_results'].values()
            if result['status'] == 'success'
        ]
        
        avg_score = 0
        if successful_results:
            scores = [r['prediction_score'] for r in successful_results]
            avg_score = sum(scores) / len(scores)
        
        report_content = f"""# åŒ…æ‹¬çš„æ­´å²çš„ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ

## å®Ÿè¡Œæ¦‚è¦

- **å®Ÿè¡Œæ—¥æ™‚**: {results_summary['execution_timestamp']}
- **ç·ãƒ†ã‚¹ãƒˆæ•°**: {total_tests}
- **æˆåŠŸãƒ†ã‚¹ãƒˆ**: {successful_tests}
- **æˆåŠŸç‡**: {success_rate:.1f}%
- **å¹³å‡äºˆæ¸¬ã‚¹ã‚³ã‚¢**: {avg_score:.1f}/100

## æ¤œè¨¼çµæœè©³ç´°

"""
        
        for test_id, result in results_summary['test_results'].items():
            if result['status'] == 'success':
                score = result['prediction_score']
                status_icon = 'âœ…' if score >= 80 else 'âš ï¸' if score >= 60 else 'ğŸ”¶'
                
                report_content += f"""### {test_id.replace('_', ' ').title()}

- **äºˆæ¸¬ã‚¹ã‚³ã‚¢**: {score}/100 {status_icon}
- **ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°**: {result.get('data_points', 'N/A')}æ—¥
- **ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ—¥**: {result.get('crash_date', 'N/A')}
- **æ¤œè¨¼ã‚¿ã‚¤ãƒ—**: {result.get('validation_type', 'N/A')}

"""
            else:
                report_content += f"""### {test_id.replace('_', ' ').title()}

- **ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: âŒ å¤±æ•—
- **ã‚¨ãƒ©ãƒ¼**: {result.get('error', 'Unknown error')}

"""
        
        # ç·åˆè©•ä¾¡
        if success_rate >= 80:
            overall_status = "âœ… å„ªç§€"
            evaluation = "LPPLãƒ¢ãƒ‡ãƒ«ã¯è¤‡æ•°ã®æ­´å²çš„ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã§é«˜ã„äºˆæ¸¬èƒ½åŠ›ã‚’å®Ÿè¨¼"
        elif success_rate >= 60:
            overall_status = "âš ï¸ è‰¯å¥½" 
            evaluation = "LPPLãƒ¢ãƒ‡ãƒ«ã¯æ¦‚ã­æœ‰åŠ¹ã ãŒæ”¹å–„ã®ä½™åœ°ã‚ã‚Š"
        else:
            overall_status = "ğŸ”¶ è¦æ”¹å–„"
            evaluation = "LPPLãƒ¢ãƒ‡ãƒ«ã®æ±ç”¨æ€§ã«èª²é¡Œã‚ã‚Š"
        
        report_content += f"""
## ç·åˆè©•ä¾¡

**{overall_status}**: {evaluation}

## ç§‘å­¦çš„ãƒ»å®Ÿç”¨çš„æ„ç¾©

- **ç†è«–æ¤œè¨¼**: è¤‡æ•°ã®æ­´å²çš„ã‚¤ãƒ™ãƒ³ãƒˆã§ã®ç†è«–é©ç”¨æ€§è©•ä¾¡
- **æ±ç”¨æ€§ç¢ºèª**: ç•°ãªã‚‹å¸‚å ´æ¡ä»¶ã§ã®ãƒ¢ãƒ‡ãƒ«æœ‰åŠ¹æ€§æ¤œè¨¼  
- **å®Ÿç”¨ä¾¡å€¤**: å°†æ¥ã®äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã¸ã®æŒ‡é‡æä¾›

---

*Generated by Claude Code - Comprehensive Historical Validation System*
"""
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    validator = ComprehensiveHistoricalValidator()
    results = validator.run_all_validations()
    
    print(f"\nğŸ† åŒ…æ‹¬çš„æ­´å²çš„æ¤œè¨¼å®Œäº†")
    print(f"æˆåŠŸç‡: {(results['successful_tests']/results['total_tests'])*100:.1f}%")
    
    return results

if __name__ == "__main__":
    main()